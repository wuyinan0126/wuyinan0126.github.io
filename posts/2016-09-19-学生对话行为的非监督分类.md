---
title:  "<font color='orange'>[摘译]</font> 学生对话行为的非监督分类"
date:   2016-09-19 00:00:00
categories: [NLP,摘译,机器学习,聚类,MOOC]
tags: [NLP,摘译,机器学习,聚类,MOOC]
---

*文章介绍了一种针对学生对话行为的非监督分类方法。首先对学生对话使用词性标签进行自然语言预处理，然后使用Query-Likelihood进行相似对话行为的信息检索，最后使用k-means聚类算法将相似对话行为进行聚类*

## 文章

> [Unsupervised Classification of Student Dialogue Acts With Query-Likelihood Clustering][paper-link]

## 语料库
---

语料库由参与2007春的JavaTutor项目的师生对话构成。师生通过网络使用文本对话进行交流，共有43个对话，包含1525个学生对话（平均每句话7.54个单词）和3332个老师对话（平均每句话9.04个单词）。文章专注于分类学生对话，而老师对话分类将由系统生成。下表是对话类别和频率，Kappa系数为0.76:

|标签|行为|描述|频率|
|---|---|---|---|
|Q|一般问题|一个于学习任务无关的问题|276|
|EQ|学习问题|一个于学习任务相关的问题|416|
|S|陈述|对一个事实的陈述|211|
|G|Grounding|对先前对话的承认|192|
|EX|Extra-Domain|任何于学习无关的对话|133|
|PF|正面反馈|对于知识或学习任务的正面评价|116|
|NF|负面反馈|对于知识或学习任务的负面评价|92|
|LF|Lukewarm反馈|同时含有正面和负面评价的评价|32|
|GRE|问候|问候词语|57|

## Query-Likelihood 聚类
---

IR（Information Retrieval，信息检索）是搜索可用的资源用于检索和查询词相似的结果的过程。IR技术大部分用于搜索引擎检索和查询词相似的结果。在提出的方法中，将被分类的目标对话将被用作一个查询，而与它相似的对话将通过query likelihood进行收集。之后，与查询相似的结果被用于聚类。

### 自然语言预处理

Query-likelihood信息检索操作的是token或word级别的。实验证实，为了增加从语料库中提取有识别力的线索，预处理是一个关键的步骤。

词性（Part-of-speech, POS）标签是一项根据词语在语言中的语法部分将其标注为名词、动词或形容词的技术。它允许我们概括词语在句子中的功能。实验证明，使用单词和词性标签作为查询词能得到很好的效果。这个方法将一些功能词语替代为它们的词性标签，例如限定词（'the', 'a'）、连词（'and', 'but'）和介词（'in', 'after'），而内容词语将被保留并提取词干，这将减少特征词语的数量。这个方法是通过观察，发现关于对话的重要的词语存在于内容词语中。

当然，在计算机科学领域，一些包含特定字符的自然语言可能表示重要的语义，因此在预处理阶段需要适当的处理。因此，在语料库中的代码片段将被替换为具有意义的标签。例如，'x[i]'将被替换为'ARRAY_INDEXING'，if、for和算数表达式将使用相似的规定替换。

### Query-Likelihood 表示

Query-likelihood模型将每个对话视为一个文档，将被预测的目标对话作为查询，我们提供对目标对话的信息检索。这个查询将产生一个文档的排名列表，从最像到最不像。Query-likelihood的实现[The Lemur Project][lemur-project]使用论文[A language-model based search engine forcomplex queries][query-paper-link]。

词语的顺序包含了对话结构的重要信息，因此我们使用一个修改过的查询方法，考虑一个对话里相邻的两个单词进行查询。

下表中展示了多个原始的对话、在被词性标签替换及提取词干后的形式、和最后提交给算法的查询形式：

|原始对话|POS和词干提取形式|查询形式|
|---|---|---|
|I'm reading it right now|VB read PRP right now|(VB read)(read PRP)(PRP right)(right now)|
|what is the basic structure to begin an array?|WDT VBZ DT basic structur TO begin DT array?|(WDT VBZ)(VBZ DT)(DT basic)(basic structur)(structur TO)(TO begin)(begin DT)(DT array)(array ?)|
|that was correct|WDT VBD correct|(WDT VBD)(VBD correct)|
|how do you thinkyou should start it?|WRB do PRP think PRP MD start PRP?|(WRB do)(do PRP)(PRP think)(think PRP)(PRP MD)(PRP start)(startPRP)(PRP ?)|

<br/>
其中VBZ是第三人称现在时的单数动词，DT是限定词，TO是'to'，VBD是过去式动词，WDT和WRB是疑问词，MD是情态动词。

下面是一个查询样例和它的相似检索：

|Query|Query Likelihood results|
|---|---|
|How can I solve this problem?|How can I do addition?<br/>What would be the results?<br/>Which should go first?|
	
### 聚类

查询获得的相似结果将被用作k-means聚类算法中的距离矩阵。这个想法实现依赖于为相似的对话创造一个二进制向量，然后group这些向量。每个在相似列表中的对话表示为1，其它表示为0。这样，每个在语料库中的目标对话将被表示为一个向量，这个向量表示和它相似的对话。算法如下：

* D为所有对话组成的语料库，$$D=\lbrace u_1,u_2,...,u_n \rbrace$$，目标是对于D中的任意一个对话$$u_i$$，确定一个标签$$l_i$$
* 对于每个$$u_i$$，
1. 设目标对话$$q_i=u_i$$
2. 设$$u_i$$的查询结果相似列表为$$R=(u_t,u_{t+1},...,u_z)$$
3. 创建查询结果向量，$$V_i=(v_1,v_2,...,v_j,...,v_n)\ such\ that\ v_j=1\ if\ u_j\in R\ else\ v_j=0$$
* 设总向量为$$V_T=(V_1,V_2,...,V_n)$$，返回k-means($$V_T$$)的聚类结果$$C=\lbrace c_1,c_2,...,c_k \rbrace$$

---

[paper-link]:  		http://www.educationaldatamining.org/EDM2013/papers/rn_paper_06.pdf
[query-paper-link]:	http://ciir.cs.umass.edu/pubfiles/ir-407.pdf
[lemur-project]:	http://www.lemurproject.org/
