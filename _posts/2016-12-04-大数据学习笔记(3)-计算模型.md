---
title:  "<font color='red'>[原创]</font> 大数据学习笔记(3)-计算模型"
date:   2016-12-04 00:00:00
categories: [原创,大数据]
tags: [原创,大数据]
---

*深入学习MapReduce、DAG计算模型的运行机制、优点和不足、计算模式等*

## MapReduce
---

### MapReduce运行机制

![Hadoop的MapReduce运行机制](/assets/2016-12-04-1.png "Hadoop的MapReduce运行机制")

1. MapReduce计算框架将应用的输入数据分割成若干block（自Hadoop-2.2起，默认为128M），存入HDFS

2. 集群中的Master负责为Worker分配Map或Reduce任务，并做一些全局管理；任务数可由开发者指定

3. Map阶段：被分配到Map任务的Worker读取对应的block，从block中解析出Key/Value对，并传递给Map函数，执行业务逻辑，将中间结果Key/Value对缓存在内存中

5. Patition阶段：缓存的中间结果会周期性地被Spill入**本地磁盘**，写入磁盘前被Partitioner分割为R份，R为Reduce任务数，分割函数一般是用Key对R哈希取模。在分割后将R个临时文件位置通知给Master，Master将其转交给Reduce任务的Worker

4. Sort&Combine阶段：在写入磁盘前，对中间结果进行**局部**排序，然后运行Combiner对数据进行合并，即对中间数据中具有相同Key的Value值进行合并，合并的业务逻辑和Reduce阶段的逻辑是相似的，这样可以大大减少中间数据量，减少网络传输量

6. Shuffle阶段：当某个Reduce任务的Worker接收到Master的通知后，其通过RPC(Remote Procedure Call)将Map任务产生的属于自己的M份临时文件**Pull**到本地，M为Map任务数。

7. Reduce阶段：将M分临时文件中局部Key有序的数据进行Merge Sort进行全局排序，然后执行Reduce函数，并将结果追加到这个Reduce任务对应的结果文件结尾

---

### MapReduce优点和不足

* 优点：

	1. 极强的可扩展性、良好的容错性、简单性（即用户只要完成Map和Reduce函数即可）

	2. 数据的高吞吐量、支持海量数据处理的大规模并行处理、细粒度容错

* 不足：不适合对实效性要求高的应用场景（如交互式查询、流式计算）、不适合迭代运算类的机器学习及数据挖掘类的应用

* 不足的原因：
	
	1. Map和Reduce任务启动时间较长。对于批处理任务来说，启动时间对于任务执行时间所占比例不大，但对于高实效性的应用来说，所占比例太高

	2. 在一次任务执行过程中，MapReduce计算模型存在多处的磁盘读写、网络传输的过程。如初始block读取、Map任务的中间结果保存入磁盘、Shuffle阶段的网络传输、Reduce阶段的磁盘读和HDFS写等。对于迭代式机器学习应用，往往需要一个任务反复迭代进行，此时磁盘读写、网络传输的开销造成效率低下

---

### MapReduce计算模式

实际应用中的大部分ETL任务都可以归结为MapReduce计算模式或其变体，如：

1. 求和模式：包括数值求和（Value为数值），记录求和（Value为非数值，累加形成队列）

2. 过滤模式：简单过滤（Map实现过滤函数，无Reduce阶段），Top K记录（Map实现统计局部Top K，Reduce实现全局Top K）

3. 组织数据模式：
	
	1. 数据分片：例如将所有记录按日期进行分类，需要将同一时间的数据放到一起，此时需要修改Partion策略，默认的Partition策略为hash取模

	2. 全局排序：MapReduce自带的排序特性，在Reduce阶段需要先将中间数据按Key进行Merge Sort，因此只需要修改Partion策略，保证不同的Reducer处理一个区间范围的记录，例如将Key为1-1000的数据给Reducer1处理，key为1001-2000点数据交给Reducer2处理，这样将所有Reducer的输出拼接在一起即可得到全局排序

4. Join模式：

	1. Reduce-Side Join：需要输入两个数据集，区分方式为：连表的外键作为Key，记录的其他内容作为Value，在Value中增加一个标志信息，表明记录属于哪个数据集。然后在Reduce阶段将相同Key，不同数据集的记录做Join。该方式较通用，但需要经过若干轮中间数据的磁盘读写、Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此计算效率较低

	2. Map-Side Join：只需要输入一个大数据集，小数据集放入内存哈希表中，以外键作为哈希表的Key。此时只需要在Map阶段对大数据的每条记录查找哈希表进行Join操作。由于避免了Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此该方式效率较高，但要求小数据集必须足够小到能放入内存

## 一种更高效的的计算框架——DAG
---

虽然MapReduce提供了简介的借口，用户只需完成Map和Reduce函数的业务逻辑就可以实现大规模数据批处理任务，但是其支持的运算符仅仅限定与Map和Reduce两类，所以在表达能力上不够丰富。

另外，MapReduce计算模型的本质是由Map和Reduce序列两个阶段完成的，在Map任务阶段有个任务同步过程，只有在所有Map任务执行完成才能开始Reduce阶段的任务。

从上可以看出MapReduce对于子任务之间复杂的交互和依赖关系缺乏表达能力，因此，一种更高效的的计算框架——DAG氤氲而生。DAG计算模型可以认为是对MapReduce计算模型的一种扩展（可以将MapReduce模型看作DAG模型的一种特例）。DAG模型可以表达复杂的并发任务之间的依赖关系，提供了丰富的运算符，使其表达能力和灵活性更加强大。

---

### DAG运行机制


