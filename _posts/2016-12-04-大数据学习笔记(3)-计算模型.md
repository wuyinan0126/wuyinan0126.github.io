---
title:  "<font color='red'>[原创]</font> 大数据学习笔记(3)-计算模型"
date:   2016-12-04 00:00:00
categories: [原创,大数据]
tags: [原创,大数据]
---

*深入学习MapReduce、DAG计算模型，介绍了MapReduce计算模型的运行机制、优点和不足、计算模式，和一种更高效的的计算框架——DAG模型的图结构描述*

## MapReduce
---

### MapReduce运行机制

![Hadoop的MapReduce运行机制](/assets/2016-12-04-1.png "Hadoop的MapReduce运行机制")

1. MapReduce计算框架将应用的输入数据分割成若干block（自Hadoop-2.2起，默认为128M），存入HDFS

2. 集群中的Master负责为Worker分配Map或Reduce任务，并做一些全局管理；任务数可由开发者指定

3. Map阶段：被分配到Map任务的Worker读取对应的block，从block中解析出Key/Value对，并传递给Map函数，执行业务逻辑，将中间结果Key/Value对缓存在内存中

5. Patition阶段：缓存的中间结果会周期性地被Spill入**本地磁盘**，写入磁盘前被Partitioner分割为R份，R为Reduce任务数，分割函数一般是用Key对R哈希取模。在分割后将R个临时文件位置通知给Master，Master将其转交给Reduce任务的Worker

4. Sort&Combine阶段：在写入磁盘前，对中间结果进行**局部**排序，然后运行Combiner对数据进行合并，即对中间数据中具有相同Key的Value值进行合并，合并的业务逻辑和Reduce阶段的逻辑是相似的，这样可以大大减少中间数据量，减少网络传输量

6. Shuffle阶段：当某个Reduce任务的Worker接收到Master的通知后，其通过RPC(Remote Procedure Call)将Map任务产生的属于自己的M份临时文件**Pull**到本地，M为Map任务数。

7. Reduce阶段：将M分临时文件中局部Key有序的数据进行Merge Sort进行全局排序，然后执行Reduce函数，并将结果追加到这个Reduce任务对应的结果文件结尾

---

### MapReduce优点和不足

* 优点：

	1. 极强的可扩展性、良好的容错性、简单性（即用户只要完成Map和Reduce函数即可）

	2. 数据的高吞吐量、支持海量数据处理的大规模并行处理、细粒度容错

* 不足：
	
	1. 不适合对实效性要求高的应用场景（如交互式查询、流式计算）

	2. 不适合迭代运算类的机器学习及数据挖掘类的应用

* 不足的原因：
	
	1. Map和Reduce任务启动时间较长。对于批处理任务来说，启动时间对于任务执行时间所占比例不大，但对于高实效性的应用来说，所占比例太高

	2. 在一次任务执行过程中，MapReduce计算模型存在多处的磁盘读写、网络传输的过程。如初始block读取、Map任务的中间结果保存入磁盘、Shuffle阶段的网络传输、Reduce阶段的磁盘读和HDFS写等。对于迭代式机器学习应用，往往需要一个任务反复迭代进行，此时磁盘读写、网络传输的开销造成效率低下

---

### MapReduce计算模式

实际应用中的大部分ETL任务都可以归结为MapReduce计算模式或其变体，如：

1. 求和模式：包括数值求和（Value为数值），记录求和（Value为非数值，累加形成队列）

2. 过滤模式：简单过滤（Map实现过滤函数，无Reduce阶段），Top K记录（Map实现统计局部Top K，Reduce实现全局Top K）

3. 组织数据模式：
	
	1. 数据分片：例如将所有记录按日期进行分类，需要将同一时间的数据放到一起，此时需要修改Partion策略，默认的Partition策略为hash取模

	2. 全局排序：MapReduce自带的排序特性，在Reduce阶段需要先将中间数据按Key进行Merge Sort，因此只需要修改Partion策略，保证不同的Reducer处理一个区间范围的记录，例如将Key为1-1000的数据给Reducer1处理，key为1001-2000点数据交给Reducer2处理，这样将所有Reducer的输出拼接在一起即可得到全局排序

4. Join模式：

	1. Reduce-Side Join：需要输入两个数据集，区分方式为：连表的外键作为Key，记录的其他内容作为Value，在Value中增加一个标志信息，表明记录属于哪个数据集。然后在Reduce阶段将相同Key，不同数据集的记录做Join。该方式较通用，但需要经过若干轮中间数据的磁盘读写、Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此计算效率较低

	2. Map-Side Join：只需要输入一个大数据集，小数据集放入内存哈希表中，以外键作为哈希表的Key。此时只需要在Map阶段对大数据的每条记录查找哈希表进行Join操作。由于避免了Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此该方式效率较高，但要求小数据集必须足够小到能放入内存

## 一种更高效的的计算框架——DAG
---

虽然MapReduce提供了简介的借口，用户只需完成Map和Reduce函数的业务逻辑就可以实现大规模数据批处理任务，但是其支持的运算符仅仅限定与Map和Reduce两类，所以在表达能力上不够丰富。

另外，MapReduce计算模型的本质是由Map和Reduce序列两个阶段完成的，在Map任务阶段有个任务同步过程，只有在所有Map任务执行完成才能开始Reduce阶段的任务。

从上可以看出MapReduce对于子任务之间复杂的交互和依赖关系缺乏表达能力，因此，一种更高效的的计算框架——DAG氤氲而生。DAG计算模型可以认为是对MapReduce计算模型的一种扩展（可以将MapReduce模型看作DAG模型的一种特例）。DAG模型可以表达复杂的并发任务之间的依赖关系，提供了丰富的运算符，使其表达能力和灵活性更加强大。

DAG的全称是"Directed Acyclic Graph"(有向无环图)，是指将计算任务分解成若干子任务，这些子任务之间由逻辑关系或运行先后顺序等因素被构建成有向无环图结构。

---

### DAG图结构描述

以微软的Dryad为例，其采用了若干简单的DAG结构及其描述符的不断组合来构建复杂结构的方式。可以形式化地用以下方式描述一个DAG图结构：

$$G=\{ {V}_{G},{E}_{G},{I}_{G},{O}_{G} \} $$

其中，VG代表图节点集合，EG代表有向边集合；IG是VG的子集，表示DAG图中的数据输入节点集合；OG也是VG的子集，表示DAG图中数据输出节点集合。

* 一个基本的图描述符为G^k，表示一个计算结构并发为k个，如下图：

![A^n](/assets/2016-12-04-2.png "A^n")

* 图结构串行连接G3 = G1 · G2，由图G1和图G2的所有节点和边构成，图G1的输入节点构成图G3的输入节点，图G2的输出节点构成图G3的输出节点，图G1的输出节点到图G2的输入节点之间构建新的有向边。这种关系可以定义下列两个描述符：

	* G1 >= G2：图G1的输出节点和图G2的输入节点间进行点对点的边连接，采用Round Robin(轮询)的方式构建有向边：
		* 如果\|OG1\|>=\|IG2\|，此时G2的输入节点中某些节点输入边可能大于1条
		* 如果\|OG1\|<\|IG2\|，此时G2的输入节点中有些节点没有输入边

	* G1 >> G2: 图G1的输出节点和图G2的输入节点之间形成完全二分图。**MapReduce架构即为由并发执行的Map阶段的图G1和Reduce阶段的图G2串行而成的完全二分图，如下图：

	![AS >> BS](/assets/2016-12-04-3.png "AS >> BS")

* G1 \|\| G2：代表图结构水平融合，允许图G1和图G2有相同的节点，融合时合并相同节点，如下图，是由图B >= C和图B >= D水平融合得到的：

![B >= C \|\| B >= D](/assets/2016-12-04-4.png "B >= C \|\| B >= D")

* 通过以上几个基础的描述符，可以构建复杂的图结构，如下图：

![复杂图结构](/assets/2016-12-04-5.png "复杂图结构")

---

### DAG图任务执行



---

**未完待续**
