---
title:  "<font color='red'>[原创]</font> 大数据学习笔记(2)-Hadoop"
date:   2016-12-01 00:00:00
categories: [原创,大数据]
tags: [原创,大数据]
---

*简单学习Hadoop相关知识，包括MapReduce计算框架、HDFS文件系统、YARN资源调度与管理系统，并搭建Hadoop单机平台*

## Hadoop
---

### MapReduce

大数据计算中最常见的一种计算方式是**批处理**。2004年Google发表了MapReduce计算范型和框架论文，这是一种构建在大规模PC之上的批处理计算框架，也是一种分布式计算模型，获得了极为广泛的应用。

MapReduce和传统的并行数据库系统(MPP)相比，更适合**非结构化数据的ETL处理**(将数据从来源端经过抽取(extract)、转换(transform)、加载(load)至目的端的过程)，且其更具有**扩展性和容错性**，但单机处理效率低。

MapReduce计算提供了简洁的编程接口，**输入和输出均是Key/Value键值对**，只需根据业务逻辑实现Map和Reduce函数即可完成大规模数据的并行批处理任务。

* Map函数以Key/Value作为输入，经逻辑计算产生若干仍以Key/Value形式表达的中间数据。计算框架自动将中间数据中具有相同Key值的记录聚在一起，传递给Reduce函数作为输入
* Reduce函数以Map阶段传递过来的某个Key值及其对应的若干Value值作为输入，对这些Value进行逻辑计算，生成Key/Value即计算结果

以上为MapReduce简介，更为详细的MapReduce计算模型学习笔记请参看我的另一篇博文：[大数据学习笔记(3)-MapReduce](https://wuyinan0126.github.io/2016/大数据学习笔记(3)-MapReduce/)

### HDFS


### YARN

YARN的全称是"Yet Another Resource Negotiator"，是一个独立的**资源调度与管理系统**。

在Hadoop1.x中，所有任务的**资源管理**以及**生命周期管理**都由全局唯一的JobTracker负责，造成其功能繁复，限制了系统的可扩展性。同时JobTracker还存在单点失效的问题，一旦JobTracker故障，整个Hadoop集群将崩溃。

在Hadoop2.x中，将**资源管理**与**任务生命周期管理**功能分离，由ResourceManager(RM)负责资源管理，由ApplicationMaster(AM)负责任务所需资源申请管理与任务生命周期管理。这样的好处除了**增强系统的可扩展性**，**解决JobTracker单点故障问题**，还**可以部署除MapReduce计算框架外的其他计算框架，共享底层硬件资源**。


## 安装Hadoop（版本2.7.3）
---

#### 准备工作 
1. SSH免密码登录:

	1. 生成密钥: 

			$ ssh-keygen -t dsa

	2. 生成authorized_keys，进入.ssh目录:

			$ cat id_dsa.pub >> authorized_keys
			$ chmod 600 authorized_keys

	3. 测试:
	
			$ ssh localhost

2. 下载Hadoop二进制包（或源码自行编译），解压至/opt/:

		$ tar -zxvf ./hadoop-2.7.3.tar.gz -C /opt/

#### 配置Hadoop
1. etc/hadoop/core-site.xml:

		<configuration>
		  <property>
		    <name>fs.defaultFS</name>
		    <value>hdfs://localhost:9000</value>
		    <description>默认的HDFS路径，与hdfs-site.xml中的配置相关。当有多个HDFS集群存在时，用此名字指定集群</description>
			</property>
		  <property>
		    <name>hadoop.tmp.dir</name>
		    <value>/opt/hadoop-2.7.3/var/tmp</value> 
		    <description>NameNode、DataNode、JournalNode等存放数据的公共目录，也可以自己单独指定这三类节点的目录</description>
			</property>
		  <property>
		    <name>hadoop.proxyuser.wuyinan.groups</name>
		    <value>*</value>
		    <description></description>
			</property>
		  <property>
		    <name>hadoop.proxyuser.wuyinan.hosts</name>
		    <value>*</value>
		    <description></description>
			</property>
		</configuration>

2. etc/hadoop/hdfs-site.xml:

		<configuration>
		  <property>
		    <name>dfs.namenode.name.dir</name>
		    <value>/opt/hadoop-2.7.3/var/name</value>
		    <description>NameNode存储命名空间和操作日志相关的元数据信息的本地文件系统路径</description>
			</property>
		  <property>
		    <name>dfs.datanode.data.dir</name>
		    <value>/opt/hadoop-2.7.3/var/data</value>
		    <description>DataNode节点存储HDFS文件的本地文件系统路径</description> 
			</property>
		  <property>
		    <name>dfs.replication</name>
		    <value>1</value>
		    <description>指定DataNode存储block的副本数量。默认值是3个，不大于DataNode个数即可</description>
			</property>
		</configuration>

3. etc/hadoop/mapred-site.xml:

		<configuration>
		  <property>
		    <name>mapreduce.framework.name</name>
		    <value>yarn</value> 
		    <description>指定运行mapreduce的环境是yarn</description>
			</property>
		  <property>
		    <name>mapreduce.tasktracker.map.tasks.maximum</name>
		    <value>2</value>
		    <description></description>
			</property>
		  <property>
		    <name>mapreduce.tasktracker.reduce.tasks.maximum</name>
		    <value>2</value>
		    <description></description>
			</property>
		</configuration>

4. etc/hadoop/yarn-site.xml:

		<configuration>
		  <property>      
		    <name>yarn.resourcemanager.hostname</name>      
		    <value>localhost</value>  
		    <description>指定ResourceManager的地址</description>
			</property>  
		  <property>  
		    <name>yarn.nodemanager.aux-services</name>  
		    <value>mapreduce_shuffle</value>  
		    <description></description>
			</property>
		  <property>  
		    <name>yarn.resourcemanager.scheduler.class</name>
		    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
		    <description></description>
			</property>
		  <property>
		    <name>yarn.log-aggregation-enable</name>
		    <value>true</value>
		    <description></description>
			</property>
		  <property>
		    <name>yarn.nodemanager.remote-app-log-dir</name>
		    <value>/tmp/logs</value>
		    <description></description>
			</property>
		</configuration>

5. etc/hadoop/mapred-env.sh:

		export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home
		export HADOOP_MAPRED_PID_DIR=/opt/hadoop-2.7.3/var/tmp

6. etc/hadoop/hadoop-env.sh:

		export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home
		export HADOOP_PID_DIR=/opt/hadoop-2.7.3/var/tmp
		export HADOOP_SECURE_DN_PID_DIR=/opt/hadoop-2.7.3/var/tmp

7. etc/hadoop/slaves:

		localhost

#### 启动Hadoop	
1. 根据hadoop.tmp.dir, dfs.namenode.name.dir, dfs.datanode.name.dir在相应位置创建目录

		$ mkdir /opt/hadoop-2.7.3/var/
		$ mkdir /opt/hadoop-2.7.3/var/tmp
		$ mkdir /opt/hadoop-2.7.3/var/name
		$ mkdir /opt/hadoop-2.7.3/var/data

2. 格式化namenode，如果Exiting with status 0，说明格式化成功:

		$ hdfs namenode -format

3. 启动namenode、datanode、yarn，每启动一个后都用jps查看是否启动成功，最后启动的进程应该包括NameNode、DataNode、ResorceManager、NodeManager:

		$ hadoop-daemon.sh start namenode
		$ hadoop-daemon.sh start datanode
		$ start-yarn.sh

4. 在浏览器查看：[http://localhost:50070/](http://localhost:50070/)和[http://localhost:8088/](http://localhost:8088/)

5. 测试，运行wordcount例子:

		$ hadoop fs -mkdir /test
		$ hadoop fs -mkdir /test/input
		$ hadoop fs -put ./words.txt /test/input
		$ hadoop jar /opt/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /test/input/ /test/output
		$ hadoop fs -cat /test/output/part-r-00000
