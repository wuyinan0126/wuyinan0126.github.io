<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title><font color='red'>[原创]</font> 大数据学习笔记(2)-Hadoop</title>
  <meta name="description" content="Welcome to geek's world!">
  <meta name="author" content="Yinan Wu">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Yinan's Blog">
  <meta name="twitter:description" content="Welcome to geek's world!">

  <meta property="og:type" content="article">
  <meta property="og:title" content="Yinan's Blog">
  <meta property="og:description" content="Welcome to geek's world!">

  <link rel="apple-touch-icon" sizes="57x57" href="/images/favicons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/images/favicons/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/favicons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/favicons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/images/favicons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/favicons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/images/favicons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-194x194.png" sizes="194x194">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/images/favicons/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="/images/favicons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <link rel="shortcut icon" href="/images/favicons/favicon.ico">
  <meta name="msapplication-TileColor" content="#ffc40d">
  <meta name="msapplication-TileImage" content="/images/favicons/mstile-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)-Hadoop/">
  <link rel="alternate" type="application/rss+xml" title="Yinan's Blog" href="/feed.xml">

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
</head>


  <body>
    <span class="mobile btn-mobile-menu">
  <i class="icon icon-list btn-mobile-menu__icon"></i>
  <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
</span>
  
<header class="panel-cover" style="background-image: url(/images/cover.jpg)">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <a href="/" title="link to home of Yinan's Blog">
          <img src="/images/profile.jpg" class="user-image" alt="My Profile Photo">
          <h1 class="panel-cover__title panel-title">Yinan's Blog</h1>
        </a>
        <hr class="panel-cover__divider">
        <p class="panel-cover__description">Welcome to geek's world!</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary">

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/me/" title="link to Yinan's Blog about me" class="blog-button">Me</a></li>
            </ul>
          </nav>

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/#blog" title="link to Yinan's Blog blog" class="blog-button">Blog</a></li>
            </ul>
          </nav>

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/tags/" title="link to Yinan's Blog tags" class="blog-button">Tags</a></li>
            </ul>
          </nav>

          <nav class="cover-navigation navigation--social">
            <ul class="navigation">
          
            
              <!-- Twitter -->
              <li class="navigation__item">
                <a href="http://twitter.com/wuyinan0126" title="@wuyinan0126 on Twitter" target="_blank">
                  <i class="icon icon-social-twitter"></i>
                  <span class="label">Twitter</span>
                </a>
              </li>
            

            
              <!-- Facebook -->
              <li class="navigation__item">
                <a href="http://fb.me/wuyinan0126" title="wuyinan0126 on Facebook" target="_blank">
                  <i class="icon icon-social-facebook"></i>
                  <span class="label">Facebook</span>
                </a>
              </li>
            

            
              <!-- LinkedIn -->
              <li class="navigation__item">
                <a href="https://www.linkedin.com/in/wuyinan0126" title="wuyinan0126 on LinkedIn" target="_blank">
                  <i class="icon icon-social-linkedin"></i>
                  <span class="label">LinkedIn</span>
                </a>
              </li>
            

            
              <!-- GitHub -->
              <li class="navigation__item">
                <a href="https://www.github.com/wuyinan0126" title="wuyinan0126 on GitHub" target="_blank">
                  <i class="icon icon-social-github"></i>
                  <span class="label">GitHub</span>
                </a>
              </li>
            

            
              <!-- Email -->
              <li class="navigation__item">
                <a href="mailto:wuyinan0126@gmail.com" title="Email wuyinan0126@gmail.com" target="_blank">
                  <i class="icon icon-mail"></i>
                  <span class="label">Email</span>
                </a>
              </li>
            

            <!-- RSS -->
            <!-- <li class="navigation__item">
              <a href="/feed.xml" title="Subscribe" target="_blank">
                <i class="icon icon-rss"></i>
                <span class="label">RSS</span>
              </a>
            </li> -->
          
            </ul>
          </nav>

        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>


    <div class="content-wrapper">
      <div class="content-wrapper__inner">
        <article class="post-container post-container--single">
  <header class="post-header">
    <div class="post-meta">
      <time datetime="1 Dec 2016" class="post-meta__date date">1 Dec 2016</time> &#8226; <span class="post-meta__tags">on <a href="/tags/#原创">原创</a> <a href="/tags/#大数据">大数据</a> </span>
    </div>
    <h1 class="post-title"><font color='red'>[原创]</font> 大数据学习笔记(2)-Hadoop</h1>
  </header>

  <section class="post">
    <p><em>简单学习Hadoop相关知识，并在集群上搭建Hadoop HA平台。包括介绍MapReduce计算框架、HDFS文件系统、YARN资源调度与管理系统、MapReduce和Yarn的参数配置等</em></p>

<h2 id="hadoop">Hadoop</h2>
<hr />

<h3 id="mapreduce">MapReduce</h3>
<hr />

<p>大数据计算中最常见的一种计算方式是<strong>批处理</strong>。2004年Google发表了MapReduce计算范型和框架论文，这是一种构建在大规模PC之上的批处理计算框架，也是一种分布式计算模型，获得了极为广泛的应用。</p>

<p>MapReduce和传统的并行数据库系统(MPP)相比，更适合<strong>非结构化数据的ETL处理</strong>(将数据从来源端经过抽取(extract)、转换(transform)、加载(load)至目的端的过程)，且其更具有<strong>扩展性和容错性</strong>，但单机处理效率低。</p>

<p>MapReduce计算提供了简洁的编程接口，<strong>输入和输出均是Key/Value键值对</strong>，只需根据业务逻辑实现Map和Reduce函数即可完成大规模数据的并行批处理任务。</p>

<ul>
  <li>Map函数以Key/Value作为输入，经逻辑计算产生若干仍以Key/Value形式表达的中间数据。计算框架自动将中间数据中具有相同Key值的记录聚在一起，传递给Reduce函数作为输入</li>
  <li>Reduce函数以Map阶段传递过来的某个Key值及其对应的若干Value值作为输入，对这些Value进行逻辑计算，生成Key/Value即计算结果</li>
</ul>

<p>以上为MapReduce的简单介绍，更为详细的MapReduce计算模型学习笔记请参看我的另一篇博文：<a href="https://wuyinan0126.github.io/2016/大数据学习笔记(3)-计算模型/">大数据学习笔记(3)-计算模型</a></p>

<hr />

<h3 id="hdfs">HDFS</h3>
<hr />

<p>HDFS的全称是”Hadoop Distributed File System”，是Hadoop中的大规模分布式文件系统。它最初是Yahoo模仿Goole的GFS(Google File System)开发的开源系统，因此在整体架构上和GFS大致相同。与GFS一样，HDFS适合存储<strong>大文件</strong>并为之提供高吞吐量的<strong>顺序读写</strong>访问，不太适合大量随机读的应用场景，也不适合储存大量的小文件的应用场景。</p>

<p>在Hadoop1.x中，HDFS可以被看作简化版的开源GFS系统，因为其在实现时绕开了一些GFS的复杂方案而采用简化方案，因此限制了性能。在这个系列的版本中，存在的问题包括：单点失效和水平扩展不佳。单点失效会导致整个集群不可用，而水平扩展不佳会导致整个文件系统管理文件数目容易达到上限，所以集群规模达到一定程度就无法扩展。</p>

<p>在Hadoop2.x中，提出了高可用方案(High Availability, HA)和NameNode联盟(NameNode Federation)。其中高可用是为了解决单点失效问题，而NameNode联盟是为了解决整个系统的水平扩展问题。</p>

<p>以上为HDFS的简单介绍，更为详细的HDFS学习笔记请参看我的另一篇博文：<a href="https://wuyinan0126.github.io/2016/大数据学习笔记(4)-分布式文件系统/">大数据学习笔记(4)-分布式文件系统</a></p>

<hr />

<h3 id="yarn">YARN</h3>
<hr />

<p>YARN的全称是”Yet Another Resource Negotiator”，是一个独立的<strong>资源调度与管理系统</strong>。</p>

<p>在Hadoop1.x中，所有任务的<strong>资源管理</strong>以及<strong>生命周期管理</strong>都由全局唯一的JobTracker负责，造成其功能繁复，限制了系统的可扩展性。同时JobTracker还存在单点失效的问题，一旦JobTracker故障，整个Hadoop集群将崩溃。</p>

<p>在Hadoop2.x中，将<strong>资源管理</strong>与<strong>任务生命周期管理</strong>功能分离，由ResourceManager(RM)负责资源管理，由ApplicationMaster(AM)负责任务所需资源申请管理与任务生命周期管理。这样的好处除了<strong>增强系统的可扩展性</strong>，<strong>解决JobTracker单点故障问题</strong>，还<strong>可以部署除MapReduce计算框架外的其他计算框架，共享底层硬件资源</strong>。</p>

<p>以上为YARN的简单介绍，更为详细的YARN学习笔记请参看我的另一篇博文：<a href="https://wuyinan0126.github.io/2016/大数据学习笔记()-资源调度和管理系统/">大数据学习笔记()-资源调度和管理系统</a></p>

<hr />

<h3 id="mapreduceyarn">MapReduce和Yarn的参数配置</h3>
<hr />

<p>Yarn中资源的最小单位是容器（Container）。容器是一个Yarn的JVM进程，在MapReduce中，AM服务、map和reduce任务都是运行在一个容器中。可以通过<a href="http://{RM_IP}:8088/cluster/scheduler">http://{RM_IP}:8088/cluster/scheduler</a>来查看正在运行的容器的状态</p>

<ul>
  <li>
    <p>在NM中，可以优化的参数有：</p>

    <ul>
      <li>yarn.node-manager.resource.memory-mb</li>
    </ul>

    <p>此参数为物理机可用于分配给容器的<strong>物理内存</strong>量，注意需要给物理机留出部分资源给操作系统使用，建议为总物理内存的80%~90%，默认为8192。在不同硬件配置的节点中，该值需要根据物理机实际配置来写</p>

    <ul>
      <li>yarn.node-manager.resource.vcore</li>
    </ul>

    <p>同理，为物理机可用于分配给容器的虚拟CPU数（我理解为线程数），建议为物理CPU核数。默认为8，如果节点CPU核数不够8个，则需要调减小这个值，YARN不会智能的探测节点的物理CPU总数。在不同硬件配置的节点中，该值需要根据物理机实际配置来写</p>

    <ul>
      <li>yarn.nodemanager.vmem-pmem-ratio</li>
    </ul>

    <p>此参数是指当任务每使用1MB<strong>物理内存</strong>，最多可使用默认为2.1MB的<strong>虚拟内存</strong>量。在JVM中，使用的内存分为虚拟内存和物理内存。JVM中所有存在内存中的对象都是虚拟内存，但在实际运行中只有一部分是实际加载在物理内存中的</p>
  </li>
  <li>
    <p>在RM中，可以优化的参数有：</p>

    <ul>
      <li>yarn.scheduler.minimum-allocation-mb</li>
    </ul>

    <p>当应用程序向RM申请容器时，RM按照此<strong>物理内存</strong>量为单位分配给容器，默认为1024。例如，我们设置分配的最小单位为2GB，则RM分配出来的容器内存一定是2G的倍数。假设现在有一个程序向RM申请3.1G的内存，则RM会分配给它一个4GB的容器去执行</p>

    <ul>
      <li>yarn.scheduler.maximum-allocation-mb</li>
    </ul>

    <p>此参数限定了RM可以分配给一个容器的最大<strong>物理内存</strong>量，默认为8192。假设应用程序向RM申请的资源超过了这个值，RM会直接拒绝这个请求</p>

    <ul>
      <li>yarn.scheduler.maximum-allocation-vcores</li>
    </ul>

    <p>同理，RM可以分配给一个容器的最多虚拟CPU个数，默认为32</p>
  </li>
  <li>
    <p>在MapReduce中，可以优化的参数有：</p>

    <ul>
      <li>mapreduce.map.memory.mb</li>
      <li>mapreduce.reduce.memory.mb</li>
    </ul>

    <p>用于AM向Yarn申请用于map或reduce task的容器时默认使用的<strong>物理内存</strong>值，其值应该在RM中的一个容器可分配的最大最小内存之间，默认为1024。这个值是全局的，因此需要根据某个job的map或reduce task需要使用的内存量，在程序中覆盖这些参数</p>

    <ul>
      <li>mapreduce.map.java.opts</li>
      <li>mapreduce.reduce.java.opts</li>
    </ul>

    <p>因为Yarn容器可以理解为一个JVM，这两个值主要是为需要运行JVM程序（java、scala等）准备的，用于设置JVM进程的堆大小。这个值应该比上面的物理内存值小（因为JVM除了堆还有别的对象需要占用内存），一般设置为上面值的0.75倍，如果JVM进程在执行中，堆上的对象申请的内存超过这个值，就会抛出OutOfMemory异常</p>
  </li>
</ul>

<p>举个栗子：</p>

<ul>
  <li>yarn.nodemanager.vmem-pmem-ratio = 2.1</li>
  <li>yarn.scheduler.minimum-allocation-mb = 1024</li>
  <li>mapreduce.map.memory.mb = 1536</li>
  <li>mapreduce.map.java.opts = 1024</li>
</ul>

<p>此时，由于mapreduce.map.memory.mb=1536，因此AM将向RM申请一个2048M内存的容器，当map task使用的物理内存量大于2048M时或使用的虚拟内存量大于2048*2.1=3225.6M时将被杀死。容器中有1024M内存用作JVM堆内存，其余内存为非堆内存。当java、scala等进程在堆内存中申请的内存超过1024M，将抛出OutOfMemory异常</p>

<hr />

<h4 id="section">实用工具</h4>
<hr />

<p>配置内存参数可以使用<a href="https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.6/bk_installing_manually_book/content/determine-hdp-memory-config.html">yarn-util.py</a>进行参考</p>

<div class="highlighter-rouge"><pre class="highlight"><code>	# 查看每个物理CPU中core的个数(即核数)
	$ cat /proc/cpuinfo| grep "cpu cores"| uniq
	4
	$ python yarn-utils.py -c 4 -m 16 -d 1 -k True
	 Using cores=4 memory=16GB disks=1 hbase=True
	 Profile: cores=4 memory=12288MB reserved=4GB usableMem=12GB disks=1
	 Num Container=3
	 Container Ram=4096MB
	 Used Ram=12GB
	 Unused Ram=4GB
	 yarn.scheduler.minimum-allocation-mb=4096
	 yarn.scheduler.maximum-allocation-mb=12288
	 yarn.nodemanager.resource.memory-mb=12288
	 mapreduce.map.memory.mb=4096
	 mapreduce.map.java.opts=-Xmx3276m
	 mapreduce.reduce.memory.mb=4096
	 mapreduce.reduce.java.opts=-Xmx3276m
	 yarn.app.mapreduce.am.resource.mb=4096
	 yarn.app.mapreduce.am.command-opts=-Xmx3276m
	 mapreduce.task.io.sort.mb=1638
</code></pre>
</div>

<hr />

<h2 id="hadoop-ha273">安装Hadoop HA（版本2.7.3）</h2>
<hr />

<h3 id="section-1">准备工作</h3>
<hr />

<ol>
  <li>
    <p>按照<a href="https://wuyinan0126.github.io/2016/大数据学习笔记(1)-Overview/">大数据学习笔记(1)-Overview</a>做好部署前提准备</p>
  </li>
  <li>
    <p>下载Hadoop二进制包，并分发到所有节点，并解压至/opt/:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible all -m copy -a 'src=/home/cat/cat/hadoop-2.7.3.tar.gz dest=/home/cat/cat/'
 $ ansible all -a 'tar -zxvf /home/cat/cat/hadoop-2.7.3.tar.gz -C /opt/'
</code></pre>
    </div>
  </li>
  <li>
    <p>创建数据文件夹、日志文件夹和myid文件:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible all -a 'mkdir -p /opt/hadoop-2.7.3/var/name'
 $ ansible all -a 'mkdir -p /opt/hadoop-2.7.3/var/data'
 $ ansible all -a 'mkdir -p /opt/hadoop-2.7.3/var/tmp'
 $ ansible all -a 'mkdir -p /opt/hadoop-2.7.3/var/journal'
</code></pre>
    </div>
  </li>
</ol>

<hr />

<h3 id="hadoop-1">配置Hadoop</h3>
<hr />

<ol>
  <li>
    <p>etc/hadoop/core-site.xml</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;      
     &lt;name&gt;fs.defaultFS&lt;/name&gt;      
     &lt;value&gt;hdfs://cats&lt;/value&gt; 
     &lt;description&gt;默认的HDFS路径，与hdfs-site.xml中的配置相关。当有多个HDFS集群存在时，用此名字指定集群&lt;/description&gt; 
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;     
     &lt;value&gt;file:///opt/hadoop-2.7.3/var/tmp&lt;/value&gt; 
     &lt;description&gt;NameNode、DataNode、JournalNode等存放数据的公共目录，也可以自己单独指定这三类节点的目录&lt;/description&gt;
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;      
     &lt;value&gt;10.2.2.141:2181,10.2.2.142:2181,10.2.2.143:2181&lt;/value&gt;
     &lt;description&gt;这里是ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点&lt;/description&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;    
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/hadoop-env.sh</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_PID_DIR=/opt/hadoop-2.7.3/var/tmp
 export HADOOP_SECURE_DN_PID_DIR=/opt/hadoop-2.7.3/var/tmp
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/hdfs-site.xml</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.name.dir&lt;/name&gt;
     &lt;value&gt;file:///opt/hadoop-2.7.3/var/name&lt;/value&gt;
     &lt;description&gt;NameNode存储命名空间和操作日志相关的元数据信息的本地文件系统路径&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.data.dir&lt;/name&gt;
     &lt;value&gt;file:///opt/hadoop-2.7.3/var/data&lt;/value&gt;
     &lt;description&gt;DataNode节点存储HDFS文件的本地文件系统路径&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.replication&lt;/name&gt;  
     &lt;value&gt;3&lt;/value&gt;
     &lt;description&gt;指定DataNode存储block的副本数量。默认值是3个，不大于DataNode个数即可&lt;/description&gt;
   &lt;/property&gt;  
   &lt;property&gt;
     &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;      
     &lt;name&gt;dfs.nameservices&lt;/name&gt;    
     &lt;value&gt;cats&lt;/value&gt; 
     &lt;description&gt;集群的逻辑名称，自己任意取&lt;/description&gt;     
   &lt;/property&gt;  
   &lt;property&gt;  
     &lt;name&gt;dfs.ha.namenodes.cats&lt;/name&gt;  
     &lt;value&gt;catk,catq&lt;/value&gt;
     &lt;description&gt;两个namenode的逻辑名称，自己任意取&lt;/description&gt; 
   &lt;/property&gt;  
   &lt;property&gt;  
     &lt;name&gt;dfs.namenode.rpc-address.cats.catk&lt;/name&gt;  
     &lt;value&gt;10.2.2.141:8020&lt;/value&gt;  
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;dfs.namenode.http-address.cats.catk&lt;/name&gt;      
     &lt;value&gt;10.2.2.141:50070&lt;/value&gt;      
   &lt;/property&gt;      
   &lt;property&gt;      
     &lt;name&gt;dfs.namenode.rpc-address.cats.catq&lt;/name&gt;      
     &lt;value&gt;10.2.2.142:8020&lt;/value&gt;      
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;dfs.namenode.http-address.cats.catq&lt;/name&gt;      
     &lt;value&gt;10.2.2.142:50070&lt;/value&gt;     
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.namenode.servicerpc-address.cats.catk&lt;/name&gt;  
     &lt;value&gt;10.2.2.141:53310&lt;/value&gt;  
   &lt;/property&gt;    
   &lt;property&gt;  
     &lt;name&gt;dfs.namenode.servicerpc-address.cats.catq&lt;/name&gt;  
     &lt;value&gt;10.2.2.142:53310&lt;/value&gt;  
   &lt;/property&gt;
   &lt;property&gt;    
     &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;    
     &lt;value&gt;true&lt;/value&gt; 
     &lt;description&gt;指定cats是否自动故障恢复，当NameNode出故障时，是否自动切换到另一台NameNode&lt;/description&gt;
   &lt;/property&gt;     
   &lt;!--指定JournalNode --&gt;  
   &lt;property&gt;  
     &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;       
     &lt;value&gt;qjournal://10.2.2.144:8485;10.2.2.145:8485;10.2.2.146:8485;10.2.2.147:8485;10.2.2.148:8485;10.2.2.149:8485;10.2.2.150:8485;10.2.2.151:8485;10.2.2.152:8485/cats&lt;/value&gt; 
     &lt;description&gt;两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。standby状态的NameNode有能力读取JNs中的变更信息，并且一直监控editl og的变化，把变化应用于自己的命名空间。standby可以确保在集群出错时，命名空间状态已经完全同步了。指定cats的两个NameNode共享edits文件目录时，使用的JournalNode集群信息，必须是奇数个，至少3个。&lt;/description&gt;  
   &lt;/property&gt;  
   &lt;property&gt;  
     &lt;name&gt;dfs.client.failover.proxy.provider.cats&lt;/name&gt;       
     &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
     &lt;description&gt;指定active出故障时，哪个实现类负责执行故障切换&lt;/description&gt;  
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;      
     &lt;value&gt;/opt/hadoop-2.7.3/var/journal&lt;/value&gt;      
   &lt;/property&gt;
   &lt;property&gt;      
     &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;      
     &lt;value&gt;sshfence&lt;/value&gt;  
     &lt;description&gt;主备架构解决单点故障问题时，必须要认真解决的是脑裂问题，即出现两个master同时对外提供服务，导致系统处于不一致状态，可能导致数据丢失等潜在问题。在HDFS HA中，JournalNode只允许一个NameNode写数据，不会出现两个Active NameNode的问题，但是，当主备切换时，之前的Active NameNode可能仍在处理客户端的RPC请求，为此，需要增加隔离机制（ fencing）将之前的Active NameNode杀死。HDFS允许用户配置多个隔离机制，当发生主备切换时，将顺次执行这些隔离机制，直到一个返回成功。隔离机制包括shell和sshfence，sshfence通过ssh登录到前一个ActiveNameNode并将其杀死。为了让该机制成功执行，需配置免密码ssh登陆&lt;/description&gt;
   &lt;/property&gt;  
   &lt;property&gt;      
     &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;      
     &lt;value&gt;/home/cat/.ssh/id_rsa&lt;/value&gt;   
   &lt;/property&gt;  
   &lt;property&gt;  
     &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;  
     &lt;value&gt;5000&lt;/value&gt;  
     &lt;description&gt;设置一个超时时间，一旦ssh超过该时间，则认为执行失败&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;  
     &lt;value&gt;20&lt;/value&gt; 
     &lt;description&gt;设定namenode server threads的数量，这些threads會用RPC跟其他的datanodes沟通。当datanodes数量太多时会发現很容易出現RPC timeout，解決方法是提升网络速度或提高这个值，但要注意的是thread数量多也表示namenode消耗的内存也随着增加&lt;/description&gt; 
   &lt;/property&gt; 
   &lt;!-- 用户权限管理 --&gt;
   &lt;property&gt;  
     &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;  
     &lt;value&gt;true&lt;/value&gt;
     &lt;description&gt;权限管理&lt;/description&gt;
   &lt;/property&gt;  
   &lt;property&gt;
     &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
     &lt;description&gt;权限访问控制列表&lt;/description&gt;
   &lt;/property&gt;
   &lt;!-- 用户权限管理 --&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/mapred-env.sh</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_MAPRED_PID_DIR=/opt/hadoop-2.7.3/var/tmp
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/mapred-site.xml</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;  
     &lt;value&gt;yarn&lt;/value&gt;  
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;  
     &lt;value&gt;1536&lt;/value&gt;  
     &lt;description&gt;每个Map Task需要的虚拟内存限制，例如需要1536MB内存时，yarn将分配一个2倍最小容器内存2048M单位的容器，这个值可以在程序中设定被覆盖&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;  
     &lt;value&gt;1536&lt;/value&gt;  
     &lt;description&gt;每个Reduce Task需要的虚拟内存限制，一般为Map的两倍，这个值可以在程序中设定被覆盖&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;  
     &lt;value&gt;-Xmx1024m -XX:MaxPermSize=64m&lt;/value&gt;  
     &lt;description&gt;设置Map Task的JVM的堆空间大小，因为Map Task分配了4096MB内存，其中3596MB内存给了java、scala等程序，这个值应该比上面的task的虚拟内存值小（因为jvm除了heap还有别的对象需要占用内存），如果jvm进程在执行中heap上的对象占用内存超过这个值， 则会抛出OutOfMemory Exception，这个值可以在程序中设定被覆盖&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt;  
     &lt;value&gt;-Xmx1024m -XX:MaxPermSize=64m&lt;/value&gt;  
     &lt;description&gt;设置Reduce Task的JVM的堆空间大小，这个值可以在程序中设定被覆盖&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;mapreduce.task.io.sort.mb&lt;/name&gt;  
     &lt;value&gt;512&lt;/value&gt;  
     &lt;description&gt;任务内部排序缓冲区大小&lt;/description&gt;
   &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/slaves</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> # datanode的ip地址
 10.2.2.143...152
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/yarn-env.sh</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/opt/jdk1.8.0_121
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/yarn-site.xml</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;!-- ResourceManager相关配置参数 --&gt;
   &lt;property&gt;
   	&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
   	&lt;value&gt;1024&lt;/value&gt;
   	&lt;description&gt;每个Task申请容器的最小内存单位，默认1024MB，例如Task需要1025M内存时会分配2*1024M内存的容器&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
     &lt;value&gt;12288&lt;/value&gt;
     &lt;discription&gt;单个任务可申请容器的最大内存，默认8192MB。由于Yarn集群还需要跑Spark的任务，而Spark的Worker内存相对需要大些，所以需要调大单个任务的最大内存&lt;/discription&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;
     &lt;value&gt;8&lt;/value&gt;
     &lt;discription&gt;单个任务可申请容器的最大虚拟核数，默认8个核&lt;/discription&gt;
   &lt;/property&gt;
   &lt;property&gt;      
     &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;      
     &lt;value&gt;10.2.2.141&lt;/value&gt;  
     &lt;description&gt;resourcemanager只有一个，设置它的主机位置&lt;/description&gt;
   &lt;/property&gt;  
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
     &lt;value&gt;10.2.2.141:8032&lt;/value&gt;
     &lt;description&gt;ResourceManager对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
     &lt;value&gt;10.2.2.141:8030&lt;/value&gt;
     &lt;description&gt;ResourceManager对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
     &lt;value&gt;10.2.2.141:8031&lt;/value&gt;
     &lt;description&gt;ResourceManager对NodeManager暴露的地址。NodeManager通过该地址向ResourceManager汇报心跳，领取任务等&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
     &lt;value&gt;10.2.2.141:8033&lt;/value&gt;
     &lt;description&gt;ResourceManager对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
     &lt;value&gt;10.2.2.141:8088&lt;/value&gt;
     &lt;description&gt;ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息&lt;/description&gt;
   &lt;/property&gt;
   &lt;!-- NodeManager相关配置参数 --&gt;
   &lt;property&gt;
   	&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
   	&lt;value&gt;12288&lt;/value&gt;
   	&lt;description&gt;NodeManager总的可用物理内存，必须给物理机留一些内存和计算资源给到操作系统使用，不能用光，16G*85%&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
   	&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
   	&lt;value&gt;8&lt;/value&gt;
   	&lt;description&gt;该节点上YARN可使用的虚拟CPU个数，默认是8，注意，目前推荐将该值设值为与物理CPU核数数目相同。如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
   	&lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
   	&lt;value&gt;2.1&lt;/value&gt;
   	&lt;description&gt;当map或reduce任务使用内存超过mapreduce.map.memory.mb或mapreduce.reduce.memory.mb时，将增加内存至2.1倍的mapreduce.reduce.memory.mb或者mapreduce.map.memory.mb&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;  
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;
     &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
     &lt;value&gt;	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;
     &lt;description&gt;启用的资源调度器主类。目前可用的有FIFO、Capacity Scheduler和Fair Scheduler&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
     &lt;value&gt;/tmp/logs&lt;/value&gt;
   &lt;/property&gt;
   &lt;!-- ApplicationMaster相关配置参数 --&gt;
   &lt;property&gt;  
     &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;
     &lt;value&gt;1536&lt;/value&gt;
     &lt;description&gt;MR ApplicationMaster占用的内存量&lt;/description&gt;
   &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;yarn.app.mapreduce.am.command-opts&lt;/name&gt;
     &lt;value&gt;-Xmx1024m -XX:MaxPermSize=64m&lt;/value&gt;
   &lt;/property&gt;
   &lt;!-- historyserver configue start --&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
   &lt;/property&gt;
   &lt;!-- historyserver configue end --&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>分发Hadoop配置文件</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible slave -m copy -a 'src=/opt/hadoop-2.7.3/etc/hadoop/ dest=/opt/hadoop-2.7.3/etc/hadoop/'
</code></pre>
    </div>
  </li>
</ol>

<hr />

<h3 id="hadoop-2">启动Hadoop</h3>
<hr />

<ol>
  <li>
    <p>确保Zookeeper已经启动：</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible zookeeper -a '/opt/zookeeper-3.4.9/bin/zkServer.sh start'
</code></pre>
    </div>
  </li>
  <li>
    <p>(在主节点)格式化集群</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hdfs zkfc -formatZK
</code></pre>
    </div>
  </li>
  <li>
    <p>(在主节点)检验集群是否格式化，ls /是否出现了hadoop-ha</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ zkCli.sh
 [zk: localhost:2181(CONNECTED) 0] ls /
 [zookeeper, hadoop-ha]
</code></pre>
    </div>
  </li>
  <li>
    <p>(在主节点)启动hadoop集群</p>

    <ol>
      <li>
        <p>启动所有journalnode</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop-daemons.sh start journalnode
</code></pre>
        </div>
      </li>
      <li>
        <p>在cat1格式化namenode，输出日志中是否出现successfully formatted</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> cat@cat1:~$ hdfs namenode -format
</code></pre>
        </div>
      </li>
      <li>
        <p>启动cat1中的namenode</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> cat@cat1:~$ hadoop-daemon.sh start namenode
</code></pre>
        </div>
      </li>
      <li>
        <p>在cat2中同步namenode数据</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> cat@cat2:~$ hdfs namenode -bootstrapStandby
</code></pre>
        </div>
      </li>
      <li>
        <p>启动cat2中的namenode</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> cat@cat2:~$ hadoop-daemon.sh start namenode
</code></pre>
        </div>
      </li>
      <li>
        <p>启动所有datanode</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop-daemons.sh start datanode
</code></pre>
        </div>
      </li>
      <li>
        <p>启动yarn</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ start-yarn.sh
</code></pre>
        </div>
      </li>
      <li>
        <p>在cat1和cat2中都启动ZooKeeperFailoverController（此时cat1变为active，cat2为standby）</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible namenode -a '/opt/hadoop-2.7.3/sbin/hadoop-daemon.sh start zkfc'
</code></pre>
        </div>
      </li>
    </ol>
  </li>
</ol>

<hr />

<h3 id="hadoop-3">测试Hadoop</h3>
<hr />

<ol>
  <li>
    <p>使用jps查看各节点起的进程</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ ansible all -a '/opt/jdk1.8.0_121/bin/jps'

 cat1: QuorumPeerMain, DFSZKFailoverController, NameNode, ResourceManager
 cat2: QuorumPeerMain, DFSZKFailoverController, NameNode
 cat3: QuorumPeerMain, JournalNode, DataNode, NodeManager
 cat4-12: JournalNode, DataNode, NodeManager
</code></pre>
    </div>
  </li>
  <li>
    <p>查看<a href="http://10.2.2.141:50070/">http://10.2.2.141:50070/</a>中cat1是否为active，查看<a href="http://10.2.2.142:50070/">http://10.2.2.142:50070/</a>中cat2是否为standby</p>
  </li>
  <li>
    <p>(在主节点)运行wordcount例子:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop fs -mkdir /test
 $ hadoop fs -mkdir /test/input
 $ hadoop fs -put ./words.txt /test/input
 $ hadoop jar /opt/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /test/input/ /test/output
 $ hadoop fs -cat /test/output/part-r-00000
</code></pre>
    </div>
  </li>
</ol>

<hr />

<h3 id="hadoop-4">创建Hadoop用户</h3>
<hr />

<ol>
  <li>
    <p>创建用户组</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ sudo groupadd admire
</code></pre>
    </div>
  </li>
  <li>
    <p>创建用户</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ sudo useradd -g admire -d /home/wyn -m wyn -s /bin/bash
 $ sudo passwd wyn
 $ hadoop fs -mkdir /user/wyn
 $ hadoop fs -chown -R wyn:supergroup /user/wyn
 $ hadoop fs -chmod 700 /user/wyn
</code></pre>
    </div>
  </li>
</ol>

<hr />

<h2 id="spark-on-yarnhttpswuyinan0126githubio20176-spark">下一步：<a href="(https://wuyinan0126.github.io/2017/大数据学习笔记(6)-Spark/)">安装Spark on Yarn</a></h2>

<hr />


    <div class="page_navigation">
    
      <a class="prev" href="/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)-Overview/">&laquo; <font color='red'>[原创]</font> 大数据学习笔记(1)-Overview</a>
    
    
      <a class="next" href="/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/"><font color='red'>[原创]</font> 大数据学习笔记(3)-计算模型 &raquo;</a>
    
    </div>

  </section>
  <section id="disqus_thread"></section><!-- /#disqus_thread -->
</article>

    <div id="disqus_thread"></div>
    <script>

    var disqus_shortname = 'wuyinan0126';

    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */

    var disqus_config = function () {
        this.page.url = 'https://wuyinan0126.github.io/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)-Hadoop/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = '/2016/大数据学习笔记(2)-Hadoop'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        this.page.title = '/2016/大数据学习笔记(2)-Hadoop';
    };

    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        s.src = '//wuyinan0126.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  

      </div>

      <footer class="footer">
  <span class="footer__copyright">&copy; 2017 Yinan Wu. All rights reserved.</span>
</footer> 

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-84272870-1', 'auto');
  ga('send', 'pageview');

</script>

    </div>
  </body>
</html>