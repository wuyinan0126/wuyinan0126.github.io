<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yinan&#39;s Blog</title>
    <description>Welcome to geek&#39;s world!</description>
    <link>https://wuyinan0126.github.io//</link>
    <atom:link href="https://wuyinan0126.github.io//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 02 Apr 2017 22:37:07 +0800</pubDate>
    <lastBuildDate>Sun, 02 Apr 2017 22:37:07 +0800</lastBuildDate>
    <generator>Jekyll v3.0.2</generator>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; TAP平台搭建和使用笔记</title>
        <description>&lt;p&gt;&lt;em&gt;在OpenStack上搭建和使用Trusted Analytics Platform，包括OpenStack的搭建、本地DNS服务的搭建、本地代理服务器的搭建、疑难问题的筛查和解决&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;tap&quot;&gt;TAP平台&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;TAP是由Intel开发的一款开源软件，它可以加速创建以大数据分析为驱动的本地云应用。它通过在公有云和私有云提供一个分享的、灵活的数据分析环境，使得企业的开发者、数据科学家、云服务提供商和系统集成商更容易地合作&lt;/p&gt;

&lt;p&gt;TAP是一个多租户的平台，旨在简化和加速端到端的分析应用程序的交付。它采用松耦合的分层架构，使得在定制解决方式时具有较大的灵活性。它由数据层(Data Layer)、分析层(Analytics Layer)和应用层(Application Layer)构成，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2017-03-09-1.png&quot; alt=&quot;TAP架构图&quot; title=&quot;TAP架构图&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;openstack&quot;&gt;OpenStack搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;TAP的OpenStack版本要求：Mirantis Opentack 7.0 for Kilo 2015.1.0&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;TAP的硬件要求：
    &lt;ul&gt;
      &lt;li&gt;1个fuel server: 4核CPU，4GB内存，1 Gbps以太网，128GB SAS硬盘&lt;/li&gt;
      &lt;li&gt;1个Controller节点: 2个6核CPU，24GB内存，1TB RAID1&lt;/li&gt;
      &lt;li&gt;1个Storage节点: 1个4核CPU，12GB内存，500GB RAID1&lt;/li&gt;
      &lt;li&gt;6个Compute节点（每个）:双socket CPU，每个socket至少4核，64GB内存，256GB SSD&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;实际硬件：
    &lt;ul&gt;
      &lt;li&gt;1个fuel server: 双网口，网口1配置VLAN&lt;/li&gt;
      &lt;li&gt;1个Controller + Cinder Storage节点：双网口，网口1配置VLAN，2个8核CPU，48GB内存，900GB SATA&lt;/li&gt;
      &lt;li&gt;4个Compute + Cinder Storage节点（每个）：双网口，网口1配置VLAN，4个16核CPU，128G内存，0.8~3.6TB RAID5&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;网络配置：
    &lt;ul&gt;
      &lt;li&gt;公开：
        &lt;ul&gt;
          &lt;li&gt;IP范围：10.2.14.3～10.2.14.21&lt;/li&gt;
          &lt;li&gt;CIDR：10.2.14.0/24&lt;/li&gt;
          &lt;li&gt;不使用VLAN标记&lt;/li&gt;
          &lt;li&gt;网关：10.2.14.1&lt;/li&gt;
          &lt;li&gt;Floating IP范围：10.2.14.22～10.2.14.79&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;存储：
        &lt;ul&gt;
          &lt;li&gt;VLAN：991&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;管理：
        &lt;ul&gt;
          &lt;li&gt;VLAN：992&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Neutron L2配置：
        &lt;ul&gt;
          &lt;li&gt;VLAN ID 范围：993～999&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OpenStack配置：
    &lt;ul&gt;
      &lt;li&gt;Repositories：修改ubuntu的软件源（如阿里云的源）：http://mirrors.aliyun.com/ubuntu/&lt;/li&gt;
      &lt;li&gt;Public network assignment：给所有节点分配所有public网络&lt;/li&gt;
      &lt;li&gt;Storage：Cinder LVM over iSCSI for volumes&lt;/li&gt;
      &lt;li&gt;Public TLS：不使用HTTPS和TLS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dns&quot;&gt;本地DNS服务的搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;由于TAP平台需要TAP Domain，之前使用xip.io不稳定且解析速度慢，因此搭建本地DNS服务器（IP为10.2.3.114）。我的TAP Domain为tap.wyn，需要将所有子域名解析为10.2.14.28&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;建立Ubuntu Server虚拟机&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装bind9：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install bind9
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;添加一个zone：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo cp /etc/bind/db.local /etc/bind/db.tap.wyn
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/named.conf.local：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; zone &quot;tap.wyn&quot; {
   type master;
   file &quot;/etc/bind/db.tap.wyn&quot;;
 };
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/db.tap.wyn：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $TTL    604800
 @       IN      SOA     tap.wyn. root.tap.wyn. (
                               2         ; Serial
                          604800         ; Refresh
                           86400         ; Retry
                         2419200         ; Expire
                          604800 )       ; Negative Cache TTL
 ;
 @       IN      NS      10.2.3.114.		# 替换为你的本地dns服务器（即本机）地址
 @       IN      A       10.2.14.28		# 使其能解析tap.wyn为10.2.14.28
 *       IN      A       10.2.14.28		# 使其能解析*.tap.wyn为10.2.14.28
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/named.conf.options：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; options {
         directory &quot;/var/cache/bind&quot;;
         forwarders {				# 本地解析不了时，给以下DNS服务器解析
                 202.112.128.51;
                 114.114.114.114;
                 0.0.0.0;
         };
         dnssec-validation auto;
         auth-nxdomain no;    
         listen-on-v6 { any; };
         allow-query { any; };			# 允许任何主机用该DNS服务器查询
 };
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编写开机启动脚本：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; sudo /etc/init.d/bind9 restart
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试：
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;修改本机/etc/resolv.conf，在所有nameserver上加入：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  nameserver 10.2.3.114			# 替换为你的本地dns服务器（即本机）地址
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;测试：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ host tap.wyn
  $ host a.tap.wyn
  $ host baidu.com
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section&quot;&gt;本地代理服务的搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;由于TAP平台需要从国外软件源下载依赖包，并且TAP平台只支持HTTP和HTTPS代理。目前国内的代理提供商已经不提供HTTP代理，因为其流量能被监视，因此需要将其他代理协议，如ShadowSocks，转为HTTP代理，因此搭建本地代理服务器（IP为10.2.3.111）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;建立Ubuntu Server虚拟机&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装shadowsocks：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo pip install shadowsocks
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新建配置文件/etc/shadowsocks.json，配置参数可以从&lt;a href=&quot;https://portal.shadowsocks.com.hk/&quot;&gt;https://portal.shadowsocks.com.hk/&lt;/a&gt;网站购买：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;		
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;server&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{your-server}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;server_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;your-port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;local_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{your-password}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;method&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aes-256-cfb&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置全局代理。安装polipo：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install polipo
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改配置文件/etc/polipo/config：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; logSyslog = true
 logFile = /var/log/polipo/polipo.log
 proxyAddress = &quot;0.0.0.0&quot;
 socksParentProxy = &quot;127.0.0.1:1080&quot;
 socksProxyType = socks5
 allowedPorts = 1-65535
 tunnelAllowedPorts = 1-65535
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编写开机启动脚本：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; sudo sslocal -c /etc/shadowsocks.json -d restart
 sudo /etc/init.d/polipo restart
 export http_proxy=http://127.0.0.1:8123/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo http_proxy=http://127.0.0.1:8123 curl www.t66y.com # 小孩子不要打开这个网址
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tap-1&quot;&gt;TAP平台搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;按照&lt;a href=&quot;https://github.com/trustedanalytics/platform-wiki-0.7/wiki/0.7-Openstack-Platform-Deployment&quot;&gt;https://github.com/trustedanalytics/platform-wiki-0.7/wiki/0.7-Openstack-Platform-Deployment&lt;/a&gt;步骤搭建，我选择的配置文件是TAP-FullVM.yaml&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;查看安装日志&lt;/h3&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用Key Pair登录JumpBox，在本机：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ ssh ubuntu@&amp;lt;jumpbox_server_ip&amp;gt; -i &amp;lt;你配置文件中选择的key pair&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;从JumpBox登录Nignx，在JumpBox中：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ sudo -i
  # ssh ubuntu@&amp;lt;nignx_server_ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看安装日志/var/log/cloud-init-output.log、/var/log/ansible.log&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;登录其他主机&lt;/h3&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;nignx主机从root@jump-box中用密钥登录，用户名为ubuntu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;cdh-master和cdh-worker主机从root@jump-box中用密钥登录，用户名为ec2-user&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;docker-broker主机在OpenStack中名为broker/0，登录用户名和密码为vcap:c1oudc0w&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-3&quot;&gt;失败后重新搭建&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;在FUEL UI重置OpenStack环境并重新部署&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;按正常流程运行，其中在运行/opt/tap.sh阶段，可能出现的失败情况：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;创建docker-broker时，not running after update错误。在jump-box执行：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ bosh locks			# 查看未释放锁的进程
 $ bosh delete deployment docker-broker
 $ bosh deployment docker-broker.yml
 $ bosh -n deploy 
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;执行以下命令时，由于找不到${port_id}，导致错误Unable to find port with name or id ‘type=dict’：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; neutron --insecure --os-cloud TAP port-update ${port_id} --allowed-address-pairs type=dict list=true ip_address=10.0.4.0/24 ip_address=172.17.0.0/16
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;手动将文件.ansible/pull/jump-box.novalocal/roles/tap/tasks/main.yml中的${port_id}修改为DockerSubnet中IP为10.0.4.4的portId&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;连接http://archive.apache.org时出现Connection reset by peer错误：&lt;/p&gt;

        &lt;p&gt;修改文件h2o-provisioner/src/main/docker/Dockerfile，&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; - wget http://archive.apache.org/dist/hadoop/core/hadoop-2.6.0/hadoop-2.6.0.tar.gz
 + wget http://apache.mirrors.lucidnetworks.net/hadoop/core/hadoop-2.6.0/hadoop-2.6.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在运行~/tqd.sh阶段，可能出现的失败情况：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;遇到parcel.state错误时（一般是在下载parcel时强制ctrl+c，导致parcel.stage一直处于DOWNLOADING状态中），在jump-box主机中修改文件./platform-ansible/library/cdh.py：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; elif action_a == &#39;deploy_parcel&#39;:
     ...
     if parcel.stage == &#39;DOWNLOADING&#39;:
         cluster.stop().wait()
         cluster.start().wait()
     ...
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在分发parcels是遇到No such torrent错误：&lt;/p&gt;

        &lt;p&gt;从cdh-master-2.node.envname.consul主机中删除文件/opt/cloudera/parcel-cache/&lt;parcel_name&gt;.torrent&lt;/parcel_name&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tap-2&quot;&gt;TAP平台使用&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Mar 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2017/TAP%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2017/TAP%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(8)-消息队列</title>
        <description>&lt;p&gt;&lt;em&gt;以Kafka为例学习消息队列的相关知识，并在集群上搭建Kafka。包括介绍消息队列、Kafka整体架构等&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;消息队列&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;消息队列是在消息传输过程中保存消息的容器或中间件，其主要目的是提供消息路由并保障消息的可靠传递。&lt;/p&gt;

&lt;p&gt;常见的消息中间件包括ActiveMQ、ZeroMQ、RabbitMQ和Kafka等。一般消息中间件支持两种模式的队列：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;消息队列模式&lt;/p&gt;

    &lt;p&gt;即&lt;strong&gt;消息生产者将消息存入队列，消息消费者从队列消费消息&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pub-Sub模式&lt;/p&gt;

    &lt;p&gt;消息生产者将消息&lt;strong&gt;发布到指定主题的队列中&lt;/strong&gt;，而消费者&lt;strong&gt;订阅指定主题的队列消息&lt;/strong&gt;，当订阅的主题有新消息时，消费者可以通过拉取(Pull)或中间件的推送(Push)消费消息&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;Kafka是LinkedIn开源的采用Pub-Sub模式的分布式消息系统，最初被设计作为Log收集工具，因其具有极高吞吐量、低延迟、可扩展、高可用以及能够对消息队列进行持久化保存（不是将全部消息保存在内存中传递），因此应用场景较多，比如作为通用的消息系统、消息实时收集、以及流式计算系统的底层构建等。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;整体架构&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;Kafka架构主要由消息生产者（Producer）、代理服务器（Broker）、消息消费者（Consumer）构成&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Producer：生产者生产指定主题（Topic）的消息并传入代理服务器集群&lt;/li&gt;
  &lt;li&gt;Broker：代理服务器集群在磁盘存储维护各种Topic的消息队列&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Consumer：消费者根据自己订阅的Topic从代理服务器集群中&lt;strong&gt;拉取（Pull）&lt;/strong&gt;新消息并对其进行处理，每个consumer属于一个consumer group，每个group中可以有多个consumer。发送到Topic的消息，只会被订阅此Topic的每个group中的一个consumer消费&lt;/p&gt;

    &lt;p&gt;采用pull方式的好处是消费者可以自主控制消费速率，避免消费者因处理速度跟不上生产者而导致消息大量积压&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Topic：即在内部对应某个名字的消息队列，比如用户访问网站的行为可以分为登录、搜索等不同Topic。Kafka支持对Topic进行数据分片（Partition）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Partition：每个数据分片是有序的、不可更改的尾部追加的消息队列。队列内的每个消息被分配给该数据分片内唯一的Offset。用户可以根据需求，如用户UID进行哈希分配，使得同一用户的数据会放入相同Partion中&lt;/p&gt;

    &lt;p&gt;对于某个Partition，在系统中是一系列被切割成固定大小的文件，新消息被追加到最后一个文件的尾部，同时在内存中维护每个文件首个消息的Offset组成的有序数组作为索引，其内容指向外部文件。消费者读取某个消息时，需要指定消息对应的Offset及读取的内容大小&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为Kafka的消息是存储在文件中的，因此天然具有持久化的能力&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;性能优化：Kafka是一个基于文件系统的消息系统，能够高效处理大批量消息的一个重要原因就是尽可能避免随机读写，尽可能转换为顺序读写，即连续读写整块数据，如Log文件尾部追加写&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;消费者可以通过变换Offset来从对应数据分片读取过期的消息，因此满足“至少送达一次”的语义&lt;/p&gt;

&lt;p&gt;Kafka将消费者目前读取到队列中的哪个信息这个信息交由消费者各自保管，并将很多其他管理信息都存放在Zookeeper而非代理服务器中，这样代理服务器完全成为无状态的，无需记载任何状态信息，增强了消息系统的容错和扩展性&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kafka01020&quot;&gt;安装Kafka（版本0.10.2.0）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2017/大数据学习笔记(5)-分布式协调系统/&quot;&gt;大数据学习笔记(5)-分布式协调系统&lt;/a&gt;安装好Zookeeper&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Kafka二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/home/cat/cat/kafka_2.11-0.10.2.0.tgz dest=/home/cat/cat/&#39;
 $ ansible zookeeper -a &#39;tar -zxvf /home/cat/cat/kafka_2.11-0.10.2.0.tgz -C /opt/&#39;
 $ ansible zookeeper -a &#39;mv /opt/kafka_2.11-0.10.2.0 /opt/kafka-0.10.2.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建kafka日志目录:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;mkdir /opt/kafka-0.10.2.0/logs&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;kafka-1&quot;&gt;配置Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/server.properties&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ##### 需要配置 #####
 # 节点唯一标识，类似zookeeper的myid
 broker.id=0  
 host.name=10.2.2.141
 # 消息存放的目录，这个目录可以配置为逗号分割的表达式，num.io.threads要大于这个目录的个数
 log.dirs=/opt/kafka-0.10.2.0/logs/
 # 设置zookeeper的连接端口
 zookeeper.connect=10.2.2.141:2181,10.2.2.142:2181,10.2.2.143:2181 

 ##### 使用默认 #####
 # kafka对外提供服务的端口
 port=9092 
 # borker进行网络处理的线程数
 num.network.threads=3 
 # borker进行I/O处理的线程数
 num.io.threads=8 
 # 发送缓冲区buffer大小
 socket.send.buffer.bytes=102400 
 # kafka接收缓冲区大小，当数据到达一定大小后再序列化到磁盘
 socket.receive.buffer.bytes=102400 
 # 这个参数是向kafka请求消息或者向kafka发送消息的请求最大数，这个值不能超过java的堆栈大小
 socket.request.max.bytes=104857600 
 # 默认的分区数，一个topic默认1个分区数
 num.partitions=1 
 # 默认消息的最大持久化时间，168小时，7天
 log.retention.hours=168 
 # 消息保存的最大值5M
 message.max.byte=5242880  
 # kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
 default.replication.factor=2  
 # 取消息的最大直接数
 replica.fetch.max.bytes=5242880 
 # 因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
 log.segment.bytes=1073741824 
 # 每隔300秒去检查上面配置的log失效时间（log.retention.hours=168），到目录查看是否有过期的消息如果有，删除
 log.retention.check.interval.ms=300000 
 # 是否启用log压缩，一般不用启用，启用的话可以提高性能
 log.cleaner.enable=false 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/opt/kafka-0.10.2.0/config/ dest=/opt/kafka-0.10.2.0/config/&#39;	
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;登入每台kafka节点，修改broker.id和host.name&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;kafka-2&quot;&gt;启动Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在每个kafka节点：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-server-start.sh -daemon /opt/kafka-0.10.2.0/config/server.properties
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;kafka-3&quot;&gt;测试Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在主节点查看&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkCli.sh
 [zk: localhost:2181(CONNECTED) 0] ls /
 [cluster, controller_epoch, controller, brokers, zookeeper, hadoop-ha, admin, isr_change_notification, consumers, config]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]创建topic，一个副本，一个分区&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]查看topic&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-topics.sh --list --zookeeper localhost:2181
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]使用kafka-console-producer在控制台发送消息&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-console-producer.sh --broker-list localhost:9092 --topic test
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]使用kafka-console-consumer在控制台接受消息&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]如果在producer console输入一条消息，能从consumer console看到这条消息就代表安装是成功&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 02 Feb 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(8)-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(8)-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(7)-数据仓库</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;hive210on-tez085&quot;&gt;安装Hive（版本2.1.0）on Tez（版本0.8.5）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;大数据学习笔记(2)-Hadoop&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Hive二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/apache-hive-2.1.0-bin.tar.gz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/apache-hive-2.1.0-bin.tar.gz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/apache-hive-2.1.0-bin /opt/hive-2.1.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Mysql驱动包&lt;a href=&quot;https://dev.mysql.com/downloads/connector/j/&quot;&gt;https://dev.mysql.com/downloads/connector/j/&lt;/a&gt;，并放入/opt/hive-2.1.0/lib中&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hive-2.1.0/lib/ dest=/opt/hive-2.1.0/lib/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)安装MySQL用于存储元数据&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install mysql-server
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为Hive建立相应的MySQL账户,并赋予足够的权限:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mysql -uroot -p
 mysql&amp;gt; CREATE USER &#39;hive&#39; IDENTIFIED BY &#39;yourpassword&#39;;
 mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &#39;hive&#39;@&#39;%&#39; WITH GRANT OPTION;
 mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选] 解除Mysql只允许本地登录，/etc/mysql/mysql.conf.d/mysqld.cnf :&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #bind-address           = 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重新加载配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo service mysql restart
 #在MacOS中
 $ launchctl unload /Users/wuyinan/Library/LaunchAgents/homebrew.mxcl.mysql.plist
 $ launchctl load /Users/wuyinan/Library/LaunchAgents/homebrew.mxcl.mysql.plist
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;建立Hive专用的元数据库:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mysql -uhive -p
 mysql&amp;gt; create database metastore;
 mysql&amp;gt; USE metastore;
 mysql&amp;gt; SOURCE /opt/hive-2.1.0/scripts/metastore/upgrade/mysql/hive-schema-2.1.0.mysql.sql;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在HDFS创建数据存储仓库&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir -p /user/hive/warehouse
 $ hadoop fs -chmod -R 777 /user/hive
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建hive的log文件存储目录&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ mkdir /opt/hive-2.1.0/logs
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive&quot;&gt;配置Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-site.xml文件::&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&amp;gt;
 &amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
 &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;jdbc:mysql://10.2.2.141:3306/metastore?characterEncoding=UTF-8&amp;amp;amp;useSSL=false&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;元数据存储的Mysql路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;hive&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;yourpassword&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/hive/warehouse&amp;lt;/value&amp;gt;
      &amp;lt;description&amp;gt;数据存储的HDFS路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;thrift://10.2.2.141:9083&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;spark-shell默认将启动一个SqlContext，因此在{SPARK_HOME}/conf目录下需要有该hive-site.xml文件，并且文件中需要指定hive.metastore.uris&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-env.sh文件:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export HADOOP_HOME=/opt/hadoop-2.7.3
 export HIVE_CONF_DIR=/opt/hive-2.1.0/conf	
 # tez相关
 export TEZ_HOME=/opt/tez-0.8.5
 export TEZ_CONF_DIR=/opt/tez-0.8.5/conf
 export TEZ_JARS=/opt/tez-0.8.5
 export HADOOP_CLASSPATH=${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-log4j2.properties文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; property.hive.log.dir = /opt/hive-2.1.0/logs
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将/opt/hive-2.1.0/conf/hive-site.xml文件和/opt/hadoop-2.7.3/etc/hadoop/hdfs-site.xml文件复制到/opt/spark-2.1.0/conf下&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cp /opt/hive-2.1.0/conf/hive-site.xml /opt/spark-2.1.0/conf/
 $ cp /opt/hadoop-2.7.3/etc/hadoop/hdfs-site.xml /opt/spark-2.1.0/conf/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Hive配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hive-2.1.0/conf/ dest=/opt/hive-2.1.0/conf/&#39;
 $ ansible slave -m copy -a &#39;src=/opt/spark-2.1.0/conf/ dest=/opt/spark-2.1.0/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive-1&quot;&gt;启动Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;启动Hadoop&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)启动Hive服务器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive --service metastore &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive-2&quot;&gt;测试Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点)启动Hive，进入Hive交互界面:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive
 hive&amp;gt;
 hive&amp;gt; show databases;
 hive&amp;gt; use default;
 hive&amp;gt; create table test(id INT);
 hive&amp;gt; insert into test VALUES(0);
 hive&amp;gt; select count(*) from test;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tez085&quot;&gt;安装Tez（版本0.8.5）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载Tez源码包，修改pom.xml：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;hadoop.version&amp;gt;2.7.3&amp;lt;/hadoop.version&amp;gt;
 &amp;lt;javac.version&amp;gt;1.8&amp;lt;/javac.version&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;根据pom.xml中protobuf.version，安装protobuf：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ wget https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
 $ tar -zxvf protobuf-2.5.0.tar.gz -C .
 $ cd protobuf-2.5.0/
 $ ./configure
 $ make
 $ make check
 $ sudo make install
 $ sudo vi /etc/ld.so.conf.d/bprotobuf.conf
 /usr/local/lib
 $ sudo ldconfig
 $ protoc --version
 libprotoc 2.5.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改Maven镜像源/etc/maven/settings.xml，在mirros下添加子节点&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;mirror&amp;gt;
     &amp;lt;id&amp;gt;nexus-aliyun&amp;lt;/id&amp;gt;
     &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt;
     &amp;lt;name&amp;gt;Nexus aliyun&amp;lt;/name&amp;gt;
     &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt;
 &amp;lt;/mirror&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开代理，编译：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ export http_proxy=http://127.0.0.1:8123/
 $ export https_proxy=http://127.0.0.1:8123/
 $ mvn package -DskipTests=true -Dmaven.javadoc.skip=true
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;服务端使用完整包。将编译好的tez-dist/target/tez-0.8.5.tar.gz上传到hdfs上(/user/tez/)&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir /user/tez/
 $ hadoop fs -put ./tez-dist/target/tez-0.8.5.tar.gz
 $ hadoop fs -chmod -R 777 /user/tez
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;客户端使用minimal包。将编译好的tez-dist/target/tez-0.8.5-minimal.tar.gz分发到各节点，解压&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &quot;src=./tez-dist/target/tez-0.8.5-minimal.tar.gz dest=/home/cat/cat/&quot;
 $ ansible all -a &quot;mkdir /opt/tez-0.8.5&quot;
 $ ansible all -a &quot;tar -zxvf /home/cat/cat/tez-0.8.5-minimal.tar.gz -C /opt/tez-0.8.5/&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;tez&quot;&gt;配置Tez&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/tez-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;tez.lib.uris&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;${fs.defaultFS}/user/tez/tez-0.8.5-minimal.tar.gz&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;tez.use.cluster.hadoop-libs&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发配置&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ansible all -m copy -a &quot;src=/opt/tez-0.8.5/conf/ dest=/opt/tez-0.8.5/conf/&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;tez-1&quot;&gt;测试Tez&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点)启动Hive，进入Hive交互界面:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive
 hive&amp;gt;
 hive&amp;gt; set hive.execution.engine=tez;
 hive&amp;gt; use default;
 hive&amp;gt; select count(*) from test;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;sqoop146&quot;&gt;安装Sqoop（版本1.4.6）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载Sqoop二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/sqoop-1.4.6.bin__hadoop-2.0.4-alpha /opt/sqoop-1.4.6&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将pg-jdbc和mysql的jar包放入$SQOOP_HOME/lib&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [https://jdbc.postgresql.org/download.html](https://jdbc.postgresql.org/download.html)		
 [https://dev.mysql.com/downloads/connector/j/](https://dev.mysql.com/downloads/connector/j/)

 $ ansible slave -m copy -a &#39;src=/opt/sqoop-1.4.6/lib/ dest=/opt/sqoop-1.4.6/lib/&#39; ---
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;sqoop&quot;&gt;配置Sqoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/sqoop-env.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export HADOOP_COMMON_HOME=/opt/hadoop-2.7.3
 export HIVE_HOME=/opt/hive-2.1.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Sqoop配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/sqoop-1.4.6/conf/ dest=/opt/sqoop-1.4.6/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;sqoop-1&quot;&gt;测试Sqoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点):&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop list-databases --connect jdbc:postgresql://10.2.26.96:5432/lrs --username lrs_owner --password pass
 $ sqoop list-databases --connect jdbc:mysql://10.2.2.141:3306/metastore --username hive --password pass
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;psql向hdfs的导入，HDFS中的路径文件夹必需不存在:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop import --connect jdbc:postgresql://{psql的IP地址}:5432/{数据库名} --username {用户名} --password {密码} --table {表名} --target-dir {HDFS中的路径} -m 5
	
 $ sqoop import --connect jdbc:postgresql://10.2.3.100:5432/cat --username postgres --password ada --table kitty --target-dir /test/kitty -m 5
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;psql向hive的导入:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop import --connect jdbc:postgresql://{psql的IP地址}:5432/{数据库名} --username {用户名} --password {密码} --table {表名} --hive-import -m 5
	
 $ sqoop import --connect jdbc:postgresql://10.2.3.100:5432/cat --username postgres --password ada --table kitty --hive-import -m 5
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 26 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(6)-Spark</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习Spark相关知识，并在Yarn集群搭建Spark。包括通过日志分析Spark on Yarn-cluster运行机制&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;spark&quot;&gt;Spark&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;spark-on-yarn-cluster&quot;&gt;Spark on Yarn-cluster运行机制&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;在Spark on Yarn-cluster模式中，Spark应用的Driver即为Yarn中的ApplicationMaster(实际也是一个Container)，Spark的Executor即为Yarn中的Container，其中Driver负责资源的申请和job的调度，Executor负责Task的具体执行&lt;/p&gt;

&lt;p&gt;运行参数：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark-submit --class logs.Main \
 --master yarn-cluster \		// Spark on Yarn-cluster
 --num-executors 19 \			// 19个Executors+1个AM(Driver)
 --executor-memory 5g \			// 每个Executors堆内存
 --executor-cores 2 \			// 每个Executors虚拟CPU核数
 --driver-memory 5g \			//  Driver堆内存
./Test-assembly-1.0.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Spark Yarn的client提交应用(Application)给Yarn的ResourceManager&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 连接到RM
 17/03/31 18:14:19 INFO RMProxy: Connecting to ResourceManager at /10.2.2.141:8032

 // 向集群请求提交一个应用
 17/03/31 18:14:19 INFO Client: Requesting a new application from cluster with 10 NodeManagers
	
 // 检查请求的资源是否超过设定值
 17/03/31 18:14:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
	
 // 分配一个ApplicationMaster，包括堆内存5120M和非堆内存512M，共5632M
 17/03/31 18:14:19 INFO Client: Will allocate AM container, with 5632 MB memory including 512 MB overhead
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RM向NodeManager申请Container，用于运行ApplicationMaster(Spark的Driver)，并将应用的jar文件上传到HDFS&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 申请Container，用于运行ApplicationMaster
 17/03/31 18:14:19 INFO Client: Setting up container launch context for our AM
 17/03/31 18:14:19 INFO Client: Setting up the launch environment for our AM container
 17/03/31 18:14:19 INFO Client: Preparing resources for our AM container
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;// 将应用的jar文件上传到HDFS
17/03/31 18:14:22 INFO Client: Uploading resource file:/tmp/spark-0222f8da-3cf4-4ff1-9109-c4877293fc5b/__spark_libs__3620896466196856366.zip -&amp;gt; hdfs://cats/user/wyn/.sparkStaging/application_1490945694024_0003/__spark_libs__3620896466196856366.zip&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;NM启动AM，在Container中初始化SparkContext，其中比较重要的是创建TaskScheduler和DAGScheduler。在Spark on Yarn-cluster模式中，TaskScheduler将选择YarnClusterScheduler和YarnClusterSchedulerBackend&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;YarnClusterScheduler用于根据每个Executor的资源剩余情况分配合适的Task，并维护一个任务队列，根据FIFO或Fair策略，调度任务&lt;/li&gt;
      &lt;li&gt;YarnClusterSchedulerBackend用于维护Executor相关信息(包括Executor的地址、通信端口、主机、资源情况)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DAGScheduler用于根据Job构建基于Stage的DAG(有向无环图)，并提交Stage给TaskScheduler&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  17/03/31 18:14:29 INFO ApplicationMaster: Preparing Local resources
		
  // 初始化SparkContext
  17/03/31 18:14:30 INFO ApplicationMaster: Waiting for spark context initialization...
  17/03/31 18:14:30 INFO SparkContext: Running Spark version 2.1.0
		
  // 创建YarnClusterScheduler
  17/03/31 18:14:31 INFO YarnClusterScheduler: Created YarnClusterScheduler
		
  // AM中注册一个SchedulerBackend，用于Executor与其通信
  17/03/31 18:14:31 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.2.2.150:45262)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AM向RM申请资源，申请到相应资源后，AM中的YarnClusterScheduler通过RPC协议让NM启动相应的Executor&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 申请资源，包括堆内存5120M和非堆内存512M，共5632M
 17/03/31 18:14:31 INFO YarnAllocator: Will request 19 executor container(s), each with 2 core(s) and 5632 MB memory (including 512 MB of overhead)
 17/03/31 18:14:31 INFO YarnAllocator: Submitted 19 unlocalized container requests.
	
 // 启动executor
 17/03/31 18:14:31 INFO YarnAllocator: Launching container container_1490945694024_0003_01_000002 on host cat5
 17/03/31 18:14:31 INFO YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NM启动Executor(container)，在container中创建ExecutorBackend，用于与AM的SchedulerBackend通信，并向AM注册并申请Task&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 每个executor中注册一个ExecutorBackend，用于与AM通信
 17/03/31 18:14:33 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (10.2.2.150:34052) with ID 2
 17/03/31 18:14:34 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (10.2.2.144:39920) with ID 4
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开始执行Job，DAGScheduler根据Job构建基于Stage的DAG，并提交Stage(也就是TaskSet)给TaskScheduler，TaskScheduler向Executor分配Task，由ExecutorBackend执行，并向AM汇报运行的状态和进度&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 开始执行Job
 17/03/31 18:14:50 INFO SparkContext: Starting job: sortBy at Main.scala:33
	
 // DAGScheduler根据Job构建基于Stage的DAG，并提交Stage(也就是TaskSet)给TaskScheduler
 17/03/31 18:14:51 INFO DAGScheduler: Submitting 23137 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at groupBy at Main.scala:31)
	
 // TaskScheduler将Task分配给Executor
 17/03/31 18:14:51 INFO YarnClusterScheduler: Adding task set 0.0 with 23137 tasks
	
 // 分配给的Executor的具体信息
 17/03/31 18:14:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, cat12, executor 12, partition 0, NODE_LOCAL, 6051 bytes)
 17/03/31 18:14:51 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 1, cat8, executor 16, partition 18, NODE_LOCAL, 6051 bytes)
 ...
 17/03/31 18:14:52 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 32) in 1413 ms on cat5 (executor 11) (1/23137)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;应用程序运行完成后，AM下令关闭所有Executor，并向RM申请注销并关闭自己&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // AM通知应用运行完成
 17/03/31 18:18:50 INFO ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
 17/03/31 18:18:50 INFO SparkContext: Invoking stop() from shutdown hook
	
 // AM下令关闭所有Executor
 17/03/31 18:18:53 INFO YarnAllocator: Driver requested a total number of 0 executor(s).
 17/03/31 18:18:53 INFO YarnClusterSchedulerBackend: Shutting down all executors
 17/03/31 18:18:53 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
	
 // AM关闭自己
 17/03/31 18:18:53 INFO SparkContext: Successfully stopped SparkContext
 17/03/31 18:18:53 INFO ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
	
 // Executor收到来自Driver的关闭命令
 17/03/31 18:18:53 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
	
 // Executor关闭
 17/03/31 18:18:53 INFO CoarseGrainedExecutorBackend: Driver from 10.2.2.150:45262 disconnected during shutdown
 17/03/31 18:18:53 INFO ShutdownHookManager: Shutdown hook called
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;spark210&quot;&gt;安装Spark（版本2.1.0）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;大数据学习笔记(2)-Hadoop&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Scala（版本2.11.8）二进制包，并分发到所有节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/scala-2.11.8.tgz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/scala-2.11.8.tgz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Spark二进制包（或源码自行编译），并分发到所有节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/spark-2.1.0-bin-hadoop2.7.tgz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/spark-2.1.0-bin-hadoop2.7.tgz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/spark-2.1.0-bin-hadoop2.7 /opt/spark-2.1.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建history默认存放位置:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir /tmp
 $ hadoop fs -mkdir /tmp/spark-history
 $ hadoop fs -chmod -R 777 /tmp
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;spark-1&quot;&gt;配置Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/spark-env.sh:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_HOME=/opt/hadoop-2.7.3
 export SCALA_HOME=/opt/scala-2.11.8	
	
 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export HDFS_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

 # spark.history.retainedApplications仅显示最近10个应用
 export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=10 -Dspark.history.fs.logDirectory=hdfs:///tmp/spark-history&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;conf/slaves:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 10.2.2.14[3:12]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;conf/spark-defaults.conf:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 对于Spark Job启用log event配置，是否记录Spark事件，用于应用程序在完成后重构webUI
 spark.eventLog.enabled           true
 spark.eventLog.dir hdfs:///tmp/spark-history
 spark.eventLog.compress          true

 spark.yarn.historyServer.address 10.2.2.141:18080
 spark.history.ui.port 18080
 spark.history.fs.logDirectory hdfs:///tmp/spark-history
 spark.history.provider org.apache.spark.deploy.history.FsHistoryProvider
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Spark配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/spark-2.1.0/conf/ dest=/opt/spark-2.1.0/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;spark-2&quot;&gt;启动Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;启动Spark的所有进程，包括Master、Worker:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)启动HistoryServer，启动的进程应包括HistoryServer：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/sbin/start-history-server.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;spark-3&quot;&gt;测试Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;使用jps查看各节点起的进程&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -a &#39;/opt/jdk1.8.0_121/bin/jps&#39;

 cat1: Master, HistoryServer, QuorumPeerMain, DFSZKFailoverController, NameNode, ResourceManager
 cat2: QuorumPeerMain, DFSZKFailoverController, NameNode
 cat3: QuorumPeerMain
 cat4-12: Worker, JournalNode, DataNode, NodeManager
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试，运行SparkPi例子:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/bin/spark-submit --class org.apache.spark.examples.SparkPi \
 --master yarn-cluster \
 --num-executors 3 \
 --driver-memory 2g \
 --executor-memory 1g \
 --executor-cores 1 \
 --queue thequeue \
 /opt/spark-2.1.0/examples/jars/spark-examples_2.11-2.1.0.jar \
 10
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看结果:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ yarn logs -applicationId ${applicationId} | grep &#39;Pi&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在界面&lt;a href=&quot;http://10.2.2.141:18080/&quot;&gt;http://10.2.2.141:18080/&lt;/a&gt;查看历史&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Sun, 15 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(6)-Spark/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(6)-Spark/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(5)-分布式协调系统</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;分布式协调系统&lt;/h2&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;zookeeper349&quot;&gt;安装Zookeeper（版本3.4.9）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(1)-Overview/&quot;&gt;大数据学习笔记(1)-Overview&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Zookeeper二进制包，并分发到所有zookeeper节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/home/cat/cat/zookeeper-3.4.9.tar.gz dest=/home/cat/cat/&#39;
 $ ansible zookeeper -a &#39;tar -zxvf /home/cat/cat/zookeeper-3.4.9.tar.gz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建数据文件夹、日志文件夹和myid文件:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;mkdir -p /opt/zookeeper-3.4.9/var/data&#39;
 $ ansible zookeeper -a &#39;mkdir -p /opt/zookeeper-3.4.9/var/log&#39;
 $ ansible zookeeper -a &#39;touch /opt/zookeeper-3.4.9/var/data/myid&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper&quot;&gt;配置Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/zoo.cfg&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 这个时间(ms)是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔
 tickTime=2000

 # Zookeeper服务器集群中的Follower服务器初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过10个tickTime的时间长度后Leader服务器还没有收到Follower的返回信息，表明这个Follower连接失败
 initLimit=10

 # 标识Leader与Follower之间发送消息，请求和应答时间长度最长不能超过多少个tickTime的时间长度
 syncLimit=5

 # 客户端连接Zookeeper服务器的端口，Zookeeper会监听这个端口，接受客户端的访问请求。
 clientPort=2181

 # Zookeeper存放数据，也把zookeeper服务器的ID文件保存到这个目录下
 dataDir=/opt/zookeeper-3.4.9/var/data
 # 数据的log日志
 dataLogDir=/opt/zookeeper-3.4.9/var/log

 # 所有安装Zookeeper的主机，必须是奇数台，不用使用全部。server.ID，ID写入每台主机的{dataDir}/myid中
 server.1=cat1:2888:3888 
 server.2=cat2:2888:3888
 server.3=cat3:2888:3888
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;bin/zkEnv.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # Zookeeper的Log日志
 export ZOO_LOG_DIR=&quot;/opt/zookeeper-3.4.9/var/log&quot; 
 export JAVA_HOME=&quot;/opt/jdk1.8.0_121&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;var/data/myid&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 根据conf/zoo.cfg内容，例如本机为cat1，则myid文件内容为：
 1
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-1&quot;&gt;分发Zookeeper配置文件&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;分发Zookeeper配置文件conf/zoo.cfg和bin/zkEnv.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/opt/zookeeper-3.4.9/conf/zoo.cfg dest=/opt/zookeeper-3.4.9/conf/&#39;
 $ ansible zookeeper -m copy -a &#39;src=/opt/zookeeper-3.4.9/bin/zkEnv.sh dest=/opt/zookeeper-3.4.9/bin/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;登录到每台zookeeper主机中修改{dataDir}/myid&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat1:~$ echo &quot;1&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
 cat@cat2:~$ echo &quot;2&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
 cat@cat3:~$ echo &quot;3&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-2&quot;&gt;启动Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有zookeeper节点启动Zookeeper服务器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-3&quot;&gt;测试Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有zookeeper节点查看zookeeper状态。如果启动失败，查看/opt/zookeeper-3.4.9/var/log/zookeeper.out日志&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkServer.sh status
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;hadoop-hahttpswuyinan0126githubio20162-hadoop&quot;&gt;下一步：&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;安装Hadoop HA&lt;/a&gt;&lt;/h2&gt;
&lt;hr /&gt;
</description>
        <pubDate>Mon, 02 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(5)-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%B3%BB%E7%BB%9F/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(5)-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%B3%BB%E7%BB%9F/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(4)-分布式文件系统</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习GFS、HDFS的…等&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;gfs&quot;&gt;GFS&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-1.png&quot; alt=&quot;Hadoop的MapReduce运行机制&quot; title=&quot;Hadoop的MapReduce运行机制&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Dec 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(3)-计算模型</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习MapReduce、DAG计算模型，介绍了MapReduce计算模型的运行机制、优点和不足、计算模式，和一种更高效的的计算框架——DAG模型的图结构描述&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;mapreduce&quot;&gt;MapReduce&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-1&quot;&gt;MapReduce运行机制&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-1.png&quot; alt=&quot;Hadoop的MapReduce运行机制&quot; title=&quot;Hadoop的MapReduce运行机制&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;MapReduce计算框架将应用的输入数据分割成若干block（自Hadoop-2.2起，默认为128M），存入HDFS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;集群中的Master负责为Worker分配Map或Reduce任务，并做一些全局管理；任务数可由开发者指定&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Map阶段：被分配到Map任务的Worker读取对应的block，从block中解析出Key/Value对，并传递给Map函数，执行业务逻辑，将中间结果Key/Value对缓存在内存中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Patition阶段：缓存的中间结果会周期性地被Spill入&lt;strong&gt;本地磁盘&lt;/strong&gt;，写入磁盘前被Partitioner分割为R份，R为Reduce任务数，分割函数一般是用Key对R哈希取模。在分割后将R个临时文件位置通知给Master，Master将其转交给Reduce任务的Worker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sort&amp;amp;Combine阶段：在写入磁盘前，对中间结果进行&lt;strong&gt;局部&lt;/strong&gt;排序，然后运行Combiner对数据进行合并，即对中间数据中具有相同Key的Value值进行合并，合并的业务逻辑和Reduce阶段的逻辑是相似的，这样可以大大减少中间数据量，减少网络传输量&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shuffle阶段：当某个Reduce任务的Worker接收到Master的通知后，其通过RPC(Remote Procedure Call)将Map任务产生的属于自己的M份临时文件&lt;strong&gt;Pull&lt;/strong&gt;到本地，M为Map任务数。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reduce阶段：将M分临时文件中局部Key有序的数据进行Merge Sort进行全局排序，然后执行Reduce函数，并将结果追加到这个Reduce任务对应的结果文件结尾&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-2&quot;&gt;MapReduce优点和不足&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;极强的可扩展性、良好的容错性、简单性（即用户只要完成Map和Reduce函数即可）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;数据的高吞吐量、支持海量数据处理的大规模并行处理、细粒度容错&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不足：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;不适合对实效性要求高的应用场景（如交互式查询、流式计算）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;不适合迭代运算类的机器学习及数据挖掘类的应用&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不足的原因：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Map和Reduce任务启动时间较长。对于批处理任务来说，启动时间对于任务执行时间所占比例不大，但对于高实效性的应用来说，所占比例太高&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在一次任务执行过程中，MapReduce计算模型存在多处的磁盘读写、网络传输的过程。如初始block读取、Map任务的中间结果保存入磁盘、Shuffle阶段的网络传输、Reduce阶段的磁盘读和HDFS写等。对于迭代式机器学习应用，往往需要一个任务反复迭代进行，此时磁盘读写、网络传输的开销造成效率低下&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-3&quot;&gt;MapReduce计算模式&lt;/h3&gt;

&lt;p&gt;实际应用中的大部分ETL任务都可以归结为MapReduce计算模式或其变体，如：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;求和模式：包括数值求和（Value为数值），记录求和（Value为非数值，累加形成队列）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;过滤模式：简单过滤（Map实现过滤函数，无Reduce阶段），Top K记录（Map实现统计局部Top K，Reduce实现全局Top K）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组织数据模式：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;数据分片：例如将所有记录按日期进行分类，需要将同一时间的数据放到一起，此时需要修改Partion策略，默认的Partition策略为hash取模&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;全局排序：MapReduce自带的排序特性，在Reduce阶段需要先将中间数据按Key进行Merge Sort，因此只需要修改Partion策略，保证不同的Reducer处理一个区间范围的记录，例如将Key为1-1000的数据给Reducer1处理，key为1001-2000点数据交给Reducer2处理，这样将所有Reducer的输出拼接在一起即可得到全局排序&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Join模式：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Reduce-Side Join：需要输入两个数据集，区分方式为：连表的外键作为Key，记录的其他内容作为Value，在Value中增加一个标志信息，表明记录属于哪个数据集。然后在Reduce阶段将相同Key，不同数据集的记录做Join。该方式较通用，但需要经过若干轮中间数据的磁盘读写、Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此计算效率较低&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Map-Side Join：只需要输入一个大数据集，小数据集放入内存哈希表中，以外键作为哈希表的Key。此时只需要在Map阶段对大数据的每条记录查找哈希表进行Join操作。由于避免了Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此该方式效率较高，但要求小数据集必须足够小到能放入内存&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;dag&quot;&gt;一种更高效的的计算框架——DAG&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;虽然MapReduce提供了简介的借口，用户只需完成Map和Reduce函数的业务逻辑就可以实现大规模数据批处理任务，但是其支持的运算符仅仅限定与Map和Reduce两类，所以在表达能力上不够丰富。&lt;/p&gt;

&lt;p&gt;另外，MapReduce计算模型的本质是由Map和Reduce序列两个阶段完成的，在Map任务阶段有个任务同步过程，只有在所有Map任务执行完成才能开始Reduce阶段的任务。&lt;/p&gt;

&lt;p&gt;从上可以看出MapReduce对于子任务之间复杂的交互和依赖关系缺乏表达能力，因此，一种更高效的的计算框架——DAG氤氲而生。DAG计算模型可以认为是对MapReduce计算模型的一种扩展（可以将MapReduce模型看作DAG模型的一种特例）。DAG模型可以表达复杂的并发任务之间的依赖关系，提供了丰富的运算符，使其表达能力和灵活性更加强大。&lt;/p&gt;

&lt;p&gt;DAG的全称是”Directed Acyclic Graph”(有向无环图)，是指将计算任务分解成若干子任务，这些子任务之间由逻辑关系或运行先后顺序等因素被构建成有向无环图结构。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;dag-1&quot;&gt;DAG图结构描述&lt;/h3&gt;

&lt;p&gt;以微软的Dryad为例，其采用了若干简单的DAG结构及其描述符的不断组合来构建复杂结构的方式。可以形式化地用以下方式描述一个DAG图结构：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G=\{ {V}_{G},{E}_{G},{I}_{G},{O}_{G} \}&lt;/script&gt;

&lt;p&gt;其中，VG代表图节点集合，EG代表有向边集合；IG是VG的子集，表示DAG图中的数据输入节点集合；OG也是VG的子集，表示DAG图中数据输出节点集合。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个基本的图描述符为G^k，表示一个计算结构并发为k个，如下图：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-2.png&quot; alt=&quot;A^n&quot; title=&quot;A^n&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;图结构串行连接G3 = G1 · G2，由图G1和图G2的所有节点和边构成，图G1的输入节点构成图G3的输入节点，图G2的输出节点构成图G3的输出节点，图G1的输出节点到图G2的输入节点之间构建新的有向边。这种关系可以定义下列两个描述符：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;G1 &amp;gt;= G2：图G1的输出节点和图G2的输入节点间进行点对点的边连接，采用Round Robin(轮询)的方式构建有向边：
        &lt;ul&gt;
          &lt;li&gt;如果|OG1|&amp;gt;=|IG2|，此时G2的输入节点中某些节点输入边可能大于1条&lt;/li&gt;
          &lt;li&gt;如果|OG1|&amp;lt;|IG2|，此时G2的输入节点中有些节点没有输入边&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;G1 » G2: 图G1的输出节点和图G2的输入节点之间形成完全二分图。**MapReduce架构即为由并发执行的Map阶段的图G1和Reduce阶段的图G2串行而成的完全二分图，如下图：&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-3.png&quot; alt=&quot;AS &amp;gt;&amp;gt; BS&quot; title=&quot;AS &amp;gt;&amp;gt; BS&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;G1 || G2：代表图结构水平融合，允许图G1和图G2有相同的节点，融合时合并相同节点，如下图，是由图B &amp;gt;= C和图B &amp;gt;= D水平融合得到的：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-4.png&quot; alt=&quot;B &amp;gt;= C || B &amp;gt;= D&quot; title=&quot;B &amp;gt;= C \|\| B &amp;gt;= D&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通过以上几个基础的描述符，可以构建复杂的图结构，如下图：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-5.png&quot; alt=&quot;复杂图结构&quot; title=&quot;复杂图结构&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;dag-2&quot;&gt;DAG图任务执行&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 04 Dec 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(2)-Hadoop</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习Hadoop相关知识，并在集群上搭建Hadoop HA平台。包括介绍MapReduce计算框架、HDFS文件系统、YARN资源调度与管理系统、MapReduce和Yarn的参数配置等&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;hadoop&quot;&gt;Hadoop&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce&quot;&gt;MapReduce&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;大数据计算中最常见的一种计算方式是&lt;strong&gt;批处理&lt;/strong&gt;。2004年Google发表了MapReduce计算范型和框架论文，这是一种构建在大规模PC之上的批处理计算框架，也是一种分布式计算模型，获得了极为广泛的应用。&lt;/p&gt;

&lt;p&gt;MapReduce和传统的并行数据库系统(MPP)相比，更适合&lt;strong&gt;非结构化数据的ETL处理&lt;/strong&gt;(将数据从来源端经过抽取(extract)、转换(transform)、加载(load)至目的端的过程)，且其更具有&lt;strong&gt;扩展性和容错性&lt;/strong&gt;，但单机处理效率低。&lt;/p&gt;

&lt;p&gt;MapReduce计算提供了简洁的编程接口，&lt;strong&gt;输入和输出均是Key/Value键值对&lt;/strong&gt;，只需根据业务逻辑实现Map和Reduce函数即可完成大规模数据的并行批处理任务。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Map函数以Key/Value作为输入，经逻辑计算产生若干仍以Key/Value形式表达的中间数据。计算框架自动将中间数据中具有相同Key值的记录聚在一起，传递给Reduce函数作为输入&lt;/li&gt;
  &lt;li&gt;Reduce函数以Map阶段传递过来的某个Key值及其对应的若干Value值作为输入，对这些Value进行逻辑计算，生成Key/Value即计算结果&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上为MapReduce的简单介绍，更为详细的MapReduce计算模型学习笔记请参看我的另一篇博文：&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(3)-计算模型/&quot;&gt;大数据学习笔记(3)-计算模型&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hdfs&quot;&gt;HDFS&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;HDFS的全称是”Hadoop Distributed File System”，是Hadoop中的大规模分布式文件系统。它最初是Yahoo模仿Goole的GFS(Google File System)开发的开源系统，因此在整体架构上和GFS大致相同。与GFS一样，HDFS适合存储&lt;strong&gt;大文件&lt;/strong&gt;并为之提供高吞吐量的&lt;strong&gt;顺序读写&lt;/strong&gt;访问，不太适合大量随机读的应用场景，也不适合储存大量的小文件的应用场景。&lt;/p&gt;

&lt;p&gt;在Hadoop1.x中，HDFS可以被看作简化版的开源GFS系统，因为其在实现时绕开了一些GFS的复杂方案而采用简化方案，因此限制了性能。在这个系列的版本中，存在的问题包括：单点失效和水平扩展不佳。单点失效会导致整个集群不可用，而水平扩展不佳会导致整个文件系统管理文件数目容易达到上限，所以集群规模达到一定程度就无法扩展。&lt;/p&gt;

&lt;p&gt;在Hadoop2.x中，提出了高可用方案(High Availability, HA)和NameNode联盟(NameNode Federation)。其中高可用是为了解决单点失效问题，而NameNode联盟是为了解决整个系统的水平扩展问题。&lt;/p&gt;

&lt;p&gt;以上为HDFS的简单介绍，更为详细的HDFS学习笔记请参看我的另一篇博文：&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(4)-分布式文件系统/&quot;&gt;大数据学习笔记(4)-分布式文件系统&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;yarn&quot;&gt;YARN&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;YARN的全称是”Yet Another Resource Negotiator”，是一个独立的&lt;strong&gt;资源调度与管理系统&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在Hadoop1.x中，所有任务的&lt;strong&gt;资源管理&lt;/strong&gt;以及&lt;strong&gt;生命周期管理&lt;/strong&gt;都由全局唯一的JobTracker负责，造成其功能繁复，限制了系统的可扩展性。同时JobTracker还存在单点失效的问题，一旦JobTracker故障，整个Hadoop集群将崩溃。&lt;/p&gt;

&lt;p&gt;在Hadoop2.x中，将&lt;strong&gt;资源管理&lt;/strong&gt;与&lt;strong&gt;任务生命周期管理&lt;/strong&gt;功能分离，由ResourceManager(RM)负责资源管理，由ApplicationMaster(AM)负责任务所需资源申请管理与任务生命周期管理。这样的好处除了&lt;strong&gt;增强系统的可扩展性&lt;/strong&gt;，&lt;strong&gt;解决JobTracker单点故障问题&lt;/strong&gt;，还&lt;strong&gt;可以部署除MapReduce计算框架外的其他计算框架，共享底层硬件资源&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;以上为YARN的简单介绍，更为详细的YARN学习笔记请参看我的另一篇博文：&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记()-资源调度和管理系统/&quot;&gt;大数据学习笔记()-资源调度和管理系统&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mapreduceyarn&quot;&gt;MapReduce和Yarn的参数配置&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;Yarn中资源的最小单位是容器（Container）。容器是一个Yarn的JVM进程，在MapReduce中，AM服务、map和reduce任务都是运行在一个容器中。可以通过&lt;a href=&quot;http://{RM_IP}:8088/cluster/scheduler&quot;&gt;http://{RM_IP}:8088/cluster/scheduler&lt;/a&gt;来查看正在运行的容器的状态&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在NM中，可以优化的参数有：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.node-manager.resource.memory-mb&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;此参数为物理机可用于分配给容器的&lt;strong&gt;物理内存&lt;/strong&gt;量，注意需要给物理机留出部分资源给操作系统使用，建议为总物理内存的80%~90%，默认为8192。在不同硬件配置的节点中，该值需要根据物理机实际配置来写&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.node-manager.resource.vcore&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;同理，为物理机可用于分配给容器的虚拟CPU数（我理解为线程数），建议为物理CPU核数。默认为8，如果节点CPU核数不够8个，则需要调减小这个值，YARN不会智能的探测节点的物理CPU总数。在不同硬件配置的节点中，该值需要根据物理机实际配置来写&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;此参数是指当任务每使用1MB&lt;strong&gt;物理内存&lt;/strong&gt;，最多可使用默认为2.1MB的&lt;strong&gt;虚拟内存&lt;/strong&gt;量。在JVM中，使用的内存分为虚拟内存和物理内存。JVM中所有存在内存中的对象都是虚拟内存，但在实际运行中只有一部分是实际加载在物理内存中的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在RM中，可以优化的参数有：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.scheduler.minimum-allocation-mb&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;当应用程序向RM申请容器时，RM按照此&lt;strong&gt;物理内存&lt;/strong&gt;量为单位分配给容器，默认为1024。例如，我们设置分配的最小单位为2GB，则RM分配出来的容器内存一定是2G的倍数。假设现在有一个程序向RM申请3.1G的内存，则RM会分配给它一个4GB的容器去执行&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.scheduler.maximum-allocation-mb&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;此参数限定了RM可以分配给一个容器的最大&lt;strong&gt;物理内存&lt;/strong&gt;量，默认为8192。假设应用程序向RM申请的资源超过了这个值，RM会直接拒绝这个请求&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;yarn.scheduler.maximum-allocation-vcores&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;同理，RM可以分配给一个容器的最多虚拟CPU个数，默认为32&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在MapReduce中，可以优化的参数有：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mapreduce.map.memory.mb&lt;/li&gt;
      &lt;li&gt;mapreduce.reduce.memory.mb&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;用于AM向Yarn申请用于map或reduce task的容器时默认使用的&lt;strong&gt;物理内存&lt;/strong&gt;值，其值应该在RM中的一个容器可分配的最大最小内存之间，默认为1024。这个值是全局的，因此需要根据某个job的map或reduce task需要使用的内存量，在程序中覆盖这些参数&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;mapreduce.map.java.opts&lt;/li&gt;
      &lt;li&gt;mapreduce.reduce.java.opts&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;因为Yarn容器可以理解为一个JVM，这两个值主要是为需要运行JVM程序（java、scala等）准备的，用于设置JVM进程的堆大小。这个值应该比上面的物理内存值小（因为JVM除了堆还有别的对象需要占用内存），一般设置为上面值的0.75倍，如果JVM进程在执行中，堆上的对象申请的内存超过这个值，就会抛出OutOfMemory异常&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举个栗子：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;yarn.nodemanager.vmem-pmem-ratio = 2.1&lt;/li&gt;
  &lt;li&gt;yarn.scheduler.minimum-allocation-mb = 1024&lt;/li&gt;
  &lt;li&gt;mapreduce.map.memory.mb = 1536&lt;/li&gt;
  &lt;li&gt;mapreduce.map.java.opts = 1024&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此时，由于mapreduce.map.memory.mb=1536，因此AM将向RM申请一个2048M内存的容器，当map task使用的物理内存量大于2048M时或使用的虚拟内存量大于2048*2.1=3225.6M时将被杀死。容器中有1024M内存用作JVM堆内存，其余内存为非堆内存。当java、scala等进程在堆内存中申请的内存超过1024M，将抛出OutOfMemory异常&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section&quot;&gt;实用工具&lt;/h4&gt;
&lt;hr /&gt;

&lt;p&gt;配置内存参数可以使用&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.6/bk_installing_manually_book/content/determine-hdp-memory-config.html&quot;&gt;yarn-util.py&lt;/a&gt;进行参考&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 查看每个物理CPU中core的个数(即核数)
$ cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq
4
$ python yarn-utils.py -c 4 -m 16 -d 1 -k True
 Using cores=4 memory=16GB disks=1 hbase=True
 Profile: cores=4 memory=12288MB reserved=4GB usableMem=12GB disks=1
 Num Container=3
 Container Ram=4096MB
 Used Ram=12GB
 Unused Ram=4GB
 yarn.scheduler.minimum-allocation-mb=4096
 yarn.scheduler.maximum-allocation-mb=12288
 yarn.nodemanager.resource.memory-mb=12288
 mapreduce.map.memory.mb=4096
 mapreduce.map.java.opts=-Xmx3276m
 mapreduce.reduce.memory.mb=4096
 mapreduce.reduce.java.opts=-Xmx3276m
 yarn.app.mapreduce.am.resource.mb=4096
 yarn.app.mapreduce.am.command-opts=-Xmx3276m
 mapreduce.task.io.sort.mb=1638
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;hadoop-ha273&quot;&gt;安装Hadoop HA（版本2.7.3）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(1)-Overview/&quot;&gt;大数据学习笔记(1)-Overview&lt;/a&gt;和&lt;a href=&quot;https://wuyinan0126.github.io/2017/大数据学习笔记(5)-分布式协调系统/&quot;&gt;大数据学习笔记(5)-分布式协调系统&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Hadoop二进制包，并分发到所有节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/hadoop-2.7.3.tar.gz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/hadoop-2.7.3.tar.gz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建数据文件夹、日志文件夹和myid文件:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -a &#39;mkdir -p /opt/hadoop-2.7.3/var/name&#39;
 $ ansible all -a &#39;mkdir -p /opt/hadoop-2.7.3/var/data&#39;
 $ ansible all -a &#39;mkdir -p /opt/hadoop-2.7.3/var/tmp&#39;
 $ ansible all -a &#39;mkdir -p /opt/hadoop-2.7.3/var/journal&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hadoop-1&quot;&gt;配置Hadoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/core-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;hdfs://cats&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;默认的HDFS路径，与hdfs-site.xml中的配置相关。当有多个HDFS集群存在时，用此名字指定集群&amp;lt;/description&amp;gt; 
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;     
     &amp;lt;value&amp;gt;file:///opt/hadoop-2.7.3/var/tmp&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;NameNode、DataNode、JournalNode等存放数据的公共目录，也可以自己单独指定这三类节点的目录&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hadoop.http.staticuser.user&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;cat&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;WEB UI登录用户，默认为Dr.Who，权限较小&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;10.2.2.141:2181,10.2.2.142:2181,10.2.2.143:2181&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;这里是ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;    
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/hadoop-env.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_PID_DIR=/opt/hadoop-2.7.3/var/tmp
 export HADOOP_SECURE_DN_PID_DIR=/opt/hadoop-2.7.3/var/tmp
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/hdfs-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:///opt/hadoop-2.7.3/var/name&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;NameNode存储命名空间和操作日志相关的元数据信息的本地文件系统路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:///opt/hadoop-2.7.3/var/data&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;DataNode节点存储HDFS文件的本地文件系统路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;指定DataNode存储block的副本数量。默认值是3个，不大于DataNode个数即可&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;    
     &amp;lt;value&amp;gt;cats&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;集群的逻辑名称，自己任意取&amp;lt;/description&amp;gt;     
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.ha.namenodes.cats&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;catk,catq&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;两个namenode的逻辑名称，自己任意取&amp;lt;/description&amp;gt; 
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cats.catk&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;10.2.2.141:8020&amp;lt;/value&amp;gt;  
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.namenode.http-address.cats.catk&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;10.2.2.141:50070&amp;lt;/value&amp;gt;      
   &amp;lt;/property&amp;gt;      
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cats.catq&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;10.2.2.142:8020&amp;lt;/value&amp;gt;      
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.namenode.http-address.cats.catq&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;10.2.2.142:50070&amp;lt;/value&amp;gt;     
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.namenode.servicerpc-address.cats.catk&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;10.2.2.141:53310&amp;lt;/value&amp;gt;  
   &amp;lt;/property&amp;gt;    
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.namenode.servicerpc-address.cats.catq&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;10.2.2.142:53310&amp;lt;/value&amp;gt;  
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;    
     &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled&amp;lt;/name&amp;gt;    
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;指定cats是否自动故障恢复，当NameNode出故障时，是否自动切换到另一台NameNode&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;     
   &amp;lt;!--指定JournalNode --&amp;gt;  
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;       
     &amp;lt;value&amp;gt;qjournal://10.2.2.144:8485;10.2.2.145:8485;10.2.2.146:8485;10.2.2.147:8485;10.2.2.148:8485;10.2.2.149:8485;10.2.2.150:8485;10.2.2.151:8485;10.2.2.152:8485/cats&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;两个NameNode为了数据同步，会通过一组称作JournalNodes的独立进程进行相互通信。当active状态的NameNode的命名空间有任何修改时，会告知大部分的JournalNodes进程。standby状态的NameNode有能力读取JNs中的变更信息，并且一直监控editl og的变化，把变化应用于自己的命名空间。standby可以确保在集群出错时，命名空间状态已经完全同步了。指定cats的两个NameNode共享edits文件目录时，使用的JournalNode集群信息，必须是奇数个，至少3个。&amp;lt;/description&amp;gt;  
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.cats&amp;lt;/name&amp;gt;       
     &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;指定active出故障时，哪个实现类负责执行故障切换&amp;lt;/description&amp;gt;  
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;/opt/hadoop-2.7.3/var/journal&amp;lt;/value&amp;gt;      
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;sshfence&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;主备架构解决单点故障问题时，必须要认真解决的是脑裂问题，即出现两个master同时对外提供服务，导致系统处于不一致状态，可能导致数据丢失等潜在问题。在HDFS HA中，JournalNode只允许一个NameNode写数据，不会出现两个Active NameNode的问题，但是，当主备切换时，之前的Active NameNode可能仍在处理客户端的RPC请求，为此，需要增加隔离机制（ fencing）将之前的Active NameNode杀死。HDFS允许用户配置多个隔离机制，当发生主备切换时，将顺次执行这些隔离机制，直到一个返回成功。隔离机制包括shell和sshfence，sshfence通过ssh登录到前一个ActiveNameNode并将其杀死。为了让该机制成功执行，需配置免密码ssh登陆&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;/home/cat/.ssh/id_rsa&amp;lt;/value&amp;gt;   
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.connect-timeout&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;5000&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;设置一个超时时间，一旦ssh超过该时间，则认为执行失败&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.namenode.handler.count&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;20&amp;lt;/value&amp;gt; 
     &amp;lt;description&amp;gt;设定namenode server threads的数量，这些threads會用RPC跟其他的datanodes沟通。当datanodes数量太多时会发現很容易出現RPC timeout，解決方法是提升网络速度或提高这个值，但要注意的是thread数量多也表示namenode消耗的内存也随着增加&amp;lt;/description&amp;gt; 
   &amp;lt;/property&amp;gt; 
   &amp;lt;!-- 用户权限管理 --&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;dfs.permissions.enabled&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;权限管理&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.namenode.acls.enabled&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;权限访问控制列表&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;!-- 用户权限管理 --&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/mapred-env.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_MAPRED_PID_DIR=/opt/hadoop-2.7.3/var/tmp
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/mapred-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;  
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.map.memory.mb&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;1536&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;每个Map Task需要的虚拟内存限制，例如需要1536MB内存时，yarn将分配一个2倍最小容器内存2048M单位的容器，这个值可以在程序中设定被覆盖&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.reduce.memory.mb&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;1536&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;每个Reduce Task需要的虚拟内存限制，一般为Map的两倍，这个值可以在程序中设定被覆盖&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.map.java.opts&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;-Xmx1024m -XX:MaxPermSize=64m&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;设置Map Task的JVM的堆空间大小，因为Map Task分配了4096MB内存，其中3596MB内存给了java、scala等程序，这个值应该比上面的task的虚拟内存值小（因为jvm除了heap还有别的对象需要占用内存），如果jvm进程在执行中heap上的对象占用内存超过这个值， 则会抛出OutOfMemory Exception，这个值可以在程序中设定被覆盖&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.reduce.java.opts&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;-Xmx1024m -XX:MaxPermSize=64m&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;设置Reduce Task的JVM的堆空间大小，这个值可以在程序中设定被覆盖&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;mapreduce.task.io.sort.mb&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;512&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;任务内部排序缓冲区大小&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/slaves&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # datanode的ip地址
 10.2.2.143...152
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/yarn-env.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;etc/hadoop/yarn-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;!-- ResourceManager相关配置参数 --&amp;gt;
   &amp;lt;property&amp;gt;
   	&amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;
   	&amp;lt;value&amp;gt;1024&amp;lt;/value&amp;gt;
   	&amp;lt;description&amp;gt;每个Task申请容器的最小内存单位，默认1024MB，例如Task需要1025M内存时会分配2*1024M内存的容器&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-mb&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;12288&amp;lt;/value&amp;gt;
     &amp;lt;discription&amp;gt;单个任务可申请容器的最大内存，默认8192MB。由于Yarn集群还需要跑Spark的任务，而Spark的Worker内存相对需要大些，所以需要调大单个任务的最大内存&amp;lt;/discription&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-vcores&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;8&amp;lt;/value&amp;gt;
     &amp;lt;discription&amp;gt;单个任务可申请容器的最大虚拟核数，默认8个核&amp;lt;/discription&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;      
     &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;      
     &amp;lt;value&amp;gt;10.2.2.141&amp;lt;/value&amp;gt;  
     &amp;lt;description&amp;gt;resourcemanager只有一个，设置它的主机位置&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;  
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.address&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;10.2.2.141:8032&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;ResourceManager对客户端暴露的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.address&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;10.2.2.141:8030&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;ResourceManager对ApplicationMaster暴露的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.resource-tracker.address&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;10.2.2.141:8031&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;ResourceManager对NodeManager暴露的地址。NodeManager通过该地址向ResourceManager汇报心跳，领取任务等&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.admin.address&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;10.2.2.141:8033&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;ResourceManager对管理员暴露的访问地址。管理员通过该地址向RM发送管理命令等&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;10.2.2.141:8088&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;ResourceManager对外web ui地址。用户可通过该地址在浏览器中查看集群各类信息&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;!-- NodeManager相关配置参数 --&amp;gt;
   &amp;lt;property&amp;gt;
   	&amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;
   	&amp;lt;value&amp;gt;12288&amp;lt;/value&amp;gt;
   	&amp;lt;description&amp;gt;NodeManager总的可用物理内存，必须给物理机留一些内存和计算资源给到操作系统使用，不能用光，16G*85%&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
   	&amp;lt;name&amp;gt;yarn.nodemanager.resource.cpu-vcores&amp;lt;/name&amp;gt;
   	&amp;lt;value&amp;gt;8&amp;lt;/value&amp;gt;
   	&amp;lt;description&amp;gt;该节点上YARN可使用的虚拟CPU个数，默认是8，注意，目前推荐将该值设值为与物理CPU核数数目相同。如果你的节点CPU核数不够8个，则需要调减小这个值，而YARN不会智能的探测节点的物理CPU总数&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
   	&amp;lt;name&amp;gt;yarn.nodemanager.vmem-pmem-ratio&amp;lt;/name&amp;gt;
   	&amp;lt;value&amp;gt;2.1&amp;lt;/value&amp;gt;
   	&amp;lt;description&amp;gt;当map或reduce任务使用内存超过mapreduce.map.memory.mb或mapreduce.reduce.memory.mb时，将增加内存至2.1倍的mapreduce.reduce.memory.mb或者mapreduce.map.memory.mb&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;  
     &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;  
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.class&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;	org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;启用的资源调度器主类。目前可用的有FIFO、Capacity Scheduler和Fair Scheduler&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.nodemanager.remote-app-log-dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;/tmp/logs&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;!-- ApplicationMaster相关配置参数 --&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;yarn.app.mapreduce.am.resource.mb&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;1536&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;MR ApplicationMaster占用的内存量&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;  
     &amp;lt;name&amp;gt;yarn.app.mapreduce.am.command-opts&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;-Xmx1024m -XX:MaxPermSize=64m&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;!-- historyserver configue start --&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;!-- historyserver configue end --&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Hadoop配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hadoop-2.7.3/etc/hadoop/ dest=/opt/hadoop-2.7.3/etc/hadoop/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hadoop-2&quot;&gt;启动Hadoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;确保Zookeeper已经启动：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;/opt/zookeeper-3.4.9/bin/zkServer.sh start&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)格式化集群&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hdfs zkfc -formatZK
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)检验集群是否格式化，ls /是否出现了hadoop-ha&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkCli.sh
 [zk: localhost:2181(CONNECTED) 0] ls /
 [zookeeper, hadoop-ha]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)启动hadoop集群&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;启动所有journalnode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop-daemons.sh start journalnode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在cat1格式化namenode，输出日志中是否出现successfully formatted&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat1:~$ hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动cat1中的namenode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat1:~$ hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在cat2中同步namenode数据&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat2:~$ hdfs namenode -bootstrapStandby
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动cat2中的namenode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat2:~$ hadoop-daemon.sh start namenode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动所有datanode&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop-daemons.sh start datanode
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;启动yarn&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在cat1和cat2中都启动ZooKeeperFailoverController（此时cat1变为active，cat2为standby）&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible namenode -a &#39;/opt/hadoop-2.7.3/sbin/hadoop-daemon.sh start zkfc&#39;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hadoop-3&quot;&gt;测试Hadoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;使用jps查看各节点起的进程&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -a &#39;/opt/jdk1.8.0_121/bin/jps&#39;

 cat1: QuorumPeerMain, DFSZKFailoverController, NameNode, ResourceManager
 cat2: QuorumPeerMain, DFSZKFailoverController, NameNode
 cat3: QuorumPeerMain, JournalNode, DataNode, NodeManager
 cat4-12: JournalNode, DataNode, NodeManager
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看&lt;a href=&quot;http://10.2.2.141:50070/&quot;&gt;http://10.2.2.141:50070/&lt;/a&gt;中cat1是否为active，查看&lt;a href=&quot;http://10.2.2.142:50070/&quot;&gt;http://10.2.2.142:50070/&lt;/a&gt;中cat2是否为standby&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)运行wordcount例子:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir /test
 $ hadoop fs -mkdir /test/input
 $ hadoop fs -put ./words.txt /test/input
 $ hadoop jar /opt/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /test/input/ /test/output
 $ hadoop fs -cat /test/output/part-r-00000
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hadoop-4&quot;&gt;创建Hadoop用户&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;创建用户组&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo groupadd admire
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建用户&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo useradd -g admire -d /home/wyn -m wyn -s /bin/bash
 $ sudo passwd wyn
 $ hadoop fs -mkdir /user/wyn
 $ hadoop fs -chown -R wyn:supergroup /user/wyn
 $ hadoop fs -chmod 700 /user/wyn
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;spark-on-yarnhttpswuyinan0126githubio20176-spark&quot;&gt;下一步：&lt;a href=&quot;https://wuyinan0126.github.io/2017/大数据学习笔记(6)-Spark/&quot;&gt;安装Spark on Yarn&lt;/a&gt;&lt;/h2&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 01 Dec 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)-Hadoop/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)-Hadoop/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(1)-Overview</title>
        <description>&lt;p&gt;&lt;em&gt;系统学习大数据生态圈中的理论知识和常用工具，并通过ansible集群管理工具在12台物理机上搭建分布式的大数据平台，包括Hadoop、Spark、Hive、Zookeeper、Kafka等常用大数据工具及其涉及的理论知识&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;环境配置&lt;/h2&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;12台DELL T1700图形工作站，每台配置：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;CPU：1颗4核8线程&lt;/li&gt;
      &lt;li&gt;内存：16GB DDR3&lt;/li&gt;
      &lt;li&gt;存储：1TB TOSHIBA DT01ACA100&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;大数据平台架构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-11-16-1.jpeg&quot; alt=&quot;大数据平台架构&quot; title=&quot;大数据平台架构&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;准备工作&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有节点配置sudo免密码：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo visudo -f /etc/sudoers
 ...
 %sudo   ALL=(ALL:ALL) ALL
 cat     ALL=(ALL) NOPASSWD:NOPASSWD:ALL
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)使用集群管理工具ansible：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;在cat1中生成密钥对，并将公钥加入各节点authorized_keys中：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ssh-keygen -t rsa
 $ cat id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
 $ scp ~/.ssh/authorized_keys cat@cat[2:12]:/home/cat/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;安装ansible：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install ansible
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改配置文件/etc/ansible/hosts，加入：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [all]
 cat[1:12]

 [master]
 cat1

 [slave]
 cat[2:12]

 [zookeeper]
 cat[1:3]

 [namenode]
 cat[1:2]

 [datanode]
 cat[3:12]
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;测试：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible master -m ping 
 $ ansible slave -m ping 
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/hosts文件，加入：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 【坑】注释掉127.0.1.1	{主机名}
 10.2.2.141      cat1
 10.2.2.142      cat2
 10.2.2.143      cat3
 10.2.2.144      cat4
 10.2.2.145      cat5
 10.2.2.146      cat6
 10.2.2.147      cat7
 10.2.2.148      cat8
 10.2.2.149      cat9
 10.2.2.150      cat10
 10.2.2.151      cat11
 10.2.2.152      cat12

 $ ansible slave -s -m copy -a &#39;src=/etc/hosts dest=/etc/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编写ansible-playbook文件init.yml：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ---

 - hosts: all
   tasks:

   - name: turn off ufw			# 关闭防火墙
     shell: iptables -F
     sudo: yes

   - name: create workspace		# 创建工作目录和.ssh
     shell: mkdir -p /home/cat/cat

   - name: chown -R cat:cat /opt # 修改/opt文件夹拥有者
     shell: chown -R cat:cat /opt
     sudo: yes

   - name: install ntp 			# 安装ntp，同步各节点时间
     shell: apt-get -y install ntp
     sudo: yes
   - name: config ntp 			# 配置/etc/ntp.conf文件, 注释原来的ntp server, 使用aliyun时间服务器
     shell: sed -i &quot;s/pool 0.u.*/pool time1.aliyun.com iburst/g&quot; /etc/ntp.conf
     shell: sed -i &quot;s/pool 1.u.*/pool time2.aliyun.com iburst/g&quot; /etc/ntp.conf 
     shell: sed -i &quot;s/pool 2.u.*/pool time3.aliyun.com iburst/g&quot; /etc/ntp.conf 
     shell: sed -i &quot;s/pool 3.u.*/pool time4.aliyun.com iburst/g&quot; /etc/ntp.conf 
     shell: sed -i &quot;s/pool ntp.ubuntu.com/# pool ntp.ubuntu.com/g&quot; /etc/ntp.conf
     sudo: yes
   - name: restart ntp 			# 重启ntp服务
     shell: service ntp restart
     sudo: yes
   - name: check ntp 			# 验证时间是否同步，检查condition列是否有至少一个sys.peer
     shell: ntpq -c assoc

   - name: check ssh keys 		# 检查是否已生成密钥对
     stat: path=/home/cat/.ssh/id_rsa
     register: keys
   - name: generate ssh keys 	# 在各节点生成密钥对
     shell: ssh-keygen -t rsa -f /home/cat/.ssh/id_rsa -q -N &quot;&quot;
     when: not keys.stat.exists
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在所有节点)将每个节点的公钥写入同一份.ssh/authorized_keys中，并分发给所有节点：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/home/cat/.ssh/authorized_keys dest=/home/cat/.ssh/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在所有节点)安装JDK：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;(在cat1)下载jdk，并分发到各从节点:&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/home/cat/cat/jdk-8u121-linux-x64.tar.gz dest=/home/cat/cat/&#39;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;(在所有节点)安装jdk:&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -a &#39;tar -zxvf /home/cat/cat/jdk-8u121-linux-x64.tar.gz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在所有节点)修改/etc/profile:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;(在主节点)修改/etc/profile，在末尾添加：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
 export HADOOP_HOME=/opt/hadoop-2.7.3
 export SCALA_HOME=/opt/scala-2.11.8
 export SPARK_HOME=/opt/spark-2.1.0
 export HIVE_HOME=/opt/hive-2.1.0
 export ZOOKEEPER_HOME=/opt/zookeeper-3.4.9
 export SQOOP_HOME=/opt/sqoop-1.4.6
 export KAFKA_HOME=/opt/kafka-0.10.2.0

 export PATH=$PATH:$JAVA_HOME/bin
 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
 export PATH=$PATH:$HIVE_HOME/bin
 export PATH=$PATH:$SCALA_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin
 export PATH=$PATH:$ZOOKEEPER_HOME/bin
 export PATH=$PATH:$SQOOP_HOME/bin
 export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;(在所有节点)分发/etc/profile，需要加上-s参数，使其使用sudo权限copy：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -s -m copy -a &#39;src=/etc/profile dest=/etc/&#39;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;zookeeperhttpswuyinan0126githubio20175-&quot;&gt;下一步：&lt;a href=&quot;https://wuyinan0126.github.io/2017/大数据学习笔记(5)-分布式协调系统/&quot;&gt;安装分布式协调系统——Zookeeper&lt;/a&gt;&lt;/h2&gt;
&lt;hr /&gt;
</description>
        <pubDate>Wed, 16 Nov 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)-Overview/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)-Overview/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; GitHub个人博客搭建</title>
        <description>&lt;p&gt;&lt;em&gt;使用Jekyll-Uno模版在GitHub上搭建个人博客，并添加评论和Google Analytics的功能。包括GitHub相关准备工作、本地开发环境的搭建和其它实用工具&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;github&quot;&gt;GitHub相关准备工作&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;在自己的GitHub仓库中创建名为username.github.io的项目，例如wuyinan0126.github.io&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将你的username.github.io项目（以下称根目录）git clone到本地&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cd $MY_WORKSPACE
 $ git clone https://github.com/username/username.github.io.git
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Jekyll-Uno模版并解压&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ wget https://github.com/joshgerdes/jekyll-uno/archive/master.zip
 $ unzip jekyll-uno-master.zip
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将解压后的jekyll-uno-master目录中的所有文件复制进根目录&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cp -r ./jekyll-uno-master/* ./username.github.io/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;进入根目录，修改配置文件_config.yml，将url和baseurl修改为&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cd username.github.io
 $ vi ./_config.yml
   -	url: &#39;https://username.github.io&#39;
   -	baseurl: &#39;/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在根目录，提交并上传更新&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ git add .
 $ git commit -a -m &quot;Initial Blog&quot;
 $ git push origin master
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;查看你的GitHub仓库中的username.github.io项目，确认代码上传成功。然后，访问http://username.github.io。Suprise！至此，我们已经将Jekyll-Uno模版展示在我们的个人博客上了！&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;jekyll-server&quot;&gt;使用Jekyll Server进行本地预览&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;安装Ruby和RubyGems，并将Ruby源替换为Ruby淘宝镜像源&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ gem sources --remove https://rubygems.org/ 
 $ gem sources -a https://ruby.taobao.org/ 
 $ gem sources -l  
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在根目录，安装Jekyll Server&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ gem install bundler
 $ bundle install
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在根目录，启动Jekyll Server&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ bundle exec jekyll serve --watch
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在&lt;a href=&quot;http://localhost:4000/&quot;&gt;http://localhost:4000/&lt;/a&gt;查看本地预览&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;sublime-2omnimarkuppreviewer&quot;&gt;使用Sublime 2和OmniMarkupPreviewer进行博文撰写&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;安装Sublime 2，并在Package Control中输入Install Package，搜索并安装OmniMarkupPreviewer。重启Sublime 2&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;进入根目录下的_posts目录，这是用于存放博文的地方，新建一个相同命名格式的文件，例如2016-09-15-GitHub个人博客搭建.markdown，并使用&lt;a href=&quot;http://www.appinn.com/markdown/#autoescape&quot;&gt;markdown语法&lt;/a&gt;进行博文撰写&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在Sublime 2的Markdown标签页点击鼠标右键，选择Preview Current Markup in Browser。或者使用快捷键（OSX ⌘+⌥+O; Windows, Linux Ctrl+Alt+O）来实时预览&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对根目录内容进行修改后，提交并上传更新&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ git add .
 $ git commit -a -m &quot;COMMENT&quot;
 $ git push origin master
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section&quot;&gt;添加评论功能&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;注册&lt;a href=&quot;https://disqus.com/&quot;&gt;Disqus&lt;/a&gt;账户，点击“I want to install Disqus on my site”，并填写基本信息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择平台。选择“install manually with Universal Code”，将获得的代码复制到根目录下的_includes/disqus.html中，Universal Code中需要修改的地方如下&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; var disqus_config = function () {
   this.page.url = &#39;{{ site.url }}{{ page.url }}&#39;; 
   this.page.identifier = &#39;{{ page.id }}&#39;; 
   this.page.title = &#39;{{ page.title }}&#39;;
 };
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改根目录下的_config.yml，取消注释&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; disqus_shortname: &#39;Disqus用户名&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;google-analytics&quot;&gt;添加Google Analytics&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;登录Google Analytics创建新网站，生成跟踪ID&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改根目录下的_config.yml，取消注释&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; google_analytics: &#39;跟踪ID&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-1&quot;&gt;页面布局修改&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;首页添加tag选项&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录下_includes/header.html:&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;nav class=&quot;cover-navigation cover-navigation--primary&quot;&amp;gt;
  &amp;lt;ul class=&quot;navigation&quot;&amp;gt;
    &amp;lt;li class=&quot;navigation__item&quot;&amp;gt;&amp;lt;a href=&quot;{{ site.baseurl }}#blog&quot; title=&quot;link to {{ site.title }} blog&quot; class=&quot;blog-button&quot;&amp;gt;Blog&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;/ul&amp;gt;
  &amp;lt;/nav&amp;gt;

 +++
 &amp;lt;nav class=&quot;cover-navigation cover-navigation--primary&quot;&amp;gt;
 &amp;lt;ul class=&quot;navigation&quot;&amp;gt;
  &amp;lt;li class=&quot;navigation__item&quot;&amp;gt;&amp;lt;a href=&quot;{{ site.baseurl }}tags&quot; title=&quot;link to {{ site.title }} tags&quot; class=&quot;blog-button&quot;&amp;gt;Tags&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
 &amp;lt;/ul&amp;gt;
 &amp;lt;/nav&amp;gt;
 +++
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录下_layouts/tags.html:&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;a href=&quot;{{ post.url }}&quot;&amp;gt;{{ post.title }}&amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;博文页添加“上一篇”“下一篇”按钮&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录下css/main.css，在最后添加:&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; .page_navigation {
   font-size: 14px;
   display: block;
   width: auto;
   overflow: hidden;
 }

 .page_navigation a {
   display: block;
   width: 50%;
   float: left;
   margin: 1em 0;
 }

 .page_navigation .next {
   text-align: right;
 }
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录下_layouts/post.html，添加：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;section class=&quot;post&quot;&amp;gt;
 {{ content }}
 +++
     &amp;lt;div class=&quot;page_navigation&quot;&amp;gt;
     {% if page.previous %}
       &amp;lt;a class=&quot;prev&quot; href=&quot;{{page.previous.url}}&quot;&amp;gt;&amp;amp;laquo; {{page.previous.title}}&amp;lt;/a&amp;gt;
     {% endif %}
     {% if page.next %}
       &amp;lt;a class=&quot;next&quot; href=&quot;{{page.next.url}}&quot;&amp;gt;{{page.next.title}} &amp;amp;raquo;&amp;lt;/a&amp;gt;
     {% endif %}
     &amp;lt;/div&amp;gt;
 +++
 &amp;lt;/section&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;添加页面，例如About Me页面&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;在根目录下新建me.md，内容如下：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ---
 layout: me
 title: About Me
 permalink: /me/
 ---
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在根目录的_layouts中新建me.html，内容如下：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ---
 layout: default
 ---

 &amp;lt;article id=&quot;about-me&quot; class=&quot;post-container post-container--single&quot;&amp;gt;
   &amp;lt;h1 class=&quot;post-title&quot;&amp;gt;About Me&amp;lt;/h1&amp;gt;
   &amp;lt;/header&amp;gt;
   &amp;lt;section class=&quot;post&quot;&amp;gt;
     {% capture about %}{% include me.md %}{% endcapture %}
     {{ about | markdownify }}
   &amp;lt;/section&amp;gt;
 &amp;lt;/article&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在根目录的_includes中新建me.md，内容为你想展示在页面的内容&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录的_includes/header.html，添加按钮：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;nav class=&quot;cover-navigation cover-navigation--primary&quot;&amp;gt;
   &amp;lt;ul class=&quot;navigation&quot;&amp;gt;
     &amp;lt;li class=&quot;navigation__item&quot;&amp;gt;&amp;lt;a href=&quot;{{ site.baseurl }}me&quot; title=&quot;link to {{ site.title }} about me&quot; class=&quot;blog-button&quot;&amp;gt;Me&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
   &amp;lt;/ul&amp;gt;
 &amp;lt;/nav&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;显示表格边界&lt;/p&gt;

    &lt;p&gt;在根目录的css/main.css中添加：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;style type=&quot;text/css&quot;&amp;gt;
 table{
     border-collapse: collapse;
     border-spacing: 0;
     border: 1px solid #F3F3F3;
 }

 th{
     border: 1px solid #F3F3F3;
     padding: 6px 13px
 }

 td{
     border: 1px solid #F3F3F3;
     padding: 6px 13px
 }
 &amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改blog页面中左边封面和右边博文列表比例&lt;/p&gt;

    &lt;p&gt;css/uno.css:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; .content-wrapper {
     z-index: 800;
 -	width: 60%;
 +	width: 80%;
 -	max-width: 800px;
 +	max-width: 1200px;
     margin-left: 40%; }

 .panel-cover--collapsed {
     width: 40%;
 - 	max-width: 530px; }
 +	max-width: 400px; }

 .no-js .panel-main {
     width: 40%;
 - 	max-width: 530px; }
 +	max-width: 400px; }

 @media all and (min-width: 1300px) {
     .content-wrapper {
 -		margin-left: 530px; } }
 +		margin-left: 400px; } }
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;js/main.js:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; - $(&#39;.panel-cover&#39;).animate({&#39;max-width&#39;: &#39;530px&#39;, &#39;width&#39;: &#39;40%&#39;}
 + $(&#39;.panel-cover&#39;).animate({&#39;max-width&#39;: &#39;400px&#39;, &#39;width&#39;: &#39;40%&#39;}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-2&quot;&gt;其它实用工具&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;使用MathJax引擎在markdown中插入公式&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;在Sublime 2的Package Settings中选择OmniMarkupPreviewer，修改default setting中的&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &quot;mathjax_enabled&quot;: true
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;以启用MathJax引擎&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改根目录下的_includes/head.html文件，在&amp;lt;head&amp;gt;标签中添加&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;以在页面渲染时加载MathJax.js&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;测试。在markdown文件中输入&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $$x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$$
 \\(x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}\\)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;上面为行间公式，下面为行内公式。使用Sublime 2的OmniMarkupPreviewer或Jekyll Server进行预览&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在markdown中链接本地图片&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;在根目录中新建一个用于存放你的图片的文件夹，例如assets，放入图片，例如test.jpg&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在markdown文件中链接&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ![TITLE](/assets/test.jpg &quot;TITLE&quot;)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;此适用于Jekyll Server进行预览，不适用于OmniMarkupPreviewer预览&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;语法高亮&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;语法高亮将仅支持Rouge&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ rougify help style
 usage: rougify style [&amp;lt;theme-name&amp;gt;] [&amp;lt;options&amp;gt;]

 Print CSS styles for the given theme.  Extra options are
 passed to the theme.  Theme defaults to thankful_eyes.

 options:
   --scope	(default: .highlight) a css selector to scope by

 available themes:
   base16, base16.dark, base16.monokai, base16.monokai.light, base16.solarized, base16.solarized.dark, colorful, github, molokai, monokai, monokai.sublime, thankful_eyes
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用Rouge生成样式&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ rougify style colorful &amp;gt; css/colorful.css
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;修改css/main.css&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; @import url(colorful.css);
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;highlight&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;bash&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;代码&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;endhighlight&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

</description>
        <pubDate>Fri, 08 Jan 2016 23:04:23 +0800</pubDate>
        <link>https://wuyinan0126.github.io//2016/GitHub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io//2016/GitHub%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
        
        <category>原创</category>
        
        <category>技术宅</category>
        
        
        <category>原创</category>
        
        <category>技术宅</category>
        
      </item>
    
  </channel>
</rss>
