<p><em>简单学习Hadoop相关知识，包括MapReduce计算框架、HDFS文件系统、YARN资源调度与管理系统，并在OpenStack上搭建Hadoop平台(HA)</em></p>

<h2 id="hadoop">Hadoop</h2>
<hr />

<h3 id="mapreduce">MapReduce</h3>

<p>大数据计算中最常见的一种计算方式是<strong>批处理</strong>。2004年Google发表了MapReduce计算范型和框架论文，这是一种构建在大规模PC之上的批处理计算框架，也是一种分布式计算模型，获得了极为广泛的应用。</p>

<p>MapReduce和传统的并行数据库系统(MPP)相比，更适合<strong>非结构化数据的ETL处理</strong>(将数据从来源端经过抽取(extract)、转换(transform)、加载(load)至目的端的过程)，且其更具有<strong>扩展性和容错性</strong>，但单机处理效率低。</p>

<p>MapReduce计算提供了简洁的编程接口，<strong>输入和输出均是Key/Value键值对</strong>，只需根据业务逻辑实现Map和Reduce函数即可完成大规模数据的并行批处理任务。</p>

<ul>
  <li>Map函数以Key/Value作为输入，经逻辑计算产生若干仍以Key/Value形式表达的中间数据。计算框架自动将中间数据中具有相同Key值的记录聚在一起，传递给Reduce函数作为输入</li>
  <li>Reduce函数以Map阶段传递过来的某个Key值及其对应的若干Value值作为输入，对这些Value进行逻辑计算，生成Key/Value即计算结果</li>
</ul>

<p>以上为MapReduce简介，更为详细的MapReduce计算模型学习笔记请参看我的另一篇博文：<a href="https://wuyinan0126.github.io/2016/大数据学习笔记(3)-MapReduce/">大数据学习笔记(3)-MapReduce</a></p>

<h3 id="hdfs">HDFS</h3>

<h3 id="yarn">YARN</h3>

<p>YARN的全称是”Yet Another Resource Negotiator”，是一个独立的<strong>资源调度与管理系统</strong>。</p>

<p>在Hadoop1.x中，所有任务的<strong>资源管理</strong>以及<strong>生命周期管理</strong>都由全局唯一的JobTracker负责，造成其功能繁复，限制了系统的可扩展性。同时JobTracker还存在单点失效的问题，一旦JobTracker故障，整个Hadoop集群将崩溃。</p>

<p>在Hadoop2.x中，将<strong>资源管理</strong>与<strong>任务生命周期管理</strong>功能分离，由ResourceManager(RM)负责资源管理，由ApplicationMaster(AM)负责任务所需资源申请管理与任务生命周期管理。这样的好处除了<strong>增强系统的可扩展性</strong>，<strong>解决JobTracker单点故障问题</strong>，还<strong>可以部署除MapReduce计算框架外的其他计算框架，共享底层硬件资源</strong>。</p>

<h2 id="hadoop273">安装Hadoop（版本2.7.3）</h2>
<hr />

<h4 id="section">准备工作</h4>
<ol>
  <li>
    <p>SSH免密码登录:</p>

    <ol>
      <li>
        <p>生成密钥:</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ ssh-keygen -t dsa
</code></pre>
        </div>
      </li>
      <li>
        <p>生成authorized_keys，进入.ssh目录:</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ cat id_dsa.pub &gt;&gt; authorized_keys
 $ chmod 600 authorized_keys
</code></pre>
        </div>
      </li>
      <li>
        <p>测试:</p>

        <div class="highlighter-rouge"><pre class="highlight"><code> $ ssh localhost
</code></pre>
        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>下载Hadoop二进制包（或源码自行编译），解压至/opt/:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ tar -zxvf ./hadoop-2.7.3.tar.gz -C /opt/
</code></pre>
    </div>
  </li>
</ol>

<h4 id="hadoop-1">配置Hadoop</h4>
<ol>
  <li>
    <p>etc/hadoop/core-site.xml:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
     &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
     &lt;description&gt;默认的HDFS路径，与hdfs-site.xml中的配置相关。当有多个HDFS集群存在时，用此名字指定集群&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
     &lt;value&gt;/opt/hadoop-2.7.3/var/tmp&lt;/value&gt; 
     &lt;description&gt;NameNode、DataNode、JournalNode等存放数据的公共目录，也可以自己单独指定这三类节点的目录&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;hadoop.proxyuser.wuyinan.groups&lt;/name&gt;
     &lt;value&gt;*&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;hadoop.proxyuser.wuyinan.hosts&lt;/name&gt;
     &lt;value&gt;*&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/hdfs-site.xml:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
     &lt;value&gt;/opt/hadoop-2.7.3/var/name&lt;/value&gt;
     &lt;description&gt;NameNode存储命名空间和操作日志相关的元数据信息的本地文件系统路径&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
     &lt;value&gt;/opt/hadoop-2.7.3/var/data&lt;/value&gt;
     &lt;description&gt;DataNode节点存储HDFS文件的本地文件系统路径&lt;/description&gt; 
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;dfs.replication&lt;/name&gt;
     &lt;value&gt;1&lt;/value&gt;
     &lt;description&gt;指定DataNode存储block的副本数量。默认值是3个，不大于DataNode个数即可&lt;/description&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/mapred-site.xml:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt; 
     &lt;description&gt;指定运行mapreduce的环境是yarn&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;mapreduce.tasktracker.map.tasks.maximum&lt;/name&gt;
     &lt;value&gt;2&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;mapreduce.tasktracker.reduce.tasks.maximum&lt;/name&gt;
     &lt;value&gt;2&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/yarn-site.xml:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> &lt;configuration&gt;
   &lt;property&gt;      
     &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;      
     &lt;value&gt;localhost&lt;/value&gt;  
     &lt;description&gt;指定ResourceManager的地址&lt;/description&gt;
     &lt;/property&gt;  
   &lt;property&gt;  
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;  
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;  
     &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
     &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
   &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
     &lt;value&gt;/tmp/logs&lt;/value&gt;
     &lt;description&gt;&lt;/description&gt;
     &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/mapred-env.sh:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home
 export HADOOP_MAPRED_PID_DIR=/opt/hadoop-2.7.3/var/tmp
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/hadoop-env.sh:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home
 export HADOOP_PID_DIR=/opt/hadoop-2.7.3/var/tmp
 export HADOOP_SECURE_DN_PID_DIR=/opt/hadoop-2.7.3/var/tmp
</code></pre>
    </div>
  </li>
  <li>
    <p>etc/hadoop/slaves:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> localhost
</code></pre>
    </div>
  </li>
</ol>

<h4 id="hadoop-2">启动Hadoop</h4>
<ol>
  <li>
    <p>根据hadoop.tmp.dir, dfs.namenode.name.dir, dfs.datanode.name.dir在相应位置创建目录</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ mkdir /opt/hadoop-2.7.3/var/
 $ mkdir /opt/hadoop-2.7.3/var/tmp
 $ mkdir /opt/hadoop-2.7.3/var/name
 $ mkdir /opt/hadoop-2.7.3/var/data
</code></pre>
    </div>
  </li>
  <li>
    <p>格式化namenode，如果Exiting with status 0，说明格式化成功:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hdfs namenode -format
</code></pre>
    </div>
  </li>
  <li>
    <p>启动namenode、datanode、yarn，每启动一个后都用jps查看是否启动成功，最后启动的进程应该包括NameNode、DataNode、ResorceManager、NodeManager:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop-daemon.sh start namenode
 $ hadoop-daemon.sh start datanode
 $ start-yarn.sh
</code></pre>
    </div>
  </li>
  <li>
    <p>在浏览器查看：<a href="http://localhost:50070/">http://localhost:50070/</a>和<a href="http://localhost:8088/">http://localhost:8088/</a></p>
  </li>
  <li>
    <p>测试，运行wordcount例子:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop fs -mkdir /test
 $ hadoop fs -mkdir /test/input
 $ hadoop fs -put ./words.txt /test/input
 $ hadoop jar /opt/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /test/input/ /test/output
 $ hadoop fs -cat /test/output/part-r-00000
</code></pre>
    </div>
  </li>
</ol>
