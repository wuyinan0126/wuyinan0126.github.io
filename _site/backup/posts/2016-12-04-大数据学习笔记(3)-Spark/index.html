<p>**</p>

<h2 id="scala2118">安装Scala（版本2.11.8）</h2>
<hr />
<ol>
  <li>
    <p>下载Scala二进制包，解压至/opt/:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ tar -zxvf ./scala-2.11.8.tgz -C /opt/
</code></pre>
    </div>
  </li>
</ol>

<h2 id="spark210">安装Spark（版本2.1.0）</h2>
<hr />

<h4 id="section">准备工作</h4>
<ol>
  <li>
    <p>下载Spark二进制包（或源码自行编译），解压至/opt/:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ tar -zxvf ./spark-2.1.0-bin-hadoop2.7 -C /opt/
 $ mv /opt/spark-2.1.0-bin-hadoop2.7 /opt/spark-2.1.0
</code></pre>
    </div>
  </li>
</ol>

<h4 id="spark">配置Spark</h4>
<ol>
  <li>
    <p>conf/spark-env.sh:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Home
 export HADOOP_HOME=/opt/hadoop-2.7.3
 export SCALA_HOME=/opt/scala-2.11.8	
	
 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export HDFS_CONF_DIR=$HADOOP_HOME/etc/hadoop
 export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

 # spark.history.retainedApplications仅显示最近50个应用
 export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=3 -Dspark.history.fs.logDirectory=file:/tmp/spark-events"
</code></pre>
    </div>
  </li>
  <li>
    <p>conf/slaves:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> localhost
</code></pre>
    </div>
  </li>
  <li>
    <p>conf/spark-defaults.conf:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> # 对于Spark Job启用log event配置，是否记录Spark事件，用于应用程序在完成后重构webUI
 spark.eventLog.enabled           true
 spark.eventLog.dir               file:/tmp/spark-events
 spark.eventLog.compress          true
</code></pre>
    </div>
  </li>
</ol>

<h4 id="spark-1">启动Spark</h4>
<ol>
  <li>
    <p>启动Hadoop</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ hadoop-daemon.sh start namenode
 $ hadoop-daemon.sh start datanode
 $ start-yarn.sh
</code></pre>
    </div>
  </li>
  <li>
    <p>启动Spark，用jps查看，启动的进程应包括Master、Worker:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ /opt/spark-2.1.0/sbin/start-all.sh
</code></pre>
    </div>
  </li>
  <li>
    <p>先创建history默认存放位置，启动HistoryServer，启动的进程应包括HistoryServer：</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ mkdir /tmp/spark-events/
 $ /opt/spark-2.1.0/sbin/start-history-server.sh
</code></pre>
    </div>
  </li>
  <li>
    <p>测试，运行SparkPi例子:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ cd /opt/spark-2.1.0
 $ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \
 --master yarn-cluster \
 --num-executors 3 \
 --driver-memory 2g \
 --executor-memory 1g \
 --executor-cores 1 \
 --queue thequeue \
 examples/jars/spark-examples_2.11-2.1.0.jar \
 10
</code></pre>
    </div>
  </li>
  <li>
    <p>查看结果:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> $ yarn logs -applicationId ${applicationId} | grep 'Pi'
</code></pre>
    </div>
  </li>
  <li>
    <p>在界面<a href="http://127.0.0.1:18080/">http://127.0.0.1:18080/</a>查看历史</p>
  </li>
</ol>

