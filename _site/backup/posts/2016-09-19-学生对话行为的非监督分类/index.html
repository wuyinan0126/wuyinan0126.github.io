<p><em>文章介绍了一种针对学生对话行为的非监督分类方法。首先对学生对话使用词性标签进行自然语言预处理，然后使用Query-Likelihood进行相似对话行为的信息检索，最后使用k-means聚类算法将相似对话行为进行聚类</em></p>

<h2 id="section">文章</h2>

<blockquote>
  <p><a href="http://www.educationaldatamining.org/EDM2013/papers/rn_paper_06.pdf">Unsupervised Classification of Student Dialogue Acts With Query-Likelihood Clustering</a></p>
</blockquote>

<h2 id="section-1">语料库</h2>
<hr />

<p>语料库由参与2007春的JavaTutor项目的师生对话构成。师生通过网络使用文本对话进行交流，共有43个对话，包含1525个学生对话（平均每句话7.54个单词）和3332个老师对话（平均每句话9.04个单词）。文章专注于分类学生对话，而老师对话分类将由系统生成。下表是对话类别和频率，Kappa系数为0.76:</p>

<table>
  <thead>
    <tr>
      <th>标签</th>
      <th>行为</th>
      <th>描述</th>
      <th>频率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Q</td>
      <td>一般问题</td>
      <td>一个于学习任务无关的问题</td>
      <td>276</td>
    </tr>
    <tr>
      <td>EQ</td>
      <td>学习问题</td>
      <td>一个于学习任务相关的问题</td>
      <td>416</td>
    </tr>
    <tr>
      <td>S</td>
      <td>陈述</td>
      <td>对一个事实的陈述</td>
      <td>211</td>
    </tr>
    <tr>
      <td>G</td>
      <td>Grounding</td>
      <td>对先前对话的承认</td>
      <td>192</td>
    </tr>
    <tr>
      <td>EX</td>
      <td>Extra-Domain</td>
      <td>任何于学习无关的对话</td>
      <td>133</td>
    </tr>
    <tr>
      <td>PF</td>
      <td>正面反馈</td>
      <td>对于知识或学习任务的正面评价</td>
      <td>116</td>
    </tr>
    <tr>
      <td>NF</td>
      <td>负面反馈</td>
      <td>对于知识或学习任务的负面评价</td>
      <td>92</td>
    </tr>
    <tr>
      <td>LF</td>
      <td>Lukewarm反馈</td>
      <td>同时含有正面和负面评价的评价</td>
      <td>32</td>
    </tr>
    <tr>
      <td>GRE</td>
      <td>问候</td>
      <td>问候词语</td>
      <td>57</td>
    </tr>
  </tbody>
</table>

<h2 id="query-likelihood-">Query-Likelihood 聚类</h2>
<hr />

<p>IR（Information Retrieval，信息检索）是搜索可用的资源用于检索和查询词相似的结果的过程。IR技术大部分用于搜索引擎检索和查询词相似的结果。在提出的方法中，将被分类的目标对话将被用作一个查询，而与它相似的对话将通过query likelihood进行收集。之后，与查询相似的结果被用于聚类。</p>

<h3 id="section-2">自然语言预处理</h3>

<p>Query-likelihood信息检索操作的是token或word级别的。实验证实，为了增加从语料库中提取有识别力的线索，预处理是一个关键的步骤。</p>

<p>词性（Part-of-speech, POS）标签是一项根据词语在语言中的语法部分将其标注为名词、动词或形容词的技术。它允许我们概括词语在句子中的功能。实验证明，使用单词和词性标签作为查询词能得到很好的效果。这个方法将一些功能词语替代为它们的词性标签，例如限定词（’the’, ‘a’）、连词（’and’, ‘but’）和介词（’in’, ‘after’），而内容词语将被保留并提取词干，这将减少特征词语的数量。这个方法是通过观察，发现关于对话的重要的词语存在于内容词语中。</p>

<p>当然，在计算机科学领域，一些包含特定字符的自然语言可能表示重要的语义，因此在预处理阶段需要适当的处理。因此，在语料库中的代码片段将被替换为具有意义的标签。例如，’x[i]’将被替换为’ARRAY_INDEXING’，if、for和算数表达式将使用相似的规定替换。</p>

<h3 id="query-likelihood--1">Query-Likelihood 表示</h3>

<p>Query-likelihood模型将每个对话视为一个文档，将被预测的目标对话作为查询，我们提供对目标对话的信息检索。这个查询将产生一个文档的排名列表，从最像到最不像。Query-likelihood的实现<a href="http://www.lemurproject.org/">The Lemur Project</a>使用论文<a href="http://ciir.cs.umass.edu/pubfiles/ir-407.pdf">A language-model based search engine forcomplex queries</a>。</p>

<p>词语的顺序包含了对话结构的重要信息，因此我们使用一个修改过的查询方法，考虑一个对话里相邻的两个单词进行查询。</p>

<p>下表中展示了多个原始的对话、在被词性标签替换及提取词干后的形式、和最后提交给算法的查询形式：</p>

<table>
  <thead>
    <tr>
      <th>原始对话</th>
      <th>POS和词干提取形式</th>
      <th>查询形式</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I’m reading it right now</td>
      <td>VB read PRP right now</td>
      <td>(VB read)(read PRP)(PRP right)(right now)</td>
    </tr>
    <tr>
      <td>what is the basic structure to begin an array?</td>
      <td>WDT VBZ DT basic structur TO begin DT array?</td>
      <td>(WDT VBZ)(VBZ DT)(DT basic)(basic structur)(structur TO)(TO begin)(begin DT)(DT array)(array ?)</td>
    </tr>
    <tr>
      <td>that was correct</td>
      <td>WDT VBD correct</td>
      <td>(WDT VBD)(VBD correct)</td>
    </tr>
    <tr>
      <td>how do you thinkyou should start it?</td>
      <td>WRB do PRP think PRP MD start PRP?</td>
      <td>(WRB do)(do PRP)(PRP think)(think PRP)(PRP MD)(PRP start)(startPRP)(PRP ?)</td>
    </tr>
  </tbody>
</table>

<p><br />
其中VBZ是第三人称现在时的单数动词，DT是限定词，TO是’to’，VBD是过去式动词，WDT和WRB是疑问词，MD是情态动词。</p>

<p>下面是一个查询样例和它的相似检索：</p>

<table>
  <thead>
    <tr>
      <th>Query</th>
      <th>Query Likelihood results</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>How can I solve this problem?</td>
      <td>How can I do addition?<br />What would be the results?<br />Which should go first?</td>
    </tr>
  </tbody>
</table>

<h3 id="section-3">聚类</h3>

<p>查询获得的相似结果将被用作k-means聚类算法中的距离矩阵。这个想法实现依赖于为相似的对话创造一个二进制向量，然后group这些向量。每个在相似列表中的对话表示为1，其它表示为0。这样，每个在语料库中的目标对话将被表示为一个向量，这个向量表示和它相似的对话。算法如下：</p>

<ul>
  <li>D为所有对话组成的语料库，<script type="math/tex">D=\lbrace u_1,u_2,...,u_n \rbrace</script>，目标是对于D中的任意一个对话<script type="math/tex">u_i</script>，确定一个标签<script type="math/tex">l_i</script></li>
  <li>对于每个<script type="math/tex">u_i</script>，
    <ol>
      <li>设目标对话<script type="math/tex">q_i=u_i</script></li>
      <li>设<script type="math/tex">u_i</script>的查询结果相似列表为<script type="math/tex">R=(u_t,u_{t+1},...,u_z)</script></li>
      <li>创建查询结果向量，<script type="math/tex">V_i=(v_1,v_2,...,v_j,...,v_n)\ such\ that\ v_j=1\ if\ u_j\in R\ else\ v_j=0</script></li>
    </ol>
  </li>
  <li>设总向量为<script type="math/tex">V_T=(V_1,V_2,...,V_n)</script>，返回k-means(<script type="math/tex">V_T</script>)的聚类结果<script type="math/tex">C=\lbrace c_1,c_2,...,c_k \rbrace</script></li>
</ul>

<hr />

